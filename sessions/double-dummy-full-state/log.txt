
Initializing a new AlphaZero environment

  Initial report
  
    Number of network parameters: 6,906,421
    Number of regularized network parameters: 6,906,240
    Memory footprint per MCTS node: 3736 bytes
  
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.87 (win rate of -44%), redundancy: 0.0%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +0.61 (win rate of 80%), redundancy: 0.0%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.74 (win rate of -187%), redundancy: 0.0%

Starting iteration 1

  Starting self-play
  
    Time spent on inference: 56%
    Generating 6 samples per second on average
    Average exploration depth: 5.1
    MCTS memory footprint: 78.64MB
    Experience buffer size: 52,000 (52,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp    Wtot      Nb      Ns
    13.0250  11.2888  0.3900  0.4570  0.8892  1.6520  1.2894  52,000  52,000  52,000  all samples
    13.0245  11.2881  0.3901  0.4570  0.8892  1.6521  1.2894  52,000  52,000  52,000  latest batch
     4.8596   3.2007  0.2214  0.4570  0.9804  0.6095  0.4235  13,000  13,000  13,000  1 to 13 turns left
     9.5041   7.6911  0.4219  0.4570  0.9341  1.5678  1.1958  13,000  13,000  13,000  14 to 26 turns left
    16.1233  14.3582  0.4441  0.4570  0.8641  2.0465  1.6387  13,000  13,000  13,000  27 to 39 turns left
    21.6243  19.9155  0.4736  0.4570  0.7783  2.3850  1.8996  13,000  13,000  13,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
      12.8936  10.8544   0.7099   0.4570   0.8722   1.2894   1.4693
      12.6976  11.5199   0.5203   0.3967   0.2608   1.2894   1.4489
    
    Launching a checkpoint evaluation
    
      Average reward: -1.27 (win rate of -14%), redundancy: 0.0%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.75 (win rate of -38%), redundancy: 0.0%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +0.26 (win rate of 63%), redundancy: 0.0%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.86 (win rate of -193%), redundancy: 0.0%

Starting iteration 2

  Starting self-play
  
    Time spent on inference: 56%
    Generating 6 samples per second on average
    Average exploration depth: 5.1
    MCTS memory footprint: 78.67MB
    Experience buffer size: 104,000 (104,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
    12.4136  11.2191  0.5408  0.3967  0.2570  1.4583  1.2897  104,000  104,000  104,000  all samples
    12.1229  10.9175  0.5530  0.3967  0.2557  1.4592  1.2899   52,000   52,000   52,000  latest batch
     4.5006   3.1981  0.3219  0.3967  0.5839  0.5596  0.4205   26,000   26,000   26,000  1 to 13 turns left
     8.9580   7.7552  0.5827  0.3967  0.2233  1.4161  1.1952   26,000   26,000   26,000  14 to 26 turns left
    15.1156  13.9859  0.6054  0.3967  0.1277  1.7970  1.6427   26,000   26,000   26,000  27 to 39 turns left
    21.0652  19.9223  0.6533  0.3967  0.0929  2.0607  1.9002   26,000   26,000   26,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
      12.4078  11.2186   0.5326   0.3967   0.2600   1.2897   1.4504
      11.8102  11.2178   0.3157   0.2608   0.0159   1.2897   1.5648
    
    Launching a checkpoint evaluation
    
      Average reward: -1.61 (win rate of -31%), redundancy: 0.0%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.89 (win rate of -44%), redundancy: 0.0%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.01 (win rate of 100%), redundancy: 0.0%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -5.02 (win rate of -201%), redundancy: 0.0%

Starting iteration 3

  Starting self-play
  

Loading environment

  Loading network from: sessions/double-dummy-full-state/bestnn.data
  Loading network from: sessions/double-dummy-full-state/curnn.data
  Loading memory from: sessions/double-dummy-full-state/mem.data
  Loaded iteration counter from: sessions/double-dummy-full-state/iter.txt

Starting iteration 3

  Starting self-play
  

Loading environment

  Loading network from: sessions/double-dummy-full-state/bestnn.data
  Loading network from: sessions/double-dummy-full-state/curnn.data
  Loading memory from: sessions/double-dummy-full-state/mem.data
  Loaded iteration counter from: sessions/double-dummy-full-state/iter.txt

Starting iteration 3

  Starting self-play
  
    Time spent on inference: 55%
    Generating 6 samples per second on average
    Average exploration depth: 5.1
    MCTS memory footprint: 78.86MB
    Experience buffer size: 156,000 (156,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
    11.8908  11.2978  0.3153  0.2608  0.0168  1.5641  1.2903  156,000  156,000  156,000  all samples
    12.0535  11.4508  0.3254  0.2608  0.0165  1.5614  1.2917   52,000   52,000   52,000  latest batch
     3.7557   3.2514  0.2225  0.2608  0.0210  0.6102  0.4209   39,000   39,000   39,000  1 to 13 turns left
     8.2634   7.6284  0.3583  0.2608  0.0157  1.5136  1.1958   39,000   39,000   39,000  14 to 26 turns left
    14.6851  14.0786  0.3301  0.2608  0.0156  1.9194  1.6432   39,000   39,000   39,000  27 to 39 turns left
    20.8402  20.2137  0.3506  0.2608  0.0151  2.2132  1.9013   39,000   39,000   39,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
      11.8948  11.2973   0.3209   0.2608   0.0157   1.2903   1.5638
       8.3336   7.8042   0.3211   0.1943   0.0141   1.2903   1.5524
    
    Launching a checkpoint evaluation
    
      Average reward: +0.40 (win rate of 70%), redundancy: 1.2%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -2.06 (win rate of -53%), redundancy: 1.0%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +0.63 (win rate of 82%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.90 (win rate of -195%), redundancy: 1.0%

Starting iteration 4

  Starting self-play
  
    Time spent on inference: 56%
    Generating 6 samples per second on average
    Average exploration depth: 5.1
    MCTS memory footprint: 78.56MB
    Experience buffer size: 208,000 (208,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     8.2260   7.6966  0.3210  0.1943  0.0141  1.5508  1.2906  208,000  208,000  208,000  all samples
     7.9789   7.4421  0.3286  0.1943  0.0139  1.5515  1.2914   52,000   52,000   52,000  latest batch
     2.3824   1.9571  0.2177  0.1943  0.0134  0.6068  0.4218   52,000   52,000   52,000  1 to 13 turns left
     5.1261   4.5627  0.3546  0.1943  0.0145  1.5132  1.1955   52,000   52,000   52,000  14 to 26 turns left
    10.0226   9.4769  0.3369  0.1943  0.0145  1.9132  1.6439   52,000   52,000   52,000  27 to 39 turns left
    15.3766  14.7933  0.3752  0.1943  0.0138  2.1700  1.9012   52,000   52,000   52,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.2483   7.7165   0.3234   0.1943   0.0141   1.2906   1.5523
       7.9282   7.4247   0.2928   0.2035   0.0071   1.2906   1.5128
    
    Launching a checkpoint evaluation
    
      Average reward: +0.76 (win rate of 88%), redundancy: 1.2%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.35 (win rate of -18%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +0.37 (win rate of 68%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -5.82 (win rate of -241%), redundancy: 1.0%

Starting iteration 5

  Starting self-play
  
    Time spent on inference: 56%
    Generating 6 samples per second on average
    Average exploration depth: 5.1
    MCTS memory footprint: 78.89MB
    Experience buffer size: 232,000 (232,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     7.8857   7.3768  0.2974  0.2035  0.0079  1.5175  1.2903  232,000  232,000  232,000  all samples
     7.7873   7.2705  0.3057  0.2035  0.0076  1.5167  1.2888   52,000   52,000   52,000  latest batch
     2.0282   1.6057  0.2058  0.2035  0.0133  0.6038  0.4210   58,000   58,000   58,000  1 to 14 turns left
     4.8981   4.3629  0.3252  0.2035  0.0065  1.4902  1.1963   58,000   58,000   58,000  14 to 27 turns left
     9.6519   9.1358  0.3064  0.2035  0.0062  1.8594  1.6438   58,000   58,000   58,000  27 to 40 turns left
    14.9669  14.4051  0.3525  0.2035  0.0058  2.1167  1.9001   58,000   58,000   58,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       7.8800   7.3742   0.2953   0.2035   0.0070   1.2903   1.5123
       7.6782   7.2217   0.2854   0.1627   0.0083   1.2903   1.5731
    
    Launching a checkpoint evaluation
    
      Average reward: +0.82 (win rate of 91%), redundancy: 1.2%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.78 (win rate of -39%), redundancy: 1.0%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +0.72 (win rate of 86%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -5.58 (win rate of -229%), redundancy: 1.0%

Starting iteration 6

  Starting self-play
  
    Time spent on inference: 56%
    Generating 6 samples per second on average
    Average exploration depth: 5.1
    MCTS memory footprint: 78.92MB
    Experience buffer size: 240,000 (240,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     7.6491   7.1897  0.2881  0.1627  0.0086  1.5704  1.2895  240,000  240,000  240,000  all samples
     7.8473   7.3824  0.2938  0.1627  0.0084  1.5693  1.2862   52,000   52,000   52,000  latest batch
     1.7259   1.3619  0.1960  0.1627  0.0053  0.6139  0.4216   60,000   60,000   60,000  1 to 14 turns left
     4.6908   4.1999  0.3196  0.1627  0.0085  1.5282  1.1935   60,000   60,000   60,000  14 to 27 turns left
     9.3584   8.8903  0.2955  0.1627  0.0100  1.9253  1.6431   60,000   60,000   60,000  27 to 40 turns left
    14.8145  14.3002  0.3411  0.1627  0.0106  2.2140  1.8996   60,000   60,000   60,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       7.6547   7.1966   0.2871   0.1627   0.0083   1.2895   1.5729
       7.4871   7.0375   0.2730   0.1711   0.0055   1.2895   1.5338
    
    Launching a checkpoint evaluation
    
      Average reward: +0.74 (win rate of 87%), redundancy: 1.1%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.99 (win rate of -50%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +0.77 (win rate of 88%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.91 (win rate of -196%), redundancy: 1.0%

Starting iteration 7

  Starting self-play
  
    Time spent on inference: 56%
    Generating 6 samples per second on average
    Average exploration depth: 5.1
    MCTS memory footprint: 78.95MB
    Experience buffer size: 248,000 (248,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     7.5829   7.1334  0.2729  0.1711  0.0055  1.5349  1.2894  248,000  248,000  248,000  all samples
     8.1301   7.6740  0.2795  0.1711  0.0055  1.5343  1.2897   52,000   52,000   52,000  latest batch
     1.6471   1.2794  0.1924  0.1711  0.0042  0.6043  0.4218   62,000   62,000   62,000  1 to 14 turns left
     4.6309   4.1448  0.3090  0.1711  0.0059  1.4976  1.1941   62,000   62,000   62,000  14 to 27 turns left
     9.2864   8.8271  0.2819  0.1711  0.0063  1.8823  1.6433   62,000   62,000   62,000  27 to 40 turns left
    14.7687  14.2836  0.3084  0.1711  0.0055  2.1558  1.8982   62,000   62,000   62,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       7.5948   7.1432   0.2750   0.1711   0.0055   1.2894   1.5335
       7.4646   7.0026   0.2668   0.1902   0.0050   1.2894   1.5405
    
    Launching a checkpoint evaluation
    
      Average reward: +1.09 (win rate of 104%, network replaced), redundancy: 1.1%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.99 (win rate of 1%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.41 (win rate of 120%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -3.99 (win rate of -150%), redundancy: 1.0%

Starting iteration 8

  Starting self-play
  
    Time spent on inference: 55%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 78.90MB
    Experience buffer size: 256,000 (256,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     7.1752   6.7007  0.2791  0.1902  0.0051  1.5427  1.2743  256,000  256,000  256,000  all samples
     6.1332   5.6037  0.3343  0.1902  0.0051  1.5562  1.2171   52,000   52,000   52,000  latest batch
     1.5908   1.2182  0.1779  0.1902  0.0045  0.5981  0.4232   64,000   64,000   64,000  1 to 14 turns left
     4.4936   3.9851  0.3125  0.1902  0.0058  1.4932  1.1813   64,000   64,000   64,000  14 to 27 turns left
     8.7562   8.2578  0.3027  0.1902  0.0056  1.8979  1.6156   64,000   64,000   64,000  27 to 40 turns left
    13.8600  13.3419  0.3233  0.1902  0.0046  2.1815  1.8772   64,000   64,000   64,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       7.1878   6.7087   0.2840   0.1902   0.0049   1.2743   1.5428
       7.0072   6.5145   0.2810   0.2070   0.0047   1.2743   1.5372
    
    Launching a checkpoint evaluation
    
      Average reward: +0.14 (win rate of 57%), redundancy: 1.5%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.87 (win rate of 6%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.51 (win rate of 125%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -3.99 (win rate of -150%), redundancy: 1.0%

Starting iteration 9

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.17MB
    Experience buffer size: 264,000 (264,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     6.8040   6.2977  0.2947  0.2070  0.0045  1.5396  1.2609  264,000  264,000  264,000  all samples
     6.1568   5.5985  0.3469  0.2070  0.0044  1.5472  1.2198   52,000   52,000   52,000  latest batch
     1.5661   1.1757  0.1792  0.2070  0.0042  0.5925  0.4242   66,000   66,000   66,000  1 to 14 turns left
     4.3777   3.8413  0.3242  0.2070  0.0051  1.4860  1.1702   66,000   66,000   66,000  14 to 27 turns left
     8.2167   7.6782  0.3267  0.2070  0.0048  1.8938  1.5902   66,000   66,000   66,000  27 to 40 turns left
    13.0626  12.5029  0.3488  0.2070  0.0039  2.1859  1.8590   66,000   66,000   66,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       6.8169   6.3079   0.2973   0.2070   0.0046   1.2609   1.5389
       6.6945   6.1848   0.2892   0.2160   0.0045   1.2609   1.5273
    
    Launching a checkpoint evaluation
    
      Average reward: +0.08 (win rate of 54%), redundancy: 1.2%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.03 (win rate of -2%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.56 (win rate of 128%), redundancy: 1.4%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.15 (win rate of -158%), redundancy: 1.0%

Starting iteration 10

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.11MB
    Experience buffer size: 272,000 (272,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     6.5976   6.0764  0.3005  0.2160  0.0047  1.5319  1.2500  272,000  272,000  272,000  all samples
     6.4640   5.9115  0.3318  0.2160  0.0047  1.5389  1.2276   52,000   52,000   52,000  latest batch
     1.5615   1.1686  0.1727  0.2160  0.0042  0.5890  0.4260   68,000   68,000   68,000  1 to 14 turns left
     4.3431   3.7929  0.3291  0.2160  0.0051  1.4818  1.1607   68,000   68,000   68,000  14 to 27 turns left
     7.9692   7.4071  0.3412  0.2160  0.0049  1.8898  1.5692   68,000   68,000   68,000  27 to 40 turns left
    12.5177  11.9381  0.3592  0.2160  0.0044  2.1671  1.8439   68,000   68,000   68,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       6.5955   6.0739   0.3011   0.2160   0.0045   1.2500   1.5288
       6.4293   5.9099   0.2907   0.2250   0.0036   1.2500   1.5154
    
    Launching a checkpoint evaluation
    
      Average reward: +0.32 (win rate of 66%), redundancy: 1.4%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.02 (win rate of -1%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.43 (win rate of 121%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -3.96 (win rate of -148%), redundancy: 1.0%

Starting iteration 11

  Starting self-play
  
    Time spent on inference: 55%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 78.88MB
    Experience buffer size: 280,000 (280,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     6.3200   5.7881  0.3033  0.2250  0.0036  1.5169  1.2380  280,000  280,000  280,000  all samples
     6.4170   5.8639  0.3245  0.2250  0.0036  1.5185  1.2174   52,000   52,000   52,000  latest batch
     1.5331   1.1397  0.1642  0.2250  0.0041  0.5869  0.4266   70,000   70,000   70,000  1 to 14 turns left
     4.2132   3.6574  0.3268  0.2250  0.0039  1.4652  1.1509   70,000   70,000   70,000  14 to 27 turns left
     7.6316   7.0522  0.3510  0.2250  0.0034  1.8624  1.5468   70,000   70,000   70,000  27 to 40 turns left
    11.8975  11.2983  0.3713  0.2250  0.0030  2.1534  1.8276   70,000   70,000   70,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       6.3012   5.7724   0.3003   0.2250   0.0035   1.2380   1.5168
       6.1074   5.5683   0.2957   0.2399   0.0036   1.2380   1.5031
    
    Launching a checkpoint evaluation
    
      Average reward: +0.34 (win rate of 67%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.48 (win rate of 26%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.35 (win rate of 118%), redundancy: 1.4%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.14 (win rate of -157%), redundancy: 1.0%

Starting iteration 12

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.10MB
    Experience buffer size: 288,000 (288,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.9924   5.4472  0.3018  0.2399  0.0034  1.5042  1.2268  288,000  288,000  288,000  all samples
     6.2955   5.7406  0.3117  0.2399  0.0034  1.5056  1.2201   52,000   52,000   52,000  latest batch
     1.5159   1.1112  0.1600  0.2399  0.0047  0.5802  0.4269   72,000   72,000   72,000  1 to 14 turns left
     4.1033   3.5328  0.3269  0.2399  0.0037  1.4607  1.1413   72,000   72,000   72,000  14 to 27 turns left
     7.1611   6.5634  0.3549  0.2399  0.0029  1.8557  1.5248   72,000   72,000   72,000  27 to 40 turns left
    11.1861  10.5784  0.3653  0.2399  0.0025  2.1201  1.8142   72,000   72,000   72,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.9966   5.4507   0.3025   0.2399   0.0035   1.2268   1.5043
       5.8329   5.2900   0.2922   0.2470   0.0037   1.2268   1.4765
    
    Launching a checkpoint evaluation
    
      Average reward: +0.32 (win rate of 66%), redundancy: 1.4%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.95 (win rate of 3%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.33 (win rate of 116%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.06 (win rate of -153%), redundancy: 1.0%

Starting iteration 13

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.13MB
    Experience buffer size: 296,000 (296,000 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7256  5.1794  0.2954  0.2470  0.0038  1.4773  1.2207  296,000  296,000  296,000  all samples
     6.1302  5.5760  0.3035  0.2470  0.0037  1.4770  1.2214   52,000   52,000   52,000  latest batch
     1.5040  1.0997  0.1521  0.2470  0.0052  0.5754  0.4270   74,000   74,000   74,000  1 to 14 turns left
     3.9853  3.4168  0.3180  0.2470  0.0035  1.4415  1.1354   74,000   74,000   74,000  14 to 27 turns left
     6.8274  6.2241  0.3532  0.2470  0.0031  1.8212  1.5135   74,000   74,000   74,000  27 to 40 turns left
    10.5876  9.9789  0.3584  0.2470  0.0032  2.0712  1.8070   74,000   74,000   74,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7376   5.1914   0.2955   0.2470   0.0037   1.2207   1.4776

Loading environment

  Loading network from: sessions/double-dummy-full-state/bestnn.data
  Loading network from: sessions/double-dummy-full-state/curnn.data
  Loading memory from: sessions/double-dummy-full-state/mem.data
  Loaded iteration counter from: sessions/double-dummy-full-state/iter.txt

Starting iteration 13

  Starting self-play
  
    Time spent on inference: 55%
    Generating 6 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.18MB
    Experience buffer size: 296,000 (296,000 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.6926  5.1460  0.2957  0.2470  0.0038  1.4770  1.2200  296,000  296,000  296,000  all samples
     5.9419  5.3857  0.3054  0.2470  0.0039  1.4753  1.2172   52,000   52,000   52,000  latest batch
     1.5093  1.1055  0.1515  0.2470  0.0052  0.5755  0.4279   74,000   74,000   74,000  1 to 14 turns left
     3.9670  3.3980  0.3185  0.2470  0.0035  1.4423  1.1347   74,000   74,000   74,000  14 to 27 turns left
     6.7805  6.1760  0.3544  0.2470  0.0032  1.8209  1.5120   74,000   74,000   74,000  27 to 40 turns left
    10.5136  9.9048  0.3584  0.2470  0.0033  2.0694  1.8053   74,000   74,000   74,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7002   5.1541   0.2955   0.2470   0.0037   1.2200   1.4770
       5.6997   5.1112   0.2969   0.2877   0.0039   1.2200   1.5082
    
    Launching a checkpoint evaluation
    
      Average reward: +0.56 (win rate of 78%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.84 (win rate of 8%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.10 (win rate of 105%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.26 (win rate of -163%), redundancy: 1.0%

Starting iteration 14

  Starting self-play
  
    Time spent on inference: 57%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.14MB
    Experience buffer size: 304,000 (304,000 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7530  5.1623  0.2991  0.2877  0.0038  1.5076  1.2200  304,000  304,000  304,000  all samples
     6.0937  5.4941  0.3082  0.2877  0.0038  1.5070  1.2176   52,000   52,000   52,000  latest batch
     1.5857  1.1368  0.1535  0.2877  0.0077  0.5853  0.4281   76,000   76,000   76,000  1 to 14 turns left
     4.0469  3.4282  0.3272  0.2877  0.0038  1.4688  1.1332   76,000   76,000   76,000  14 to 27 turns left
     6.7736  6.1239  0.3596  0.2877  0.0024  1.8565  1.5113   76,000   76,000   76,000  27 to 40 turns left
    10.6068  9.9616  0.3561  0.2877  0.0015  2.1197  1.8075   76,000   76,000   76,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7597   5.1693   0.2989   0.2877   0.0039   1.2200   1.5084
       5.5792   4.9879   0.2893   0.2981   0.0039   1.2200   1.4937
    
    Launching a checkpoint evaluation
    
      Average reward: +0.48 (win rate of 74%), redundancy: 1.4%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.06 (win rate of -3%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.50 (win rate of 125%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.06 (win rate of -153%), redundancy: 1.0%

Starting iteration 15

  Starting self-play
  
    Time spent on inference: 57%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 78.96MB
    Experience buffer size: 312,000 (312,000 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7035  5.1115  0.2898  0.2981  0.0040  1.4939  1.2201  312,000  312,000  312,000  all samples
     6.1781  5.5839  0.2920  0.2981  0.0040  1.4946  1.2205   52,000   52,000   52,000  latest batch
     1.5252  1.0671  0.1518  0.2981  0.0082  0.5821  0.4272   78,000   78,000   78,000  1 to 13 turns left
     3.9779  3.3592  0.3167  0.2981  0.0039  1.4554  1.1332   78,000   78,000   78,000  14 to 26 turns left
     6.7326  6.0844  0.3476  0.2981  0.0025  1.8408  1.5119   78,000   78,000   78,000  27 to 39 turns left
    10.5763  9.9335  0.3430  0.2981  0.0016  2.0973  1.8081   78,000   78,000   78,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7070   5.1148   0.2902   0.2981   0.0039   1.2201   1.4937
       5.6819   5.0775   0.2865   0.3147   0.0032   1.2201   1.4998
    
    Launching a checkpoint evaluation
    
      Average reward: +0.66 (win rate of 83%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.08 (win rate of -4%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.21 (win rate of 110%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -3.86 (win rate of -143%), redundancy: 1.0%

Starting iteration 16

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.12MB
    Experience buffer size: 320,000 (320,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.8191   5.2132  0.2880  0.3147  0.0032  1.5003  1.2189  320,000  320,000  320,000  all samples
     6.6108   5.9982  0.2946  0.3147  0.0032  1.5002  1.2190   52,000   52,000   52,000  latest batch
     1.5778   1.1052  0.1512  0.3147  0.0067  0.5778  0.4271   80,000   80,000   80,000  1 to 14 turns left
     4.0566   3.4238  0.3151  0.3147  0.0030  1.4529  1.1312   80,000   80,000   80,000  14 to 27 turns left
     6.8623   6.1992  0.3466  0.3147  0.0018  1.8467  1.5101   80,000   80,000   80,000  27 to 40 turns left
    10.7796  10.1243  0.3393  0.3147  0.0013  2.1237  1.8073   80,000   80,000   80,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.8270   5.2212   0.2879   0.3147   0.0032   1.2189   1.4994

Loading environment

  Loading network from: sessions/double-dummy-full-state/bestnn.data
  Loading network from: sessions/double-dummy-full-state/curnn.data
  Loading memory from: sessions/double-dummy-full-state/mem.data
  Loaded iteration counter from: sessions/double-dummy-full-state/iter.txt

Starting iteration 16

  Starting self-play
  
    Time spent on inference: 55%
    Generating 6 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 78.88MB
    Experience buffer size: 282,500 (282,500 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.8006   5.1943  0.2885  0.3147  0.0032  1.5007  1.2197  282,500  282,500  282,500  all samples
     6.4410   5.8296  0.2936  0.3147  0.0031  1.5028  1.2243   52,000   52,000   52,000  latest batch
     1.5648   1.0921  0.1513  0.3147  0.0067  0.5777  0.4269   70,625   70,625   70,625  1 to 14 turns left
     4.0605   3.4279  0.3150  0.3147  0.0029  1.4532  1.1334   70,625   70,625   70,625  14 to 27 turns left
     6.7949   6.1288  0.3496  0.3147  0.0018  1.8469  1.5089   70,625   70,625   70,625  27 to 40 turns left
    10.7740  10.1198  0.3382  0.3147  0.0013  2.1246  1.8094   70,625   70,625   70,625  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.8117   5.2055   0.2883   0.3147   0.0032   1.2197   1.4999
       5.8267   5.1607   0.2954   0.3666   0.0040   1.2197   1.5174
    
    Launching a checkpoint evaluation
    
      Average reward: +0.88 (win rate of 94%), redundancy: 1.4%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.94 (win rate of 3%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.58 (win rate of 129%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.10 (win rate of -155%), redundancy: 1.0%

Starting iteration 17

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 78.75MB
    Experience buffer size: 288,000 (288,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.8969   5.2303  0.2960  0.3666  0.0039  1.5174  1.2198  288,000  288,000  288,000  all samples
     6.2616   5.5887  0.3024  0.3666  0.0039  1.5166  1.2176   52,000   52,000   52,000  latest batch
     1.5928   1.0607  0.1570  0.3667  0.0085  0.5867  0.4272   72,000   72,000   72,000  1 to 14 turns left
     4.1090   3.4176  0.3213  0.3667  0.0035  1.4726  1.1338   72,000   72,000   72,000  14 to 27 turns left
     6.9672   6.2411  0.3572  0.3667  0.0022  1.8641  1.5085   72,000   72,000   72,000  27 to 40 turns left
    10.9197  10.2032  0.3482  0.3667  0.0016  2.1461  1.8098   72,000   72,000   72,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.9076   5.2406   0.2964   0.3666   0.0040   1.2198   1.5174
       5.8377   5.1760   0.2938   0.3640   0.0039   1.2198   1.5033
    
    Launching a checkpoint evaluation
    
      Average reward: +0.72 (win rate of 86%), redundancy: 1.4%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.99 (win rate of 1%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.26 (win rate of 113%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.12 (win rate of -156%), redundancy: 1.0%

Starting iteration 18

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.40MB
    Experience buffer size: 293,500 (293,500 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.8967   5.2325  0.2957  0.3640  0.0044  1.5030  1.2199  293,500  293,500  293,500  all samples
     6.2301   5.5632  0.2985  0.3640  0.0044  1.5032  1.2208   52,000   52,000   52,000  latest batch
     1.5904   1.0616  0.1561  0.3640  0.0087  0.5823  0.4276   73,375   73,375   73,375  1 to 14 turns left
     4.1016   3.4131  0.3206  0.3640  0.0038  1.4562  1.1336   73,375   73,375   73,375  14 to 27 turns left
     6.9112   6.1880  0.3563  0.3640  0.0029  1.8435  1.5089   73,375   73,375   73,375  27 to 40 turns left
    10.9805  10.2644  0.3498  0.3640  0.0022  2.1300  1.8094   73,375   73,375   73,375  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.8989   5.2364   0.2945   0.3640   0.0039   1.2199   1.5035
       5.7058   5.0766   0.2930   0.3284   0.0078   1.2199   1.4917
    
    Launching a checkpoint evaluation
    
      Average reward: +0.59 (win rate of 80%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.84 (win rate of 8%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.68 (win rate of 134%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.15 (win rate of -158%), redundancy: 1.0%

Starting iteration 19

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.21MB
    Experience buffer size: 299,000 (299,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7903   5.1602  0.2940  0.3284  0.0077  1.4906  1.2201  299,000  299,000  299,000  all samples
     5.8471   5.2112  0.3000  0.3284  0.0075  1.4911  1.2188   52,000   52,000   52,000  latest batch
     1.5366   1.0306  0.1589  0.3284  0.0187  0.5784  0.4279   74,750   74,750   74,750  1 to 13 turns left
     4.0207   3.3647  0.3215  0.3284  0.0061  1.4461  1.1344   74,750   74,750   74,750  14 to 26 turns left
     6.8190   6.1332  0.3536  0.3284  0.0036  1.8315  1.5073   74,750   74,750   74,750  27 to 39 turns left
    10.7830  10.1108  0.3415  0.3284  0.0023  2.1063  1.8106   74,750   74,750   74,750  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7925   5.1625   0.2937   0.3284   0.0078   1.2201   1.4919
       5.6455   5.0454   0.2846   0.3121   0.0035   1.2201   1.4977
    
    Launching a checkpoint evaluation
    
      Average reward: +0.78 (win rate of 89%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.89 (win rate of 5%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.28 (win rate of 114%), redundancy: 1.4%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.25 (win rate of -162%), redundancy: 1.0%

Starting iteration 20

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 78.97MB
    Experience buffer size: 304,500 (304,500 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.8045   5.2044  0.2841  0.3121  0.0038  1.4941  1.2208  304,500  304,500  304,500  all samples
     6.4973   5.8942  0.2872  0.3121  0.0038  1.4925  1.2217   52,000   52,000   52,000  latest batch
     1.4897   1.0183  0.1503  0.3121  0.0090  0.5816  0.4284   76,125   76,125   76,125  1 to 14 turns left
     3.9946   3.3693  0.3099  0.3121  0.0032  1.4521  1.1362   76,125   76,125   76,125  14 to 27 turns left
     6.8622   6.2033  0.3448  0.3121  0.0020  1.8321  1.5076   76,125   76,125   76,125  27 to 40 turns left
    10.8787  10.2340  0.3313  0.3121  0.0012  2.1105  1.8111   76,125   76,125   76,125  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.8047   5.2043   0.2848   0.3121   0.0035   1.2208   1.4978
       5.7070   5.1243   0.2807   0.2989   0.0031   1.2208   1.4707
    
    Launching a checkpoint evaluation
    
      Average reward: +0.95 (win rate of 98%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.95 (win rate of 3%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.40 (win rate of 120%), redundancy: 1.4%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.07 (win rate of -154%), redundancy: 1.0%

Starting iteration 21

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.13MB
    Experience buffer size: 310,000 (310,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.8597   5.2761  0.2814  0.2989  0.0034  1.4704  1.2204  310,000  310,000  310,000  all samples
     6.5316   5.9427  0.2866  0.2989  0.0034  1.4690  1.2200   52,000   52,000   52,000  latest batch
     1.4578   1.0032  0.1483  0.2989  0.0074  0.5612  0.4287   77,500   77,500   77,500  1 to 14 turns left
     4.0253   3.4173  0.3061  0.2989  0.0031  1.4186  1.1355   77,500   77,500   77,500  14 to 27 turns left
     6.9707   6.3299  0.3400  0.2989  0.0019  1.8162  1.5068   77,500   77,500   77,500  27 to 40 turns left
    10.9846  10.3533  0.3312  0.2989  0.0012  2.0853  1.8106   77,500   77,500   77,500  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.8669   5.2828   0.2821   0.2989   0.0031   1.2204   1.4707
       5.7475   5.1728   0.2788   0.2931   0.0027   1.2204   1.4955
    
    Launching a checkpoint evaluation
    
      Average reward: +0.86 (win rate of 93%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.10 (win rate of -5%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.35 (win rate of 118%), redundancy: 1.4%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.13 (win rate of -156%), redundancy: 1.1%

Starting iteration 22

  Starting self-play
  
    Time spent on inference: 55%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 78.66MB
    Experience buffer size: 315,500 (315,500 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7765   5.2015  0.2791  0.2931  0.0028  1.4967  1.2199  315,500  315,500  315,500  all samples
     6.0080   5.4279  0.2841  0.2931  0.0028  1.4977  1.2194   52,000   52,000   52,000  latest batch
     1.4394   0.9942  0.1463  0.2931  0.0058  0.5761  0.4282   78,875   78,875   78,875  1 to 14 turns left
     3.9721   3.3718  0.3046  0.2931  0.0025  1.4478  1.1346   78,875   78,875   78,875  14 to 27 turns left
     6.8506   6.2195  0.3363  0.2931  0.0016  1.8382  1.5069   78,875   78,875   78,875  27 to 40 turns left
    10.8458  10.2222  0.3291  0.2931  0.0013  2.1248  1.8098   78,875   78,875   78,875  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7831   5.2074   0.2798   0.2931   0.0027   1.2199   1.4952
       5.6939   5.1262   0.2768   0.2883   0.0027   1.2199   1.4800
    
    Launching a checkpoint evaluation
    
      Average reward: +0.68 (win rate of 84%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.95 (win rate of 3%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.16 (win rate of 108%), redundancy: 1.4%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.20 (win rate of -160%), redundancy: 1.0%

Starting iteration 23

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 78.96MB
    Experience buffer size: 321,000 (321,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.8084   5.2385  0.2790  0.2883  0.0027  1.4785  1.2208  321,000  321,000  321,000  all samples
     6.3385   5.7622  0.2853  0.2883  0.0027  1.4807  1.2248   52,000   52,000   52,000  latest batch
     1.4208   0.9814  0.1455  0.2883  0.0055  0.5634  0.4283   80,250   80,250   80,250  1 to 14 turns left
     3.9947   3.4012  0.3028  0.2883  0.0024  1.4251  1.1345   80,250   80,250   80,250  14 to 27 turns left
     6.8938   6.2686  0.3353  0.2883  0.0017  1.8164  1.5086   80,250   80,250   80,250  27 to 40 turns left
    10.9255  10.3033  0.3326  0.2883  0.0014  2.1092  1.8118   80,250   80,250   80,250  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.8063   5.2378   0.2776   0.2883   0.0027   1.2208   1.4802
       5.7229   5.1580   0.2772   0.2847   0.0029   1.2208   1.4876
    
    Launching a checkpoint evaluation
    
      Average reward: +0.91 (win rate of 96%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.92 (win rate of 4%), redundancy: 1.3%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.13 (win rate of 106%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.35 (win rate of -167%), redundancy: 1.0%

Starting iteration 24

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 78.80MB
    Experience buffer size: 326,500 (326,500 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.8353   5.2682  0.2797  0.2847  0.0027  1.4865  1.2205  326,500  326,500  326,500  all samples
     6.1752   5.6001  0.2876  0.2847  0.0028  1.4880  1.2186   52,000   52,000   52,000  latest batch
     1.4081   0.9725  0.1452  0.2847  0.0057  0.5685  0.4283   81,625   81,625   81,625  1 to 14 turns left
     3.9943   3.4014  0.3058  0.2847  0.0024  1.4394  1.1337   81,625   81,625   81,625  14 to 27 turns left
     6.9390   6.3142  0.3384  0.2847  0.0016  1.8403  1.5091   81,625   81,625   81,625  27 to 40 turns left
    10.9961  10.3810  0.3292  0.2847  0.0011  2.0979  1.8110   81,625   81,625   81,625  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.8404   5.2739   0.2788   0.2847   0.0030   1.2205   1.4880
       5.7375   5.1834   0.2742   0.2775   0.0024   1.2205   1.4874
    
    Launching a checkpoint evaluation
    
      Average reward: +0.66 (win rate of 83%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.76 (win rate of 12%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.13 (win rate of 106%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.12 (win rate of -156%), redundancy: 1.0%

Starting iteration 25

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 78.97MB
    Experience buffer size: 332,000 (332,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7948   5.2406  0.2742  0.2775  0.0024  1.4897  1.2205  332,000  332,000  332,000  all samples
     6.1054   5.5450  0.2804  0.2775  0.0024  1.4897  1.2199   52,000   52,000   52,000  latest batch
     1.3950   0.9663  0.1460  0.2775  0.0052  0.5759  0.4275   83,000   83,000   83,000  1 to 14 turns left
     3.9972   3.4179  0.2994  0.2775  0.0023  1.4500  1.1348   83,000   83,000   83,000  14 to 27 turns left
     6.9367   6.3265  0.3313  0.2775  0.0014  1.8344  1.5098   83,000   83,000   83,000  27 to 40 turns left
    10.8480  10.2492  0.3205  0.2775  0.0008  2.0988  1.8098   83,000   83,000   83,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.8015   5.2461   0.2755   0.2775   0.0024   1.2205   1.4872
       5.7413   5.1880   0.2768   0.2741   0.0024   1.2205   1.4520
    
    Launching a checkpoint evaluation
    
      Average reward: +0.36 (win rate of 68%), redundancy: 1.4%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.99 (win rate of 1%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.37 (win rate of 118%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.05 (win rate of -152%), redundancy: 1.0%

Starting iteration 26

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.02MB
    Experience buffer size: 337,500 (337,500 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.8188   5.2650  0.2773  0.2741  0.0025  1.4534  1.2207  337,500  337,500  337,500  all samples
     6.1554   5.5965  0.2824  0.2741  0.0025  1.4501  1.2201   52,000   52,000   52,000  latest batch
     1.3833   0.9571  0.1469  0.2741  0.0052  0.5670  0.4278   84,375   84,375   84,375  1 to 14 turns left
     3.9834   3.4054  0.3016  0.2741  0.0024  1.4118  1.1343   84,375   84,375   84,375  14 to 27 turns left
     6.9691   6.3591  0.3345  0.2741  0.0015  1.7854  1.5105   84,375   84,375   84,375  27 to 40 turns left
    10.9400  10.3393  0.3258  0.2741  0.0009  2.0492  1.8101   84,375   84,375   84,375  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.8326   5.2783   0.2778   0.2741   0.0024   1.2207   1.4519
       5.7268   5.1817   0.2699   0.2724   0.0028   1.2207   1.4782
    
    Launching a checkpoint evaluation
    
      Average reward: +0.56 (win rate of 78%), redundancy: 1.2%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.19 (win rate of -9%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.27 (win rate of 114%), redundancy: 1.4%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.22 (win rate of -161%), redundancy: 1.0%

Starting iteration 27

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.01MB
    Experience buffer size: 343,000 (343,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7644   5.2169  0.2722  0.2724  0.0029  1.4778  1.2206  343,000  343,000  343,000  all samples
     6.0658   5.5121  0.2783  0.2724  0.0029  1.4801  1.2217   52,000   52,000   52,000  latest batch
     1.3941   0.9711  0.1445  0.2724  0.0060  0.5615  0.4270   85,750   85,750   85,750  1 to 14 turns left
     3.9613   3.3874  0.2989  0.2724  0.0026  1.4226  1.1339   85,750   85,750   85,750  14 to 27 turns left
     6.8914   6.2895  0.3277  0.2724  0.0018  1.8170  1.5112   85,750   85,750   85,750  27 to 40 turns left
    10.8059  10.2149  0.3174  0.2724  0.0012  2.1100  1.8105   85,750   85,750   85,750  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7676   5.2207   0.2717   0.2724   0.0028   1.2206   1.4787
       5.6966   5.1528   0.2705   0.2705   0.0028   1.2206   1.4917
    
    Launching a checkpoint evaluation
    
      Average reward: +0.82 (win rate of 91%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.02 (win rate of -1%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +0.79 (win rate of 90%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.09 (win rate of -154%), redundancy: 1.0%

Starting iteration 28

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.31MB
    Experience buffer size: 348,500 (348,500 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7499   5.2048  0.2720  0.2705  0.0027  1.4934  1.2208  348,500  348,500  348,500  all samples
     6.2809   5.7297  0.2780  0.2705  0.0027  1.4941  1.2216   52,000   52,000   52,000  latest batch
     1.3929   0.9734  0.1432  0.2705  0.0059  0.5762  0.4273   87,125   87,125   87,125  1 to 14 turns left
     3.9217   3.3505  0.2982  0.2705  0.0025  1.4437  1.1337   87,125   87,125   87,125  14 to 27 turns left
     6.8298   6.2305  0.3273  0.2705  0.0015  1.8316  1.5121   87,125   87,125   87,125  27 to 40 turns left
    10.8538  10.2633  0.3192  0.2705  0.0008  2.1221  1.8102   87,125   87,125   87,125  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7521   5.2072   0.2715   0.2705   0.0028   1.2208   1.4921
       5.6749   5.1357   0.2693   0.2676   0.0024   1.2208   1.4705
    
    Launching a checkpoint evaluation
    
      Average reward: +0.66 (win rate of 83%), redundancy: 1.2%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.02 (win rate of -1%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.24 (win rate of 112%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.19 (win rate of -160%), redundancy: 1.0%

Starting iteration 29

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.32MB
    Experience buffer size: 354,000 (354,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7459   5.2056  0.2702  0.2676  0.0025  1.4685  1.2207  354,000  354,000  354,000  all samples
     5.8587   5.3137  0.2748  0.2676  0.0025  1.4677  1.2186   52,000   52,000   52,000  latest batch
     1.3772   0.9601  0.1441  0.2676  0.0054  0.5660  0.4272   88,500   88,500   88,500  1 to 14 turns left
     3.9201   3.3558  0.2943  0.2676  0.0023  1.4169  1.1335   88,500   88,500   88,500  14 to 27 turns left
     6.8203   6.2269  0.3245  0.2676  0.0014  1.8036  1.5129   88,500   88,500   88,500  27 to 40 turns left
    10.8634  10.2774  0.3175  0.2676  0.0009  2.0874  1.8093   88,500   88,500   88,500  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7460   5.2058   0.2702   0.2676   0.0024   1.2207   1.4705
       5.6621   5.1223   0.2689   0.2684   0.0026   1.2207   1.4737
    
    Launching a checkpoint evaluation
    
      Average reward: +0.80 (win rate of 90%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.07 (win rate of -4%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.73 (win rate of 136%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -3.53 (win rate of -126%), redundancy: 1.0%

Starting iteration 30

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 78.90MB
    Experience buffer size: 359,500 (359,500 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7142   5.1734  0.2700  0.2684  0.0024  1.4719  1.2199  359,500  359,500  359,500  all samples
     6.3058   5.7604  0.2746  0.2684  0.0024  1.4704  1.2188   52,000   52,000   52,000  latest batch
     1.3656   0.9511  0.1410  0.2684  0.0051  0.5674  0.4274   89,875   89,875   89,875  1 to 14 turns left
     3.9347   3.3693  0.2947  0.2684  0.0023  1.4264  1.1338   89,875   89,875   89,875  14 to 27 turns left
     6.8327   6.2362  0.3268  0.2684  0.0014  1.8114  1.5123   89,875   89,875   89,875  27 to 40 turns left
    10.7238  10.1371  0.3175  0.2684  0.0008  2.0824  1.8061   89,875   89,875   89,875  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7186   5.1779   0.2698   0.2684   0.0026   1.2199   1.4735
       5.6505   5.1163   0.2654   0.2663   0.0025   1.2199   1.4708
    
    Launching a checkpoint evaluation
    
      Average reward: +0.81 (win rate of 90%), redundancy: 1.4%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.02 (win rate of -1%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.69 (win rate of 134%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.24 (win rate of -162%), redundancy: 1.0%

Starting iteration 31

  Starting self-play
  
    Time spent on inference: 57%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.04MB
    Experience buffer size: 365,000 (365,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7636   5.2300  0.2648  0.2663  0.0025  1.4702  1.2206  365,000  365,000  365,000  all samples
     6.3861   5.8505  0.2669  0.2663  0.0025  1.4718  1.2238   52,000   52,000   52,000  latest batch
     1.3568   0.9459  0.1392  0.2663  0.0053  0.5628  0.4274   91,250   91,250   91,250  1 to 14 turns left
     3.9534   3.3962  0.2886  0.2663  0.0023  1.4198  1.1348   91,250   91,250   91,250  14 to 27 turns left
     6.8762   6.2889  0.3196  0.2663  0.0014  1.8049  1.5119   91,250   91,250   91,250  27 to 40 turns left
    10.8632  10.2841  0.3119  0.2663  0.0009  2.0934  1.8084   91,250   91,250   91,250  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7650   5.2306   0.2656   0.2663   0.0025   1.2206   1.4709
       5.6968   5.1665   0.2637   0.2642   0.0025   1.2206   1.4702
    
    Launching a checkpoint evaluation
    
      Average reward: +0.64 (win rate of 82%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.90 (win rate of 5%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.69 (win rate of 134%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.22 (win rate of -161%), redundancy: 1.0%

Starting iteration 32

  Starting self-play
  
    Time spent on inference: 57%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.49MB
    Experience buffer size: 370,500 (370,500 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7518   5.2228  0.2624  0.2642  0.0023  1.4692  1.2209  370,500  370,500  370,500  all samples
     6.0983   5.5677  0.2641  0.2642  0.0023  1.4680  1.2222   52,000   52,000   52,000  latest batch
     1.3452   0.9382  0.1378  0.2642  0.0050  0.5693  0.4271   92,625   92,625   92,625  1 to 13 turns left
     3.9384   3.3861  0.2860  0.2642  0.0022  1.4197  1.1350   92,625   92,625   92,625  14 to 26 turns left
     6.8597   6.2789  0.3153  0.2642  0.0013  1.8011  1.5133   92,625   92,625   92,625  27 to 39 turns left
    10.8556  10.2802  0.3105  0.2642  0.0007  2.0865  1.8082   92,625   92,625   92,625  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7591   5.2283   0.2642   0.2642   0.0025   1.2209   1.4704
       5.7070   5.1782   0.2636   0.2628   0.0025   1.2209   1.4750
    
    Launching a checkpoint evaluation
    
      Average reward: +0.89 (win rate of 94%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.71 (win rate of 15%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.16 (win rate of 108%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -3.87 (win rate of -144%), redundancy: 1.0%

Starting iteration 33

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 78.80MB
    Experience buffer size: 376,000 (376,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7828   5.2535  0.2641  0.2628  0.0024  1.4739  1.2204  376,000  376,000  376,000  all samples
     6.1653   5.6313  0.2688  0.2628  0.0024  1.4733  1.2173   52,000   52,000   52,000  latest batch
     1.3466   0.9393  0.1392  0.2628  0.0053  0.5663  0.4261   94,000   94,000   94,000  1 to 14 turns left
     3.9492   3.3988  0.2854  0.2628  0.0022  1.4225  1.1356   94,000   94,000   94,000  14 to 27 turns left
     6.8995   6.3194  0.3161  0.2628  0.0013  1.8137  1.5126   94,000   94,000   94,000  27 to 40 turns left
    10.9369  10.3581  0.3153  0.2628  0.0007  2.0929  1.8075   94,000   94,000   94,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7867   5.2570   0.2644   0.2628   0.0025   1.2204   1.4752
       5.7311   5.2044   0.2659   0.2587   0.0022   1.2204   1.4671
    
    Launching a checkpoint evaluation
    
      Average reward: +0.76 (win rate of 88%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.04 (win rate of -2%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.94 (win rate of 147%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.03 (win rate of -152%), redundancy: 1.0%

Starting iteration 34

  Starting self-play
  
    Time spent on inference: 57%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.06MB
    Experience buffer size: 381,500 (381,500 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7410   5.2136  0.2666  0.2587  0.0022  1.4649  1.2202  381,500  381,500  381,500  all samples
     5.6351   5.1018  0.2724  0.2587  0.0022  1.4660  1.2189   52,000   52,000   52,000  latest batch
     1.3438   0.9411  0.1393  0.2587  0.0047  0.5576  0.4265   95,375   95,375   95,375  1 to 14 turns left
     3.9260   3.3754  0.2899  0.2587  0.0020  1.4188  1.1345   95,375   95,375   95,375  14 to 27 turns left
     6.8597   6.2802  0.3197  0.2587  0.0012  1.8057  1.5111   95,375   95,375   95,375  27 to 40 turns left
    10.8338  10.2569  0.3176  0.2587  0.0006  2.0774  1.8087   95,375   95,375   95,375  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7425   5.2152   0.2665   0.2587   0.0022   1.2202   1.4669
       5.6583   5.1390   0.2615   0.2556   0.0022   1.2202   1.4641
    
    Launching a checkpoint evaluation
    
      Average reward: +0.86 (win rate of 93%), redundancy: 1.4%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.94 (win rate of 3%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.49 (win rate of 125%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.04 (win rate of -152%), redundancy: 1.0%

Starting iteration 35

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.36MB
    Experience buffer size: 387,000 (387,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7251   5.2061  0.2611  0.2556  0.0023  1.4626  1.2205  387,000  387,000  387,000  all samples
     6.2163   5.6932  0.2651  0.2556  0.0024  1.4633  1.2238   52,000   52,000   52,000  latest batch
     1.3354   0.9391  0.1357  0.2556  0.0050  0.5641  0.4262   96,750   96,750   96,750  1 to 14 turns left
     3.8974   3.3569  0.2827  0.2556  0.0022  1.4158  1.1350   96,750   96,750   96,750  14 to 27 turns left
     6.8447   6.2710  0.3168  0.2556  0.0013  1.7961  1.5107   96,750   96,750   96,750  27 to 40 turns left
    10.8245  10.2589  0.3093  0.2556  0.0007  2.0747  1.8102   96,750   96,750   96,750  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7257   5.2058   0.2621   0.2556   0.0022   1.2205   1.4639
       5.6743   5.1593   0.2607   0.2521   0.0022   1.2205   1.4440
    
    Launching a checkpoint evaluation
    
      Average reward: +0.82 (win rate of 91%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.88 (win rate of 6%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.39 (win rate of 119%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.22 (win rate of -161%), redundancy: 1.0%

Starting iteration 36

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.03MB
    Experience buffer size: 392,500 (392,500 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7032   5.1884  0.2604  0.2521  0.0023  1.4428  1.2206  392,500  392,500  392,500  all samples
     5.9627   5.4423  0.2659  0.2521  0.0023  1.4428  1.2201   52,000   52,000   52,000  latest batch
     1.3123   0.9210  0.1341  0.2521  0.0051  0.5490  0.4261   98,125   98,125   98,125  1 to 14 turns left
     3.8660   3.3290  0.2827  0.2521  0.0022  1.4019  1.1353   98,125   98,125   98,125  14 to 27 turns left
     6.8314   6.2631  0.3148  0.2521  0.0013  1.7805  1.5090   98,125   98,125   98,125  27 to 40 turns left
    10.8014  10.2388  0.3098  0.2521  0.0007  2.0397  1.8120   98,125   98,125   98,125  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7102   5.1949   0.2610   0.2521   0.0022   1.2206   1.4438
       5.6590   5.1485   0.2599   0.2481   0.0024   1.2206   1.4710
    
    Launching a checkpoint evaluation
    
      Average reward: +1.08 (win rate of 104%, network replaced), redundancy: 1.4%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.22 (win rate of 39%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +2.30 (win rate of 165%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -1.81 (win rate of -40%), redundancy: 1.0%

Starting iteration 37

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.6
    MCTS memory footprint: 78.74MB
    Experience buffer size: 398,000 (398,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7255   5.2177  0.2574  0.2481  0.0023  1.4693  1.2122  398,000  398,000  398,000  all samples
     5.9130   5.4157  0.2469  0.2481  0.0023  1.4752  1.1561   52,000   52,000   52,000  latest batch
     1.3064   0.9213  0.1318  0.2481  0.0052  0.5582  0.4256   99,500   99,500   99,500  1 to 14 turns left
     3.9256   3.3921  0.2833  0.2481  0.0021  1.4239  1.1271   99,500   99,500   99,500  14 to 27 turns left
     6.8932   6.3324  0.3114  0.2481  0.0012  1.8124  1.4976   99,500   99,500   99,500  27 to 40 turns left
    10.7804  10.2283  0.3032  0.2481  0.0008  2.0826  1.7985   99,500   99,500   99,500  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7317   5.2209   0.2603   0.2481   0.0024   1.2122   1.4714
       5.6864   5.1750   0.2622   0.2465   0.0027   1.2122   1.4811
    
    Launching a checkpoint evaluation
    
      Average reward: +0.07 (win rate of 54%), redundancy: 1.4%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.39 (win rate of 30%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +2.32 (win rate of 166%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -1.91 (win rate of -45%), redundancy: 1.0%

Starting iteration 38

  Starting self-play
  
    Time spent on inference: 55%
    Generating 5 samples per second on average
    Average exploration depth: 5.6
    MCTS memory footprint: 78.98MB
    Experience buffer size: 403,500 (403,500 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7349   5.2212  0.2646  0.2465  0.0026  1.4805  1.2044  403,500  403,500  403,500  all samples
     6.3782   5.8500  0.2791  0.2465  0.0026  1.4831  1.1604   52,000   52,000   52,000  latest batch
     1.3152   0.9294  0.1335  0.2465  0.0058  0.5618  0.4250  100,875  100,875  100,875  1 to 14 turns left
     3.9258   3.3876  0.2892  0.2465  0.0025  1.4275  1.1190  100,875  100,875  100,875  14 to 27 turns left
     6.9396   6.3716  0.3200  0.2465  0.0014  1.8196  1.4875  100,875  100,875  100,875  27 to 40 turns left
    10.7600  10.1970  0.3158  0.2465  0.0007  2.1130  1.7861  100,875  100,875  100,875  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7399   5.2258   0.2648   0.2465   0.0027   1.2044   1.4814
       5.6654   5.1588   0.2600   0.2443   0.0022   1.2044   1.4694
    
    Launching a checkpoint evaluation
    
      Average reward: +0.11 (win rate of 56%), redundancy: 1.4%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.46 (win rate of 27%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +2.25 (win rate of 162%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -2.05 (win rate of -52%), redundancy: 1.0%

Starting iteration 39

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.6
    MCTS memory footprint: 78.78MB
    Experience buffer size: 409,000 (409,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7335   5.2253  0.2617  0.2443  0.0022  1.4699  1.1964  409,000  409,000  409,000  all samples
     6.2290   5.7095  0.2729  0.2443  0.0022  1.4713  1.1563   52,000   52,000   52,000  latest batch
     1.3110   0.9313  0.1305  0.2443  0.0048  0.5594  0.4247  102,250  102,250  102,250  1 to 14 turns left
     3.9246   3.3908  0.2874  0.2443  0.0021  1.4112  1.1106  102,250  102,250  102,250  14 to 27 turns left
     6.9522   6.3898  0.3168  0.2443  0.0012  1.8053  1.4763  102,250  102,250  102,250  27 to 40 turns left
    10.7461  10.1890  0.3121  0.2443  0.0007  2.1036  1.7741  102,250  102,250  102,250  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7373   5.2287   0.2620   0.2443   0.0022   1.1964   1.4695
       5.6983   5.1899   0.2619   0.2442   0.0023   1.1964   1.4277
    
    Launching a checkpoint evaluation
    
      Average reward: -0.03 (win rate of 48%), redundancy: 1.4%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.29 (win rate of 36%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +2.41 (win rate of 170%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -1.78 (win rate of -39%), redundancy: 1.0%

Starting iteration 40

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.6
    MCTS memory footprint: 78.85MB
    Experience buffer size: 414,500 (414,500 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7687   5.2604  0.2617  0.2442  0.0023  1.4272  1.1888  414,500  414,500  414,500  all samples
     6.2755   5.7660  0.2630  0.2442  0.0023  1.4293  1.1583   52,000   52,000   52,000  latest batch
     1.3043   0.9247  0.1304  0.2442  0.0051  0.5594  0.4241  103,625  103,625  103,625  1 to 14 turns left
     3.9406   3.4059  0.2883  0.2442  0.0023  1.3876  1.1029  103,625  103,625  103,625  14 to 27 turns left
     7.0438   6.4787  0.3196  0.2442  0.0013  1.7462  1.4659  103,625  103,625  103,625  27 to 40 turns left
    10.7821  10.2285  0.3088  0.2442  0.0007  2.0154  1.7622  103,625  103,625  103,625  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7725   5.2635   0.2625   0.2442   0.0023   1.1888   1.4281
       5.7216   5.2192   0.2595   0.2405   0.0023   1.1888   1.4338
    
    Launching a checkpoint evaluation
    
      Average reward: +0.18 (win rate of 59%), redundancy: 1.5%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.39 (win rate of 30%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +2.23 (win rate of 162%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -2.27 (win rate of -64%), redundancy: 1.0%
