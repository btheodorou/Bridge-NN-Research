
Initializing a new AlphaZero environment

  Initial report
  
    Number of network parameters: 6,906,421
    Number of regularized network parameters: 6,906,240
    Memory footprint per MCTS node: 3736 bytes
  
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.87 (win rate of -44%), redundancy: 0.0%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +0.61 (win rate of 80%), redundancy: 0.0%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.74 (win rate of -187%), redundancy: 0.0%

Starting iteration 1

  Starting self-play
  
    Time spent on inference: 56%
    Generating 6 samples per second on average
    Average exploration depth: 5.1
    MCTS memory footprint: 78.64MB
    Experience buffer size: 52,000 (52,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp    Wtot      Nb      Ns
    13.0250  11.2888  0.3900  0.4570  0.8892  1.6520  1.2894  52,000  52,000  52,000  all samples
    13.0245  11.2881  0.3901  0.4570  0.8892  1.6521  1.2894  52,000  52,000  52,000  latest batch
     4.8596   3.2007  0.2214  0.4570  0.9804  0.6095  0.4235  13,000  13,000  13,000  1 to 13 turns left
     9.5041   7.6911  0.4219  0.4570  0.9341  1.5678  1.1958  13,000  13,000  13,000  14 to 26 turns left
    16.1233  14.3582  0.4441  0.4570  0.8641  2.0465  1.6387  13,000  13,000  13,000  27 to 39 turns left
    21.6243  19.9155  0.4736  0.4570  0.7783  2.3850  1.8996  13,000  13,000  13,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
      12.8936  10.8544   0.7099   0.4570   0.8722   1.2894   1.4693
      12.6976  11.5199   0.5203   0.3967   0.2608   1.2894   1.4489
    
    Launching a checkpoint evaluation
    
      Average reward: -1.27 (win rate of -14%), redundancy: 0.0%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.75 (win rate of -38%), redundancy: 0.0%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +0.26 (win rate of 63%), redundancy: 0.0%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.86 (win rate of -193%), redundancy: 0.0%

Starting iteration 2

  Starting self-play
  
    Time spent on inference: 56%
    Generating 6 samples per second on average
    Average exploration depth: 5.1
    MCTS memory footprint: 78.67MB
    Experience buffer size: 104,000 (104,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
    12.4136  11.2191  0.5408  0.3967  0.2570  1.4583  1.2897  104,000  104,000  104,000  all samples
    12.1229  10.9175  0.5530  0.3967  0.2557  1.4592  1.2899   52,000   52,000   52,000  latest batch
     4.5006   3.1981  0.3219  0.3967  0.5839  0.5596  0.4205   26,000   26,000   26,000  1 to 13 turns left
     8.9580   7.7552  0.5827  0.3967  0.2233  1.4161  1.1952   26,000   26,000   26,000  14 to 26 turns left
    15.1156  13.9859  0.6054  0.3967  0.1277  1.7970  1.6427   26,000   26,000   26,000  27 to 39 turns left
    21.0652  19.9223  0.6533  0.3967  0.0929  2.0607  1.9002   26,000   26,000   26,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
      12.4078  11.2186   0.5326   0.3967   0.2600   1.2897   1.4504
      11.8102  11.2178   0.3157   0.2608   0.0159   1.2897   1.5648
    
    Launching a checkpoint evaluation
    
      Average reward: -1.61 (win rate of -31%), redundancy: 0.0%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.89 (win rate of -44%), redundancy: 0.0%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.01 (win rate of 100%), redundancy: 0.0%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -5.02 (win rate of -201%), redundancy: 0.0%

Starting iteration 3

  Starting self-play
  

Loading environment

  Loading network from: sessions/double-dummy-full-state/bestnn.data
  Loading network from: sessions/double-dummy-full-state/curnn.data
  Loading memory from: sessions/double-dummy-full-state/mem.data
  Loaded iteration counter from: sessions/double-dummy-full-state/iter.txt

Starting iteration 3

  Starting self-play
  

Loading environment

  Loading network from: sessions/double-dummy-full-state/bestnn.data
  Loading network from: sessions/double-dummy-full-state/curnn.data
  Loading memory from: sessions/double-dummy-full-state/mem.data
  Loaded iteration counter from: sessions/double-dummy-full-state/iter.txt

Starting iteration 3

  Starting self-play
  
    Time spent on inference: 55%
    Generating 6 samples per second on average
    Average exploration depth: 5.1
    MCTS memory footprint: 78.86MB
    Experience buffer size: 156,000 (156,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
    11.8908  11.2978  0.3153  0.2608  0.0168  1.5641  1.2903  156,000  156,000  156,000  all samples
    12.0535  11.4508  0.3254  0.2608  0.0165  1.5614  1.2917   52,000   52,000   52,000  latest batch
     3.7557   3.2514  0.2225  0.2608  0.0210  0.6102  0.4209   39,000   39,000   39,000  1 to 13 turns left
     8.2634   7.6284  0.3583  0.2608  0.0157  1.5136  1.1958   39,000   39,000   39,000  14 to 26 turns left
    14.6851  14.0786  0.3301  0.2608  0.0156  1.9194  1.6432   39,000   39,000   39,000  27 to 39 turns left
    20.8402  20.2137  0.3506  0.2608  0.0151  2.2132  1.9013   39,000   39,000   39,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
      11.8948  11.2973   0.3209   0.2608   0.0157   1.2903   1.5638
       8.3336   7.8042   0.3211   0.1943   0.0141   1.2903   1.5524
    
    Launching a checkpoint evaluation
    
      Average reward: +0.40 (win rate of 70%), redundancy: 1.2%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -2.06 (win rate of -53%), redundancy: 1.0%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +0.63 (win rate of 82%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.90 (win rate of -195%), redundancy: 1.0%

Starting iteration 4

  Starting self-play
  
    Time spent on inference: 56%
    Generating 6 samples per second on average
    Average exploration depth: 5.1
    MCTS memory footprint: 78.56MB
    Experience buffer size: 208,000 (208,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     8.2260   7.6966  0.3210  0.1943  0.0141  1.5508  1.2906  208,000  208,000  208,000  all samples
     7.9789   7.4421  0.3286  0.1943  0.0139  1.5515  1.2914   52,000   52,000   52,000  latest batch
     2.3824   1.9571  0.2177  0.1943  0.0134  0.6068  0.4218   52,000   52,000   52,000  1 to 13 turns left
     5.1261   4.5627  0.3546  0.1943  0.0145  1.5132  1.1955   52,000   52,000   52,000  14 to 26 turns left
    10.0226   9.4769  0.3369  0.1943  0.0145  1.9132  1.6439   52,000   52,000   52,000  27 to 39 turns left
    15.3766  14.7933  0.3752  0.1943  0.0138  2.1700  1.9012   52,000   52,000   52,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.2483   7.7165   0.3234   0.1943   0.0141   1.2906   1.5523
       7.9282   7.4247   0.2928   0.2035   0.0071   1.2906   1.5128
    
    Launching a checkpoint evaluation
    
      Average reward: +0.76 (win rate of 88%), redundancy: 1.2%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.35 (win rate of -18%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +0.37 (win rate of 68%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -5.82 (win rate of -241%), redundancy: 1.0%

Starting iteration 5

  Starting self-play
  
    Time spent on inference: 56%
    Generating 6 samples per second on average
    Average exploration depth: 5.1
    MCTS memory footprint: 78.89MB
    Experience buffer size: 232,000 (232,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     7.8857   7.3768  0.2974  0.2035  0.0079  1.5175  1.2903  232,000  232,000  232,000  all samples
     7.7873   7.2705  0.3057  0.2035  0.0076  1.5167  1.2888   52,000   52,000   52,000  latest batch
     2.0282   1.6057  0.2058  0.2035  0.0133  0.6038  0.4210   58,000   58,000   58,000  1 to 14 turns left
     4.8981   4.3629  0.3252  0.2035  0.0065  1.4902  1.1963   58,000   58,000   58,000  14 to 27 turns left
     9.6519   9.1358  0.3064  0.2035  0.0062  1.8594  1.6438   58,000   58,000   58,000  27 to 40 turns left
    14.9669  14.4051  0.3525  0.2035  0.0058  2.1167  1.9001   58,000   58,000   58,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       7.8800   7.3742   0.2953   0.2035   0.0070   1.2903   1.5123
       7.6782   7.2217   0.2854   0.1627   0.0083   1.2903   1.5731
    
    Launching a checkpoint evaluation
    
      Average reward: +0.82 (win rate of 91%), redundancy: 1.2%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.78 (win rate of -39%), redundancy: 1.0%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +0.72 (win rate of 86%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -5.58 (win rate of -229%), redundancy: 1.0%

Starting iteration 6

  Starting self-play
  
    Time spent on inference: 56%
    Generating 6 samples per second on average
    Average exploration depth: 5.1
    MCTS memory footprint: 78.92MB
    Experience buffer size: 240,000 (240,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     7.6491   7.1897  0.2881  0.1627  0.0086  1.5704  1.2895  240,000  240,000  240,000  all samples
     7.8473   7.3824  0.2938  0.1627  0.0084  1.5693  1.2862   52,000   52,000   52,000  latest batch
     1.7259   1.3619  0.1960  0.1627  0.0053  0.6139  0.4216   60,000   60,000   60,000  1 to 14 turns left
     4.6908   4.1999  0.3196  0.1627  0.0085  1.5282  1.1935   60,000   60,000   60,000  14 to 27 turns left
     9.3584   8.8903  0.2955  0.1627  0.0100  1.9253  1.6431   60,000   60,000   60,000  27 to 40 turns left
    14.8145  14.3002  0.3411  0.1627  0.0106  2.2140  1.8996   60,000   60,000   60,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       7.6547   7.1966   0.2871   0.1627   0.0083   1.2895   1.5729
       7.4871   7.0375   0.2730   0.1711   0.0055   1.2895   1.5338
    
    Launching a checkpoint evaluation
    
      Average reward: +0.74 (win rate of 87%), redundancy: 1.1%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.99 (win rate of -50%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +0.77 (win rate of 88%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.91 (win rate of -196%), redundancy: 1.0%

Starting iteration 7

  Starting self-play
  
    Time spent on inference: 56%
    Generating 6 samples per second on average
    Average exploration depth: 5.1
    MCTS memory footprint: 78.95MB
    Experience buffer size: 248,000 (248,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     7.5829   7.1334  0.2729  0.1711  0.0055  1.5349  1.2894  248,000  248,000  248,000  all samples
     8.1301   7.6740  0.2795  0.1711  0.0055  1.5343  1.2897   52,000   52,000   52,000  latest batch
     1.6471   1.2794  0.1924  0.1711  0.0042  0.6043  0.4218   62,000   62,000   62,000  1 to 14 turns left
     4.6309   4.1448  0.3090  0.1711  0.0059  1.4976  1.1941   62,000   62,000   62,000  14 to 27 turns left
     9.2864   8.8271  0.2819  0.1711  0.0063  1.8823  1.6433   62,000   62,000   62,000  27 to 40 turns left
    14.7687  14.2836  0.3084  0.1711  0.0055  2.1558  1.8982   62,000   62,000   62,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       7.5948   7.1432   0.2750   0.1711   0.0055   1.2894   1.5335
       7.4646   7.0026   0.2668   0.1902   0.0050   1.2894   1.5405
    
    Launching a checkpoint evaluation
    
      Average reward: +1.09 (win rate of 104%, network replaced), redundancy: 1.1%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.99 (win rate of 1%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.41 (win rate of 120%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -3.99 (win rate of -150%), redundancy: 1.0%

Starting iteration 8

  Starting self-play
  
    Time spent on inference: 55%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 78.90MB
    Experience buffer size: 256,000 (256,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     7.1752   6.7007  0.2791  0.1902  0.0051  1.5427  1.2743  256,000  256,000  256,000  all samples
     6.1332   5.6037  0.3343  0.1902  0.0051  1.5562  1.2171   52,000   52,000   52,000  latest batch
     1.5908   1.2182  0.1779  0.1902  0.0045  0.5981  0.4232   64,000   64,000   64,000  1 to 14 turns left
     4.4936   3.9851  0.3125  0.1902  0.0058  1.4932  1.1813   64,000   64,000   64,000  14 to 27 turns left
     8.7562   8.2578  0.3027  0.1902  0.0056  1.8979  1.6156   64,000   64,000   64,000  27 to 40 turns left
    13.8600  13.3419  0.3233  0.1902  0.0046  2.1815  1.8772   64,000   64,000   64,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       7.1878   6.7087   0.2840   0.1902   0.0049   1.2743   1.5428
       7.0072   6.5145   0.2810   0.2070   0.0047   1.2743   1.5372
    
    Launching a checkpoint evaluation
    
      Average reward: +0.14 (win rate of 57%), redundancy: 1.5%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.87 (win rate of 6%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.51 (win rate of 125%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -3.99 (win rate of -150%), redundancy: 1.0%

Starting iteration 9

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.17MB
    Experience buffer size: 264,000 (264,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     6.8040   6.2977  0.2947  0.2070  0.0045  1.5396  1.2609  264,000  264,000  264,000  all samples
     6.1568   5.5985  0.3469  0.2070  0.0044  1.5472  1.2198   52,000   52,000   52,000  latest batch
     1.5661   1.1757  0.1792  0.2070  0.0042  0.5925  0.4242   66,000   66,000   66,000  1 to 14 turns left
     4.3777   3.8413  0.3242  0.2070  0.0051  1.4860  1.1702   66,000   66,000   66,000  14 to 27 turns left
     8.2167   7.6782  0.3267  0.2070  0.0048  1.8938  1.5902   66,000   66,000   66,000  27 to 40 turns left
    13.0626  12.5029  0.3488  0.2070  0.0039  2.1859  1.8590   66,000   66,000   66,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       6.8169   6.3079   0.2973   0.2070   0.0046   1.2609   1.5389
       6.6945   6.1848   0.2892   0.2160   0.0045   1.2609   1.5273
    
    Launching a checkpoint evaluation
    
      Average reward: +0.08 (win rate of 54%), redundancy: 1.2%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.03 (win rate of -2%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.56 (win rate of 128%), redundancy: 1.4%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.15 (win rate of -158%), redundancy: 1.0%

Starting iteration 10

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.11MB
    Experience buffer size: 272,000 (272,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     6.5976   6.0764  0.3005  0.2160  0.0047  1.5319  1.2500  272,000  272,000  272,000  all samples
     6.4640   5.9115  0.3318  0.2160  0.0047  1.5389  1.2276   52,000   52,000   52,000  latest batch
     1.5615   1.1686  0.1727  0.2160  0.0042  0.5890  0.4260   68,000   68,000   68,000  1 to 14 turns left
     4.3431   3.7929  0.3291  0.2160  0.0051  1.4818  1.1607   68,000   68,000   68,000  14 to 27 turns left
     7.9692   7.4071  0.3412  0.2160  0.0049  1.8898  1.5692   68,000   68,000   68,000  27 to 40 turns left
    12.5177  11.9381  0.3592  0.2160  0.0044  2.1671  1.8439   68,000   68,000   68,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       6.5955   6.0739   0.3011   0.2160   0.0045   1.2500   1.5288
       6.4293   5.9099   0.2907   0.2250   0.0036   1.2500   1.5154
    
    Launching a checkpoint evaluation
    
      Average reward: +0.32 (win rate of 66%), redundancy: 1.4%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.02 (win rate of -1%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.43 (win rate of 121%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -3.96 (win rate of -148%), redundancy: 1.0%

Starting iteration 11

  Starting self-play
  
    Time spent on inference: 55%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 78.88MB
    Experience buffer size: 280,000 (280,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     6.3200   5.7881  0.3033  0.2250  0.0036  1.5169  1.2380  280,000  280,000  280,000  all samples
     6.4170   5.8639  0.3245  0.2250  0.0036  1.5185  1.2174   52,000   52,000   52,000  latest batch
     1.5331   1.1397  0.1642  0.2250  0.0041  0.5869  0.4266   70,000   70,000   70,000  1 to 14 turns left
     4.2132   3.6574  0.3268  0.2250  0.0039  1.4652  1.1509   70,000   70,000   70,000  14 to 27 turns left
     7.6316   7.0522  0.3510  0.2250  0.0034  1.8624  1.5468   70,000   70,000   70,000  27 to 40 turns left
    11.8975  11.2983  0.3713  0.2250  0.0030  2.1534  1.8276   70,000   70,000   70,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       6.3012   5.7724   0.3003   0.2250   0.0035   1.2380   1.5168
       6.1074   5.5683   0.2957   0.2399   0.0036   1.2380   1.5031
    
    Launching a checkpoint evaluation
    
      Average reward: +0.34 (win rate of 67%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.48 (win rate of 26%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.35 (win rate of 118%), redundancy: 1.4%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.14 (win rate of -157%), redundancy: 1.0%

Starting iteration 12

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.10MB
    Experience buffer size: 288,000 (288,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.9924   5.4472  0.3018  0.2399  0.0034  1.5042  1.2268  288,000  288,000  288,000  all samples
     6.2955   5.7406  0.3117  0.2399  0.0034  1.5056  1.2201   52,000   52,000   52,000  latest batch
     1.5159   1.1112  0.1600  0.2399  0.0047  0.5802  0.4269   72,000   72,000   72,000  1 to 14 turns left
     4.1033   3.5328  0.3269  0.2399  0.0037  1.4607  1.1413   72,000   72,000   72,000  14 to 27 turns left
     7.1611   6.5634  0.3549  0.2399  0.0029  1.8557  1.5248   72,000   72,000   72,000  27 to 40 turns left
    11.1861  10.5784  0.3653  0.2399  0.0025  2.1201  1.8142   72,000   72,000   72,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.9966   5.4507   0.3025   0.2399   0.0035   1.2268   1.5043
       5.8329   5.2900   0.2922   0.2470   0.0037   1.2268   1.4765
    
    Launching a checkpoint evaluation
    
      Average reward: +0.32 (win rate of 66%), redundancy: 1.4%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.95 (win rate of 3%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.33 (win rate of 116%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.06 (win rate of -153%), redundancy: 1.0%

Starting iteration 13

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.13MB
    Experience buffer size: 296,000 (296,000 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7256  5.1794  0.2954  0.2470  0.0038  1.4773  1.2207  296,000  296,000  296,000  all samples
     6.1302  5.5760  0.3035  0.2470  0.0037  1.4770  1.2214   52,000   52,000   52,000  latest batch
     1.5040  1.0997  0.1521  0.2470  0.0052  0.5754  0.4270   74,000   74,000   74,000  1 to 14 turns left
     3.9853  3.4168  0.3180  0.2470  0.0035  1.4415  1.1354   74,000   74,000   74,000  14 to 27 turns left
     6.8274  6.2241  0.3532  0.2470  0.0031  1.8212  1.5135   74,000   74,000   74,000  27 to 40 turns left
    10.5876  9.9789  0.3584  0.2470  0.0032  2.0712  1.8070   74,000   74,000   74,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7376   5.1914   0.2955   0.2470   0.0037   1.2207   1.4776

Loading environment

  Loading network from: sessions/double-dummy-full-state/bestnn.data
  Loading network from: sessions/double-dummy-full-state/curnn.data
  Loading memory from: sessions/double-dummy-full-state/mem.data
  Loaded iteration counter from: sessions/double-dummy-full-state/iter.txt

Starting iteration 13

  Starting self-play
  
    Time spent on inference: 55%
    Generating 6 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.18MB
    Experience buffer size: 296,000 (296,000 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.6926  5.1460  0.2957  0.2470  0.0038  1.4770  1.2200  296,000  296,000  296,000  all samples
     5.9419  5.3857  0.3054  0.2470  0.0039  1.4753  1.2172   52,000   52,000   52,000  latest batch
     1.5093  1.1055  0.1515  0.2470  0.0052  0.5755  0.4279   74,000   74,000   74,000  1 to 14 turns left
     3.9670  3.3980  0.3185  0.2470  0.0035  1.4423  1.1347   74,000   74,000   74,000  14 to 27 turns left
     6.7805  6.1760  0.3544  0.2470  0.0032  1.8209  1.5120   74,000   74,000   74,000  27 to 40 turns left
    10.5136  9.9048  0.3584  0.2470  0.0033  2.0694  1.8053   74,000   74,000   74,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7002   5.1541   0.2955   0.2470   0.0037   1.2200   1.4770
       5.6997   5.1112   0.2969   0.2877   0.0039   1.2200   1.5082
    
    Launching a checkpoint evaluation
    
      Average reward: +0.56 (win rate of 78%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.84 (win rate of 8%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.10 (win rate of 105%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.26 (win rate of -163%), redundancy: 1.0%

Starting iteration 14

  Starting self-play
  
    Time spent on inference: 57%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.14MB
    Experience buffer size: 304,000 (304,000 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7530  5.1623  0.2991  0.2877  0.0038  1.5076  1.2200  304,000  304,000  304,000  all samples
     6.0937  5.4941  0.3082  0.2877  0.0038  1.5070  1.2176   52,000   52,000   52,000  latest batch
     1.5857  1.1368  0.1535  0.2877  0.0077  0.5853  0.4281   76,000   76,000   76,000  1 to 14 turns left
     4.0469  3.4282  0.3272  0.2877  0.0038  1.4688  1.1332   76,000   76,000   76,000  14 to 27 turns left
     6.7736  6.1239  0.3596  0.2877  0.0024  1.8565  1.5113   76,000   76,000   76,000  27 to 40 turns left
    10.6068  9.9616  0.3561  0.2877  0.0015  2.1197  1.8075   76,000   76,000   76,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7597   5.1693   0.2989   0.2877   0.0039   1.2200   1.5084
       5.5792   4.9879   0.2893   0.2981   0.0039   1.2200   1.4937
    
    Launching a checkpoint evaluation
    
      Average reward: +0.48 (win rate of 74%), redundancy: 1.4%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.06 (win rate of -3%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.50 (win rate of 125%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.06 (win rate of -153%), redundancy: 1.0%

Starting iteration 15

  Starting self-play
  
    Time spent on inference: 57%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 78.96MB
    Experience buffer size: 312,000 (312,000 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7035  5.1115  0.2898  0.2981  0.0040  1.4939  1.2201  312,000  312,000  312,000  all samples
     6.1781  5.5839  0.2920  0.2981  0.0040  1.4946  1.2205   52,000   52,000   52,000  latest batch
     1.5252  1.0671  0.1518  0.2981  0.0082  0.5821  0.4272   78,000   78,000   78,000  1 to 13 turns left
     3.9779  3.3592  0.3167  0.2981  0.0039  1.4554  1.1332   78,000   78,000   78,000  14 to 26 turns left
     6.7326  6.0844  0.3476  0.2981  0.0025  1.8408  1.5119   78,000   78,000   78,000  27 to 39 turns left
    10.5763  9.9335  0.3430  0.2981  0.0016  2.0973  1.8081   78,000   78,000   78,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7070   5.1148   0.2902   0.2981   0.0039   1.2201   1.4937
       5.6819   5.0775   0.2865   0.3147   0.0032   1.2201   1.4998
    
    Launching a checkpoint evaluation
    
      Average reward: +0.66 (win rate of 83%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.08 (win rate of -4%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.21 (win rate of 110%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -3.86 (win rate of -143%), redundancy: 1.0%

Starting iteration 16

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.12MB
    Experience buffer size: 320,000 (320,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.8191   5.2132  0.2880  0.3147  0.0032  1.5003  1.2189  320,000  320,000  320,000  all samples
     6.6108   5.9982  0.2946  0.3147  0.0032  1.5002  1.2190   52,000   52,000   52,000  latest batch
     1.5778   1.1052  0.1512  0.3147  0.0067  0.5778  0.4271   80,000   80,000   80,000  1 to 14 turns left
     4.0566   3.4238  0.3151  0.3147  0.0030  1.4529  1.1312   80,000   80,000   80,000  14 to 27 turns left
     6.8623   6.1992  0.3466  0.3147  0.0018  1.8467  1.5101   80,000   80,000   80,000  27 to 40 turns left
    10.7796  10.1243  0.3393  0.3147  0.0013  2.1237  1.8073   80,000   80,000   80,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.8270   5.2212   0.2879   0.3147   0.0032   1.2189   1.4994

Loading environment

  Loading network from: sessions/double-dummy-full-state/bestnn.data
  Loading network from: sessions/double-dummy-full-state/curnn.data
  Loading memory from: sessions/double-dummy-full-state/mem.data
  Loaded iteration counter from: sessions/double-dummy-full-state/iter.txt

Starting iteration 16

  Starting self-play
  
    Time spent on inference: 55%
    Generating 6 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 78.88MB
    Experience buffer size: 282,500 (282,500 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.8006   5.1943  0.2885  0.3147  0.0032  1.5007  1.2197  282,500  282,500  282,500  all samples
     6.4410   5.8296  0.2936  0.3147  0.0031  1.5028  1.2243   52,000   52,000   52,000  latest batch
     1.5648   1.0921  0.1513  0.3147  0.0067  0.5777  0.4269   70,625   70,625   70,625  1 to 14 turns left
     4.0605   3.4279  0.3150  0.3147  0.0029  1.4532  1.1334   70,625   70,625   70,625  14 to 27 turns left
     6.7949   6.1288  0.3496  0.3147  0.0018  1.8469  1.5089   70,625   70,625   70,625  27 to 40 turns left
    10.7740  10.1198  0.3382  0.3147  0.0013  2.1246  1.8094   70,625   70,625   70,625  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.8117   5.2055   0.2883   0.3147   0.0032   1.2197   1.4999
       5.8267   5.1607   0.2954   0.3666   0.0040   1.2197   1.5174
    
    Launching a checkpoint evaluation
    
      Average reward: +0.88 (win rate of 94%), redundancy: 1.4%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.94 (win rate of 3%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.58 (win rate of 129%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.10 (win rate of -155%), redundancy: 1.0%

Starting iteration 17

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 78.75MB
    Experience buffer size: 288,000 (288,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.8969   5.2303  0.2960  0.3666  0.0039  1.5174  1.2198  288,000  288,000  288,000  all samples
     6.2616   5.5887  0.3024  0.3666  0.0039  1.5166  1.2176   52,000   52,000   52,000  latest batch
     1.5928   1.0607  0.1570  0.3667  0.0085  0.5867  0.4272   72,000   72,000   72,000  1 to 14 turns left
     4.1090   3.4176  0.3213  0.3667  0.0035  1.4726  1.1338   72,000   72,000   72,000  14 to 27 turns left
     6.9672   6.2411  0.3572  0.3667  0.0022  1.8641  1.5085   72,000   72,000   72,000  27 to 40 turns left
    10.9197  10.2032  0.3482  0.3667  0.0016  2.1461  1.8098   72,000   72,000   72,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.9076   5.2406   0.2964   0.3666   0.0040   1.2198   1.5174
       5.8377   5.1760   0.2938   0.3640   0.0039   1.2198   1.5033
    
    Launching a checkpoint evaluation
    
      Average reward: +0.72 (win rate of 86%), redundancy: 1.4%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.99 (win rate of 1%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.26 (win rate of 113%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.12 (win rate of -156%), redundancy: 1.0%

Starting iteration 18

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.40MB
    Experience buffer size: 293,500 (293,500 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.8967   5.2325  0.2957  0.3640  0.0044  1.5030  1.2199  293,500  293,500  293,500  all samples
     6.2301   5.5632  0.2985  0.3640  0.0044  1.5032  1.2208   52,000   52,000   52,000  latest batch
     1.5904   1.0616  0.1561  0.3640  0.0087  0.5823  0.4276   73,375   73,375   73,375  1 to 14 turns left
     4.1016   3.4131  0.3206  0.3640  0.0038  1.4562  1.1336   73,375   73,375   73,375  14 to 27 turns left
     6.9112   6.1880  0.3563  0.3640  0.0029  1.8435  1.5089   73,375   73,375   73,375  27 to 40 turns left
    10.9805  10.2644  0.3498  0.3640  0.0022  2.1300  1.8094   73,375   73,375   73,375  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.8989   5.2364   0.2945   0.3640   0.0039   1.2199   1.5035
       5.7058   5.0766   0.2930   0.3284   0.0078   1.2199   1.4917
    
    Launching a checkpoint evaluation
    
      Average reward: +0.59 (win rate of 80%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.84 (win rate of 8%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.68 (win rate of 134%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.15 (win rate of -158%), redundancy: 1.0%

Starting iteration 19

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.21MB
    Experience buffer size: 299,000 (299,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7903   5.1602  0.2940  0.3284  0.0077  1.4906  1.2201  299,000  299,000  299,000  all samples
     5.8471   5.2112  0.3000  0.3284  0.0075  1.4911  1.2188   52,000   52,000   52,000  latest batch
     1.5366   1.0306  0.1589  0.3284  0.0187  0.5784  0.4279   74,750   74,750   74,750  1 to 13 turns left
     4.0207   3.3647  0.3215  0.3284  0.0061  1.4461  1.1344   74,750   74,750   74,750  14 to 26 turns left
     6.8190   6.1332  0.3536  0.3284  0.0036  1.8315  1.5073   74,750   74,750   74,750  27 to 39 turns left
    10.7830  10.1108  0.3415  0.3284  0.0023  2.1063  1.8106   74,750   74,750   74,750  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7925   5.1625   0.2937   0.3284   0.0078   1.2201   1.4919
       5.6455   5.0454   0.2846   0.3121   0.0035   1.2201   1.4977
    
    Launching a checkpoint evaluation
    
      Average reward: +0.78 (win rate of 89%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.89 (win rate of 5%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.28 (win rate of 114%), redundancy: 1.4%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.25 (win rate of -162%), redundancy: 1.0%

Starting iteration 20

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 78.97MB
    Experience buffer size: 304,500 (304,500 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.8045   5.2044  0.2841  0.3121  0.0038  1.4941  1.2208  304,500  304,500  304,500  all samples
     6.4973   5.8942  0.2872  0.3121  0.0038  1.4925  1.2217   52,000   52,000   52,000  latest batch
     1.4897   1.0183  0.1503  0.3121  0.0090  0.5816  0.4284   76,125   76,125   76,125  1 to 14 turns left
     3.9946   3.3693  0.3099  0.3121  0.0032  1.4521  1.1362   76,125   76,125   76,125  14 to 27 turns left
     6.8622   6.2033  0.3448  0.3121  0.0020  1.8321  1.5076   76,125   76,125   76,125  27 to 40 turns left
    10.8787  10.2340  0.3313  0.3121  0.0012  2.1105  1.8111   76,125   76,125   76,125  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.8047   5.2043   0.2848   0.3121   0.0035   1.2208   1.4978
       5.7070   5.1243   0.2807   0.2989   0.0031   1.2208   1.4707
    
    Launching a checkpoint evaluation
    
      Average reward: +0.95 (win rate of 98%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.95 (win rate of 3%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.40 (win rate of 120%), redundancy: 1.4%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.07 (win rate of -154%), redundancy: 1.0%

Starting iteration 21

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.13MB
    Experience buffer size: 310,000 (310,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.8597   5.2761  0.2814  0.2989  0.0034  1.4704  1.2204  310,000  310,000  310,000  all samples
     6.5316   5.9427  0.2866  0.2989  0.0034  1.4690  1.2200   52,000   52,000   52,000  latest batch
     1.4578   1.0032  0.1483  0.2989  0.0074  0.5612  0.4287   77,500   77,500   77,500  1 to 14 turns left
     4.0253   3.4173  0.3061  0.2989  0.0031  1.4186  1.1355   77,500   77,500   77,500  14 to 27 turns left
     6.9707   6.3299  0.3400  0.2989  0.0019  1.8162  1.5068   77,500   77,500   77,500  27 to 40 turns left
    10.9846  10.3533  0.3312  0.2989  0.0012  2.0853  1.8106   77,500   77,500   77,500  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.8669   5.2828   0.2821   0.2989   0.0031   1.2204   1.4707
       5.7475   5.1728   0.2788   0.2931   0.0027   1.2204   1.4955
    
    Launching a checkpoint evaluation
    
      Average reward: +0.86 (win rate of 93%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.10 (win rate of -5%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.35 (win rate of 118%), redundancy: 1.4%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.13 (win rate of -156%), redundancy: 1.1%

Starting iteration 22

  Starting self-play
  
    Time spent on inference: 55%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 78.66MB
    Experience buffer size: 315,500 (315,500 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7765   5.2015  0.2791  0.2931  0.0028  1.4967  1.2199  315,500  315,500  315,500  all samples
     6.0080   5.4279  0.2841  0.2931  0.0028  1.4977  1.2194   52,000   52,000   52,000  latest batch
     1.4394   0.9942  0.1463  0.2931  0.0058  0.5761  0.4282   78,875   78,875   78,875  1 to 14 turns left
     3.9721   3.3718  0.3046  0.2931  0.0025  1.4478  1.1346   78,875   78,875   78,875  14 to 27 turns left
     6.8506   6.2195  0.3363  0.2931  0.0016  1.8382  1.5069   78,875   78,875   78,875  27 to 40 turns left
    10.8458  10.2222  0.3291  0.2931  0.0013  2.1248  1.8098   78,875   78,875   78,875  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7831   5.2074   0.2798   0.2931   0.0027   1.2199   1.4952
       5.6939   5.1262   0.2768   0.2883   0.0027   1.2199   1.4800
    
    Launching a checkpoint evaluation
    
      Average reward: +0.68 (win rate of 84%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.95 (win rate of 3%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.16 (win rate of 108%), redundancy: 1.4%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.20 (win rate of -160%), redundancy: 1.0%

Starting iteration 23

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 78.96MB
    Experience buffer size: 321,000 (321,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.8084   5.2385  0.2790  0.2883  0.0027  1.4785  1.2208  321,000  321,000  321,000  all samples
     6.3385   5.7622  0.2853  0.2883  0.0027  1.4807  1.2248   52,000   52,000   52,000  latest batch
     1.4208   0.9814  0.1455  0.2883  0.0055  0.5634  0.4283   80,250   80,250   80,250  1 to 14 turns left
     3.9947   3.4012  0.3028  0.2883  0.0024  1.4251  1.1345   80,250   80,250   80,250  14 to 27 turns left
     6.8938   6.2686  0.3353  0.2883  0.0017  1.8164  1.5086   80,250   80,250   80,250  27 to 40 turns left
    10.9255  10.3033  0.3326  0.2883  0.0014  2.1092  1.8118   80,250   80,250   80,250  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.8063   5.2378   0.2776   0.2883   0.0027   1.2208   1.4802
       5.7229   5.1580   0.2772   0.2847   0.0029   1.2208   1.4876
    
    Launching a checkpoint evaluation
    
      Average reward: +0.91 (win rate of 96%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.92 (win rate of 4%), redundancy: 1.3%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.13 (win rate of 106%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.35 (win rate of -167%), redundancy: 1.0%

Starting iteration 24

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 78.80MB
    Experience buffer size: 326,500 (326,500 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.8353   5.2682  0.2797  0.2847  0.0027  1.4865  1.2205  326,500  326,500  326,500  all samples
     6.1752   5.6001  0.2876  0.2847  0.0028  1.4880  1.2186   52,000   52,000   52,000  latest batch
     1.4081   0.9725  0.1452  0.2847  0.0057  0.5685  0.4283   81,625   81,625   81,625  1 to 14 turns left
     3.9943   3.4014  0.3058  0.2847  0.0024  1.4394  1.1337   81,625   81,625   81,625  14 to 27 turns left
     6.9390   6.3142  0.3384  0.2847  0.0016  1.8403  1.5091   81,625   81,625   81,625  27 to 40 turns left
    10.9961  10.3810  0.3292  0.2847  0.0011  2.0979  1.8110   81,625   81,625   81,625  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.8404   5.2739   0.2788   0.2847   0.0030   1.2205   1.4880
       5.7375   5.1834   0.2742   0.2775   0.0024   1.2205   1.4874
    
    Launching a checkpoint evaluation
    
      Average reward: +0.66 (win rate of 83%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.76 (win rate of 12%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.13 (win rate of 106%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.12 (win rate of -156%), redundancy: 1.0%

Starting iteration 25

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 78.97MB
    Experience buffer size: 332,000 (332,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7948   5.2406  0.2742  0.2775  0.0024  1.4897  1.2205  332,000  332,000  332,000  all samples
     6.1054   5.5450  0.2804  0.2775  0.0024  1.4897  1.2199   52,000   52,000   52,000  latest batch
     1.3950   0.9663  0.1460  0.2775  0.0052  0.5759  0.4275   83,000   83,000   83,000  1 to 14 turns left
     3.9972   3.4179  0.2994  0.2775  0.0023  1.4500  1.1348   83,000   83,000   83,000  14 to 27 turns left
     6.9367   6.3265  0.3313  0.2775  0.0014  1.8344  1.5098   83,000   83,000   83,000  27 to 40 turns left
    10.8480  10.2492  0.3205  0.2775  0.0008  2.0988  1.8098   83,000   83,000   83,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.8015   5.2461   0.2755   0.2775   0.0024   1.2205   1.4872
       5.7413   5.1880   0.2768   0.2741   0.0024   1.2205   1.4520
    
    Launching a checkpoint evaluation
    
      Average reward: +0.36 (win rate of 68%), redundancy: 1.4%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.99 (win rate of 1%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.37 (win rate of 118%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.05 (win rate of -152%), redundancy: 1.0%

Starting iteration 26

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.02MB
    Experience buffer size: 337,500 (337,500 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.8188   5.2650  0.2773  0.2741  0.0025  1.4534  1.2207  337,500  337,500  337,500  all samples
     6.1554   5.5965  0.2824  0.2741  0.0025  1.4501  1.2201   52,000   52,000   52,000  latest batch
     1.3833   0.9571  0.1469  0.2741  0.0052  0.5670  0.4278   84,375   84,375   84,375  1 to 14 turns left
     3.9834   3.4054  0.3016  0.2741  0.0024  1.4118  1.1343   84,375   84,375   84,375  14 to 27 turns left
     6.9691   6.3591  0.3345  0.2741  0.0015  1.7854  1.5105   84,375   84,375   84,375  27 to 40 turns left
    10.9400  10.3393  0.3258  0.2741  0.0009  2.0492  1.8101   84,375   84,375   84,375  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.8326   5.2783   0.2778   0.2741   0.0024   1.2207   1.4519
       5.7268   5.1817   0.2699   0.2724   0.0028   1.2207   1.4782
    
    Launching a checkpoint evaluation
    
      Average reward: +0.56 (win rate of 78%), redundancy: 1.2%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.19 (win rate of -9%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.27 (win rate of 114%), redundancy: 1.4%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.22 (win rate of -161%), redundancy: 1.0%

Starting iteration 27

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.01MB
    Experience buffer size: 343,000 (343,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7644   5.2169  0.2722  0.2724  0.0029  1.4778  1.2206  343,000  343,000  343,000  all samples
     6.0658   5.5121  0.2783  0.2724  0.0029  1.4801  1.2217   52,000   52,000   52,000  latest batch
     1.3941   0.9711  0.1445  0.2724  0.0060  0.5615  0.4270   85,750   85,750   85,750  1 to 14 turns left
     3.9613   3.3874  0.2989  0.2724  0.0026  1.4226  1.1339   85,750   85,750   85,750  14 to 27 turns left
     6.8914   6.2895  0.3277  0.2724  0.0018  1.8170  1.5112   85,750   85,750   85,750  27 to 40 turns left
    10.8059  10.2149  0.3174  0.2724  0.0012  2.1100  1.8105   85,750   85,750   85,750  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7676   5.2207   0.2717   0.2724   0.0028   1.2206   1.4787
       5.6966   5.1528   0.2705   0.2705   0.0028   1.2206   1.4917
    
    Launching a checkpoint evaluation
    
      Average reward: +0.82 (win rate of 91%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.02 (win rate of -1%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +0.79 (win rate of 90%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.09 (win rate of -154%), redundancy: 1.0%

Starting iteration 28

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.31MB
    Experience buffer size: 348,500 (348,500 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7499   5.2048  0.2720  0.2705  0.0027  1.4934  1.2208  348,500  348,500  348,500  all samples
     6.2809   5.7297  0.2780  0.2705  0.0027  1.4941  1.2216   52,000   52,000   52,000  latest batch
     1.3929   0.9734  0.1432  0.2705  0.0059  0.5762  0.4273   87,125   87,125   87,125  1 to 14 turns left
     3.9217   3.3505  0.2982  0.2705  0.0025  1.4437  1.1337   87,125   87,125   87,125  14 to 27 turns left
     6.8298   6.2305  0.3273  0.2705  0.0015  1.8316  1.5121   87,125   87,125   87,125  27 to 40 turns left
    10.8538  10.2633  0.3192  0.2705  0.0008  2.1221  1.8102   87,125   87,125   87,125  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7521   5.2072   0.2715   0.2705   0.0028   1.2208   1.4921
       5.6749   5.1357   0.2693   0.2676   0.0024   1.2208   1.4705
    
    Launching a checkpoint evaluation
    
      Average reward: +0.66 (win rate of 83%), redundancy: 1.2%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.02 (win rate of -1%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.24 (win rate of 112%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.19 (win rate of -160%), redundancy: 1.0%

Starting iteration 29

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.32MB
    Experience buffer size: 354,000 (354,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7459   5.2056  0.2702  0.2676  0.0025  1.4685  1.2207  354,000  354,000  354,000  all samples
     5.8587   5.3137  0.2748  0.2676  0.0025  1.4677  1.2186   52,000   52,000   52,000  latest batch
     1.3772   0.9601  0.1441  0.2676  0.0054  0.5660  0.4272   88,500   88,500   88,500  1 to 14 turns left
     3.9201   3.3558  0.2943  0.2676  0.0023  1.4169  1.1335   88,500   88,500   88,500  14 to 27 turns left
     6.8203   6.2269  0.3245  0.2676  0.0014  1.8036  1.5129   88,500   88,500   88,500  27 to 40 turns left
    10.8634  10.2774  0.3175  0.2676  0.0009  2.0874  1.8093   88,500   88,500   88,500  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7460   5.2058   0.2702   0.2676   0.0024   1.2207   1.4705
       5.6621   5.1223   0.2689   0.2684   0.0026   1.2207   1.4737
    
    Launching a checkpoint evaluation
    
      Average reward: +0.80 (win rate of 90%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.07 (win rate of -4%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.73 (win rate of 136%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -3.53 (win rate of -126%), redundancy: 1.0%

Starting iteration 30

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 78.90MB
    Experience buffer size: 359,500 (359,500 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7142   5.1734  0.2700  0.2684  0.0024  1.4719  1.2199  359,500  359,500  359,500  all samples
     6.3058   5.7604  0.2746  0.2684  0.0024  1.4704  1.2188   52,000   52,000   52,000  latest batch
     1.3656   0.9511  0.1410  0.2684  0.0051  0.5674  0.4274   89,875   89,875   89,875  1 to 14 turns left
     3.9347   3.3693  0.2947  0.2684  0.0023  1.4264  1.1338   89,875   89,875   89,875  14 to 27 turns left
     6.8327   6.2362  0.3268  0.2684  0.0014  1.8114  1.5123   89,875   89,875   89,875  27 to 40 turns left
    10.7238  10.1371  0.3175  0.2684  0.0008  2.0824  1.8061   89,875   89,875   89,875  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7186   5.1779   0.2698   0.2684   0.0026   1.2199   1.4735
       5.6505   5.1163   0.2654   0.2663   0.0025   1.2199   1.4708
    
    Launching a checkpoint evaluation
    
      Average reward: +0.81 (win rate of 90%), redundancy: 1.4%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.02 (win rate of -1%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.69 (win rate of 134%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.24 (win rate of -162%), redundancy: 1.0%

Starting iteration 31

  Starting self-play
  
    Time spent on inference: 57%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.04MB
    Experience buffer size: 365,000 (365,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7636   5.2300  0.2648  0.2663  0.0025  1.4702  1.2206  365,000  365,000  365,000  all samples
     6.3861   5.8505  0.2669  0.2663  0.0025  1.4718  1.2238   52,000   52,000   52,000  latest batch
     1.3568   0.9459  0.1392  0.2663  0.0053  0.5628  0.4274   91,250   91,250   91,250  1 to 14 turns left
     3.9534   3.3962  0.2886  0.2663  0.0023  1.4198  1.1348   91,250   91,250   91,250  14 to 27 turns left
     6.8762   6.2889  0.3196  0.2663  0.0014  1.8049  1.5119   91,250   91,250   91,250  27 to 40 turns left
    10.8632  10.2841  0.3119  0.2663  0.0009  2.0934  1.8084   91,250   91,250   91,250  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7650   5.2306   0.2656   0.2663   0.0025   1.2206   1.4709
       5.6968   5.1665   0.2637   0.2642   0.0025   1.2206   1.4702
    
    Launching a checkpoint evaluation
    
      Average reward: +0.64 (win rate of 82%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.90 (win rate of 5%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.69 (win rate of 134%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.22 (win rate of -161%), redundancy: 1.0%

Starting iteration 32

  Starting self-play
  
    Time spent on inference: 57%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.49MB
    Experience buffer size: 370,500 (370,500 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7518   5.2228  0.2624  0.2642  0.0023  1.4692  1.2209  370,500  370,500  370,500  all samples
     6.0983   5.5677  0.2641  0.2642  0.0023  1.4680  1.2222   52,000   52,000   52,000  latest batch
     1.3452   0.9382  0.1378  0.2642  0.0050  0.5693  0.4271   92,625   92,625   92,625  1 to 13 turns left
     3.9384   3.3861  0.2860  0.2642  0.0022  1.4197  1.1350   92,625   92,625   92,625  14 to 26 turns left
     6.8597   6.2789  0.3153  0.2642  0.0013  1.8011  1.5133   92,625   92,625   92,625  27 to 39 turns left
    10.8556  10.2802  0.3105  0.2642  0.0007  2.0865  1.8082   92,625   92,625   92,625  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7591   5.2283   0.2642   0.2642   0.0025   1.2209   1.4704
       5.7070   5.1782   0.2636   0.2628   0.0025   1.2209   1.4750
    
    Launching a checkpoint evaluation
    
      Average reward: +0.89 (win rate of 94%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.71 (win rate of 15%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.16 (win rate of 108%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -3.87 (win rate of -144%), redundancy: 1.0%

Starting iteration 33

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 78.80MB
    Experience buffer size: 376,000 (376,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7828   5.2535  0.2641  0.2628  0.0024  1.4739  1.2204  376,000  376,000  376,000  all samples
     6.1653   5.6313  0.2688  0.2628  0.0024  1.4733  1.2173   52,000   52,000   52,000  latest batch
     1.3466   0.9393  0.1392  0.2628  0.0053  0.5663  0.4261   94,000   94,000   94,000  1 to 14 turns left
     3.9492   3.3988  0.2854  0.2628  0.0022  1.4225  1.1356   94,000   94,000   94,000  14 to 27 turns left
     6.8995   6.3194  0.3161  0.2628  0.0013  1.8137  1.5126   94,000   94,000   94,000  27 to 40 turns left
    10.9369  10.3581  0.3153  0.2628  0.0007  2.0929  1.8075   94,000   94,000   94,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7867   5.2570   0.2644   0.2628   0.0025   1.2204   1.4752
       5.7311   5.2044   0.2659   0.2587   0.0022   1.2204   1.4671
    
    Launching a checkpoint evaluation
    
      Average reward: +0.76 (win rate of 88%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.04 (win rate of -2%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.94 (win rate of 147%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.03 (win rate of -152%), redundancy: 1.0%

Starting iteration 34

  Starting self-play
  
    Time spent on inference: 57%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.06MB
    Experience buffer size: 381,500 (381,500 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7410   5.2136  0.2666  0.2587  0.0022  1.4649  1.2202  381,500  381,500  381,500  all samples
     5.6351   5.1018  0.2724  0.2587  0.0022  1.4660  1.2189   52,000   52,000   52,000  latest batch
     1.3438   0.9411  0.1393  0.2587  0.0047  0.5576  0.4265   95,375   95,375   95,375  1 to 14 turns left
     3.9260   3.3754  0.2899  0.2587  0.0020  1.4188  1.1345   95,375   95,375   95,375  14 to 27 turns left
     6.8597   6.2802  0.3197  0.2587  0.0012  1.8057  1.5111   95,375   95,375   95,375  27 to 40 turns left
    10.8338  10.2569  0.3176  0.2587  0.0006  2.0774  1.8087   95,375   95,375   95,375  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7425   5.2152   0.2665   0.2587   0.0022   1.2202   1.4669
       5.6583   5.1390   0.2615   0.2556   0.0022   1.2202   1.4641
    
    Launching a checkpoint evaluation
    
      Average reward: +0.86 (win rate of 93%), redundancy: 1.4%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.94 (win rate of 3%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.49 (win rate of 125%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.04 (win rate of -152%), redundancy: 1.0%

Starting iteration 35

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.36MB
    Experience buffer size: 387,000 (387,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7251   5.2061  0.2611  0.2556  0.0023  1.4626  1.2205  387,000  387,000  387,000  all samples
     6.2163   5.6932  0.2651  0.2556  0.0024  1.4633  1.2238   52,000   52,000   52,000  latest batch
     1.3354   0.9391  0.1357  0.2556  0.0050  0.5641  0.4262   96,750   96,750   96,750  1 to 14 turns left
     3.8974   3.3569  0.2827  0.2556  0.0022  1.4158  1.1350   96,750   96,750   96,750  14 to 27 turns left
     6.8447   6.2710  0.3168  0.2556  0.0013  1.7961  1.5107   96,750   96,750   96,750  27 to 40 turns left
    10.8245  10.2589  0.3093  0.2556  0.0007  2.0747  1.8102   96,750   96,750   96,750  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7257   5.2058   0.2621   0.2556   0.0022   1.2205   1.4639
       5.6743   5.1593   0.2607   0.2521   0.0022   1.2205   1.4440
    
    Launching a checkpoint evaluation
    
      Average reward: +0.82 (win rate of 91%), redundancy: 1.3%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.88 (win rate of 6%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.39 (win rate of 119%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -4.22 (win rate of -161%), redundancy: 1.0%

Starting iteration 36

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.3
    MCTS memory footprint: 79.03MB
    Experience buffer size: 392,500 (392,500 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7032   5.1884  0.2604  0.2521  0.0023  1.4428  1.2206  392,500  392,500  392,500  all samples
     5.9627   5.4423  0.2659  0.2521  0.0023  1.4428  1.2201   52,000   52,000   52,000  latest batch
     1.3123   0.9210  0.1341  0.2521  0.0051  0.5490  0.4261   98,125   98,125   98,125  1 to 14 turns left
     3.8660   3.3290  0.2827  0.2521  0.0022  1.4019  1.1353   98,125   98,125   98,125  14 to 27 turns left
     6.8314   6.2631  0.3148  0.2521  0.0013  1.7805  1.5090   98,125   98,125   98,125  27 to 40 turns left
    10.8014  10.2388  0.3098  0.2521  0.0007  2.0397  1.8120   98,125   98,125   98,125  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7102   5.1949   0.2610   0.2521   0.0022   1.2206   1.4438
       5.6590   5.1485   0.2599   0.2481   0.0024   1.2206   1.4710
    
    Launching a checkpoint evaluation
    
      Average reward: +1.08 (win rate of 104%, network replaced), redundancy: 1.4%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.22 (win rate of 39%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +2.30 (win rate of 165%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -1.81 (win rate of -40%), redundancy: 1.0%

Starting iteration 37

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.6
    MCTS memory footprint: 78.74MB
    Experience buffer size: 398,000 (398,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7255   5.2177  0.2574  0.2481  0.0023  1.4693  1.2122  398,000  398,000  398,000  all samples
     5.9130   5.4157  0.2469  0.2481  0.0023  1.4752  1.1561   52,000   52,000   52,000  latest batch
     1.3064   0.9213  0.1318  0.2481  0.0052  0.5582  0.4256   99,500   99,500   99,500  1 to 14 turns left
     3.9256   3.3921  0.2833  0.2481  0.0021  1.4239  1.1271   99,500   99,500   99,500  14 to 27 turns left
     6.8932   6.3324  0.3114  0.2481  0.0012  1.8124  1.4976   99,500   99,500   99,500  27 to 40 turns left
    10.7804  10.2283  0.3032  0.2481  0.0008  2.0826  1.7985   99,500   99,500   99,500  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7317   5.2209   0.2603   0.2481   0.0024   1.2122   1.4714
       5.6864   5.1750   0.2622   0.2465   0.0027   1.2122   1.4811
    
    Launching a checkpoint evaluation
    
      Average reward: +0.07 (win rate of 54%), redundancy: 1.4%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.39 (win rate of 30%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +2.32 (win rate of 166%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -1.91 (win rate of -45%), redundancy: 1.0%

Starting iteration 38

  Starting self-play
  
    Time spent on inference: 55%
    Generating 5 samples per second on average
    Average exploration depth: 5.6
    MCTS memory footprint: 78.98MB
    Experience buffer size: 403,500 (403,500 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7349   5.2212  0.2646  0.2465  0.0026  1.4805  1.2044  403,500  403,500  403,500  all samples
     6.3782   5.8500  0.2791  0.2465  0.0026  1.4831  1.1604   52,000   52,000   52,000  latest batch
     1.3152   0.9294  0.1335  0.2465  0.0058  0.5618  0.4250  100,875  100,875  100,875  1 to 14 turns left
     3.9258   3.3876  0.2892  0.2465  0.0025  1.4275  1.1190  100,875  100,875  100,875  14 to 27 turns left
     6.9396   6.3716  0.3200  0.2465  0.0014  1.8196  1.4875  100,875  100,875  100,875  27 to 40 turns left
    10.7600  10.1970  0.3158  0.2465  0.0007  2.1130  1.7861  100,875  100,875  100,875  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7399   5.2258   0.2648   0.2465   0.0027   1.2044   1.4814
       5.6654   5.1588   0.2600   0.2443   0.0022   1.2044   1.4694
    
    Launching a checkpoint evaluation
    
      Average reward: +0.11 (win rate of 56%), redundancy: 1.4%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.46 (win rate of 27%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +2.25 (win rate of 162%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -2.05 (win rate of -52%), redundancy: 1.0%

Starting iteration 39

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.6
    MCTS memory footprint: 78.78MB
    Experience buffer size: 409,000 (409,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7335   5.2253  0.2617  0.2443  0.0022  1.4699  1.1964  409,000  409,000  409,000  all samples
     6.2290   5.7095  0.2729  0.2443  0.0022  1.4713  1.1563   52,000   52,000   52,000  latest batch
     1.3110   0.9313  0.1305  0.2443  0.0048  0.5594  0.4247  102,250  102,250  102,250  1 to 14 turns left
     3.9246   3.3908  0.2874  0.2443  0.0021  1.4112  1.1106  102,250  102,250  102,250  14 to 27 turns left
     6.9522   6.3898  0.3168  0.2443  0.0012  1.8053  1.4763  102,250  102,250  102,250  27 to 40 turns left
    10.7461  10.1890  0.3121  0.2443  0.0007  2.1036  1.7741  102,250  102,250  102,250  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7373   5.2287   0.2620   0.2443   0.0022   1.1964   1.4695
       5.6983   5.1899   0.2619   0.2442   0.0023   1.1964   1.4277
    
    Launching a checkpoint evaluation
    
      Average reward: -0.03 (win rate of 48%), redundancy: 1.4%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.29 (win rate of 36%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +2.41 (win rate of 170%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -1.78 (win rate of -39%), redundancy: 1.0%

Starting iteration 40

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.6
    MCTS memory footprint: 78.85MB
    Experience buffer size: 414,500 (414,500 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7687   5.2604  0.2617  0.2442  0.0023  1.4272  1.1888  414,500  414,500  414,500  all samples
     6.2755   5.7660  0.2630  0.2442  0.0023  1.4293  1.1583   52,000   52,000   52,000  latest batch
     1.3043   0.9247  0.1304  0.2442  0.0051  0.5594  0.4241  103,625  103,625  103,625  1 to 14 turns left
     3.9406   3.4059  0.2883  0.2442  0.0023  1.3876  1.1029  103,625  103,625  103,625  14 to 27 turns left
     7.0438   6.4787  0.3196  0.2442  0.0013  1.7462  1.4659  103,625  103,625  103,625  27 to 40 turns left
    10.7821  10.2285  0.3088  0.2442  0.0007  2.0154  1.7622  103,625  103,625  103,625  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7725   5.2635   0.2625   0.2442   0.0023   1.1888   1.4281
       5.7216   5.2192   0.2595   0.2405   0.0023   1.1888   1.4338
    
    Launching a checkpoint evaluation
    
      Average reward: +0.18 (win rate of 59%), redundancy: 1.5%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.39 (win rate of 30%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +2.23 (win rate of 162%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -2.27 (win rate of -64%), redundancy: 1.0%

Starting iteration 41

  Starting self-play
  
    Time spent on inference: 55%
    Generating 5 samples per second on average
    Average exploration depth: 5.6
    MCTS memory footprint: 79.49MB
    Experience buffer size: 420,000 (420,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7296   5.2273  0.2594  0.2405  0.0023  1.4354  1.1812  420,000  420,000  420,000  all samples
     5.9183   5.4123  0.2632  0.2405  0.0023  1.4362  1.1533   52,000   52,000   52,000  latest batch
     1.3110   0.9395  0.1257  0.2405  0.0053  0.5446  0.4243  105,000  105,000  105,000  1 to 14 turns left
     3.9417   3.4129  0.2861  0.2405  0.0021  1.3813  1.0946  105,000  105,000  105,000  14 to 27 turns left
     7.0141   6.4556  0.3168  0.2405  0.0012  1.7680  1.4561  105,000  105,000  105,000  27 to 40 turns left
    10.6505  10.1006  0.3088  0.2405  0.0006  2.0478  1.7498  105,000  105,000  105,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7334   5.2307   0.2598   0.2405   0.0023   1.1812   1.4343
       5.7342   5.2308   0.2618   0.2390   0.0026   1.1812   1.4387
    
    Launching a checkpoint evaluation
    
      Average reward: +0.30 (win rate of 65%), redundancy: 1.5%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.69 (win rate of 16%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.91 (win rate of 146%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -1.96 (win rate of -48%), redundancy: 1.0%

Starting iteration 42

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.6
    MCTS memory footprint: 78.88MB
    Experience buffer size: 425,500 (425,500 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.8204   5.3174  0.2612  0.2390  0.0028  1.4430  1.1745  425,500  425,500  425,500  all samples
     5.9518   5.4464  0.2635  0.2390  0.0028  1.4457  1.1583   52,000   52,000   52,000  latest batch
     1.3190   0.9505  0.1230  0.2390  0.0065  0.5472  0.4241  106,375  106,375  106,375  1 to 14 turns left
     4.0226   3.4936  0.2874  0.2390  0.0026  1.3908  1.0877  106,375  106,375  106,375  14 to 27 turns left
     7.1450   6.5858  0.3187  0.2390  0.0014  1.7778  1.4478  106,375  106,375  106,375  27 to 40 turns left
    10.7962  10.2409  0.3156  0.2390  0.0008  2.0561  1.7384  106,375  106,375  106,375  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.8266   5.3237   0.2613   0.2390   0.0026   1.1745   1.4394
       5.7443   5.2495   0.2565   0.2359   0.0024   1.1745   1.4286
    
    Launching a checkpoint evaluation
    
      Average reward: +0.02 (win rate of 51%), redundancy: 1.5%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.30 (win rate of 35%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +2.45 (win rate of 172%), redundancy: 1.4%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -1.86 (win rate of -43%), redundancy: 1.0%

Starting iteration 43

  Starting self-play
  

Loading environment

  Loading network from: sessions/double-dummy-full-state/bestnn.data
  Loading network from: sessions/double-dummy-full-state/curnn.data
  Loading memory from: sessions/double-dummy-full-state/mem.data
  Loaded iteration counter from: sessions/double-dummy-full-state/iter.txt

Starting iteration 43

  Starting self-play
  
    Time spent on inference: 55%
    Generating 5 samples per second on average
    Average exploration depth: 5.8
    MCTS memory footprint: 78.70MB
    Experience buffer size: 431,000 (431,000 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7860   5.2846  0.2630  0.2359  0.0025  1.4264  1.1591  431,000  431,000  431,000  all samples
     6.1191   5.5573  0.3233  0.2359  0.0025  1.4218  1.0926   52,000   52,000   52,000  latest batch
     1.3240   0.9593  0.1232  0.2359  0.0056  0.5467  0.4226  107,750  107,750  107,750  1 to 14 turns left
     4.0591   3.5331  0.2878  0.2359  0.0023  1.3817  1.0781  107,750  107,750  107,750  14 to 27 turns left
     7.1291   6.5700  0.3219  0.2359  0.0013  1.7489  1.4282  107,750  107,750  107,750  27 to 40 turns left
    10.6314  10.0760  0.3188  0.2359  0.0006  2.0281  1.7077  107,750  107,750  107,750  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7911   5.2890   0.2637   0.2359   0.0024   1.1591   1.4287
       5.7402   5.2378   0.2648   0.2353   0.0023   1.1591   1.4198
    
    Launching a checkpoint evaluation
    
      Average reward: +0.36 (win rate of 68%), redundancy: 1.7%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.85 (win rate of 8%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.87 (win rate of 144%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -1.45 (win rate of -22%), redundancy: 1.0%

Starting iteration 44

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.8
    MCTS memory footprint: 79.01MB
    Experience buffer size: 436,500 (436,500 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7802   5.2717  0.2708  0.2353  0.0024  1.4175  1.1445  436,500  436,500  436,500  all samples
     5.8685   5.3083  0.3226  0.2353  0.0023  1.4115  1.0909   52,000   52,000   52,000  latest batch
     1.3259   0.9615  0.1238  0.2353  0.0053  0.5394  0.4205  109,125  109,125  109,125  1 to 14 turns left
     4.0797   3.5486  0.2936  0.2353  0.0021  1.3741  1.0679  109,125  109,125  109,125  14 to 27 turns left
     7.1382   6.5716  0.3299  0.2353  0.0013  1.7458  1.4110  109,125  109,125  109,125  27 to 40 turns left
    10.5756  10.0037  0.3359  0.2353  0.0007  2.0106  1.6788  109,125  109,125  109,125  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7887   5.2802   0.2709   0.2353   0.0023   1.1445   1.4201
       5.7394   5.2351   0.2668   0.2353   0.0022   1.1445   1.4096
    
    Launching a checkpoint evaluation
    
      Average reward: +0.24 (win rate of 62%), redundancy: 1.6%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.66 (win rate of 17%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +0.93 (win rate of 97%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -1.44 (win rate of -22%), redundancy: 1.0%

Starting iteration 45

  Starting self-play
  
    Time spent on inference: 55%
    Generating 5 samples per second on average
    Average exploration depth: 5.8
    MCTS memory footprint: 79.01MB
    Experience buffer size: 442,000 (442,000 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7346  5.2260  0.2710  0.2353  0.0022  1.4074  1.1346  442,000  442,000  442,000  all samples
     5.6944  5.1510  0.3059  0.2353  0.0022  1.4018  1.0932   52,000   52,000   52,000  latest batch
     1.3181  0.9529  0.1249  0.2353  0.0050  0.5422  0.4188  110,500  110,500  110,500  1 to 13 turns left
     4.0312  3.5017  0.2921  0.2353  0.0021  1.3661  1.0627  110,500  110,500  110,500  14 to 26 turns left
     7.0933  6.5279  0.3288  0.2353  0.0012  1.7276  1.3982  110,500  110,500  110,500  27 to 39 turns left
    10.4983  9.9242  0.3381  0.2353  0.0006  1.9937  1.6585  110,500  110,500  110,500  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7378   5.2285   0.2718   0.2353   0.0021   1.1346   1.4095
       5.6874   5.1843   0.2663   0.2343   0.0024   1.1346   1.3734
    
    Launching a checkpoint evaluation
    
      Average reward: +0.22 (win rate of 61%), redundancy: 1.8%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.80 (win rate of 10%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.32 (win rate of 116%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -1.61 (win rate of -31%), redundancy: 1.0%

Starting iteration 46

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.8
    MCTS memory footprint: 78.64MB
    Experience buffer size: 447,500 (447,500 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7194  5.2127  0.2700  0.2343  0.0024  1.3758  1.1275  447,500  447,500  447,500  all samples
     6.0153  5.4897  0.2889  0.2343  0.0024  1.3730  1.0978   52,000   52,000   52,000  latest batch
     1.3139  0.9507  0.1235  0.2343  0.0054  0.5351  0.4174  111,875  111,875  111,875  1 to 14 turns left
     3.9971  3.4723  0.2884  0.2343  0.0022  1.3432  1.0606  111,875  111,875  111,875  14 to 27 turns left
     7.0198  6.4560  0.3282  0.2343  0.0013  1.6877  1.3895  111,875  111,875  111,875  27 to 40 turns left
    10.5463  9.9716  0.3398  0.2343  0.0007  1.9373  1.6425  111,875  111,875  111,875  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7229   5.2156   0.2706   0.2343   0.0024   1.1275   1.3733
       5.6681   5.1575   0.2725   0.2359   0.0022   1.1275   1.3985
    
    Launching a checkpoint evaluation
    
      Average reward: +0.50 (win rate of 75%), redundancy: 1.7%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.64 (win rate of 18%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.30 (win rate of 115%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -1.59 (win rate of -30%), redundancy: 1.0%

Starting iteration 47

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.8
    MCTS memory footprint: 78.59MB
    Experience buffer size: 453,000 (453,000 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.7037  5.1905  0.2750  0.2359  0.0023  1.3973  1.1205  453,000  453,000  453,000  all samples
     6.2163  5.6878  0.2904  0.2359  0.0023  1.3924  1.0938   52,000   52,000   52,000  latest batch
     1.3116  0.9459  0.1248  0.2359  0.0050  0.5408  0.4159  113,250  113,250  113,250  1 to 14 turns left
     3.9824  3.4491  0.2952  0.2359  0.0022  1.3663  1.0587  113,250  113,250  113,250  14 to 27 turns left
     6.9781  6.4076  0.3332  0.2359  0.0014  1.7138  1.3807  113,250  113,250  113,250  27 to 40 turns left
    10.5448  9.9614  0.3468  0.2359  0.0007  1.9684  1.6269  113,250  113,250  113,250  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.7035   5.1895   0.2760   0.2359   0.0022   1.1205   1.3979
       5.6597   5.1455   0.2734   0.2386   0.0022   1.1205   1.3643
    
    Launching a checkpoint evaluation
    
      Average reward: +0.42 (win rate of 71%), redundancy: 1.8%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.66 (win rate of 17%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.90 (win rate of 145%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -1.65 (win rate of -32%), redundancy: 1.0%

Starting iteration 48

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.8
    MCTS memory footprint: 78.88MB
    Experience buffer size: 458,500 (458,500 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.6426  5.1260  0.2757  0.2386  0.0024  1.3591  1.1141  458,500  458,500  458,500  all samples
     5.8706  5.3438  0.2859  0.2386  0.0023  1.3584  1.0958   52,000   52,000   52,000  latest batch
     1.3051  0.9363  0.1249  0.2386  0.0053  0.5311  0.4144  114,625  114,625  114,625  1 to 14 turns left
     3.9417  3.4087  0.2923  0.2386  0.0021  1.3422  1.0574  114,625  114,625  114,625  14 to 27 turns left
     6.8805  6.3050  0.3355  0.2386  0.0013  1.6727  1.3734  114,625  114,625  114,625  27 to 40 turns left
    10.4425  9.8533  0.3499  0.2386  0.0007  1.8901  1.6112  114,625  114,625  114,625  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.6479   5.1313   0.2758   0.2386   0.0022   1.1141   1.3640
       5.6152   5.0972   0.2751   0.2407   0.0022   1.1141   1.3813
    
    Launching a checkpoint evaluation
    
      Average reward: +0.36 (win rate of 68%), redundancy: 1.8%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.85 (win rate of 8%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.58 (win rate of 129%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -1.70 (win rate of -35%), redundancy: 1.0%

Starting iteration 49

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.8
    MCTS memory footprint: 78.89MB
    Experience buffer size: 464,000 (464,000 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.6166  5.0980  0.2756  0.2407  0.0022  1.3773  1.1070  464,000  464,000  464,000  all samples
     5.9568  5.4337  0.2801  0.2407  0.0022  1.3749  1.0919   52,000   52,000   52,000  latest batch
     1.3064  0.9341  0.1267  0.2407  0.0049  0.5334  0.4129  116,000  116,000  116,000  1 to 14 turns left
     3.9227  3.3879  0.2920  0.2407  0.0020  1.3495  1.0546  116,000  116,000  116,000  14 to 27 turns left
     6.8401  6.2631  0.3350  0.2407  0.0013  1.6890  1.3647  116,000  116,000  116,000  27 to 40 turns left
    10.3981  9.8078  0.3489  0.2407  0.0007  1.9374  1.5959  116,000  116,000  116,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.6155   5.0957   0.2769   0.2407   0.0022   1.1070   1.3809
       5.5499   5.0270   0.2773   0.2433   0.0023   1.1070   1.3746
    
    Launching a checkpoint evaluation
    
      Average reward: +0.18 (win rate of 59%), redundancy: 1.7%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.03 (win rate of -2%), redundancy: 1.0%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.09 (win rate of 104%), redundancy: 1.1%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -1.78 (win rate of -39%), redundancy: 1.0%

Starting iteration 50

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.8
    MCTS memory footprint: 79.04MB
    Experience buffer size: 469,500 (469,500 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.5790  5.0568  0.2763  0.2433  0.0026  1.3723  1.1010  469,500  469,500  469,500  all samples
     5.8576  5.3336  0.2782  0.2433  0.0027  1.3718  1.0934   52,000   52,000   52,000  latest batch
     1.3007  0.9246  0.1271  0.2433  0.0059  0.5358  0.4117  117,375  117,375  117,375  1 to 14 turns left
     3.8801  3.3408  0.2936  0.2433  0.0025  1.3537  1.0536  117,375  117,375  117,375  14 to 27 turns left
     6.7921  6.2114  0.3360  0.2433  0.0015  1.6861  1.3573  117,375  117,375  117,375  27 to 40 turns left
    10.3412  9.7485  0.3487  0.2433  0.0008  1.9134  1.5813  117,375  117,375  117,375  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.5824   5.0600   0.2769   0.2433   0.0023   1.1010   1.3747
       5.5460   5.0278   0.2717   0.2442   0.0023   1.1010   1.3548
    
    Launching a checkpoint evaluation
    
      Average reward: +0.44 (win rate of 72%), redundancy: 1.7%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.85 (win rate of 8%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.86 (win rate of 143%), redundancy: 1.4%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -2.07 (win rate of -53%), redundancy: 1.0%

Starting iteration 51

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.8
    MCTS memory footprint: 79.17MB
    Experience buffer size: 475,000 (475,000 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.5520  5.0352  0.2704  0.2442  0.0022  1.3528  1.0944  475,000  475,000  475,000  all samples
     5.7622  5.2402  0.2756  0.2442  0.0022  1.3539  1.0925   52,000   52,000   52,000  latest batch
     1.2933  0.9181  0.1262  0.2442  0.0048  0.5357  0.4098  118,750  118,750  118,750  1 to 14 turns left
     3.8447  3.3078  0.2907  0.2442  0.0020  1.3588  1.0521  118,750  118,750  118,750  14 to 27 turns left
     6.7528  6.1803  0.3270  0.2442  0.0012  1.6714  1.3490  118,750  118,750  118,750  27 to 40 turns left
    10.3212  9.7384  0.3379  0.2442  0.0007  1.8453  1.5665  118,750  118,750  118,750  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.5553   5.0384   0.2704   0.2442   0.0023   1.0944   1.3546
       5.4962   4.9815   0.2674   0.2449   0.0024   1.0944   1.3523
    
    Launching a checkpoint evaluation
    
      Average reward: +0.32 (win rate of 66%), redundancy: 1.8%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.71 (win rate of 15%), redundancy: 1.0%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.74 (win rate of 137%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -1.83 (win rate of -42%), redundancy: 1.0%

Starting iteration 52

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.8
    MCTS memory footprint: 78.80MB
    Experience buffer size: 480,500 (480,500 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.5113  4.9972  0.2670  0.2449  0.0023  1.3505  1.0936  480,500  480,500  480,500  all samples
     5.9838  5.4666  0.2700  0.2449  0.0023  1.3504  1.0936   52,000   52,000   52,000  latest batch
     1.2886  0.9142  0.1243  0.2449  0.0052  0.5294  0.4094  120,125  120,125  120,125  1 to 14 turns left
     3.8304  3.2951  0.2884  0.2449  0.0021  1.3396  1.0521  120,125  120,125  120,125  14 to 27 turns left
     6.7077  6.1352  0.3264  0.2449  0.0012  1.6622  1.3475  120,125  120,125  120,125  27 to 40 turns left
    10.2193  9.6449  0.3288  0.2449  0.0006  1.8710  1.5654  120,125  120,125  120,125  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.5179   5.0032   0.2674   0.2449   0.0024   1.0936   1.3523
       5.4905   4.9771   0.2670   0.2443   0.0021   1.0936   1.3411
    
    Launching a checkpoint evaluation
    
      Average reward: +0.44 (win rate of 72%), redundancy: 1.7%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.97 (win rate of 2%), redundancy: 1.0%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.23 (win rate of 112%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -1.99 (win rate of -50%), redundancy: 1.0%

Starting iteration 53

  Starting self-play
  
    Time spent on inference: 57%
    Generating 5 samples per second on average
    Average exploration depth: 5.8
    MCTS memory footprint: 79.61MB
    Experience buffer size: 486,000 (486,000 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.5503  5.0366  0.2671  0.2443  0.0024  1.3394  1.0935  486,000  486,000  486,000  all samples
     5.7780  5.2598  0.2715  0.2443  0.0024  1.3398  1.0917   52,000   52,000   52,000  latest batch
     1.2781  0.9053  0.1229  0.2443  0.0055  0.5142  0.4094  121,500  121,500  121,500  1 to 14 turns left
     3.8094  3.2765  0.2865  0.2443  0.0020  1.3211  1.0522  121,500  121,500  121,500  14 to 27 turns left
     6.7299  6.1615  0.3228  0.2443  0.0012  1.6500  1.3474  121,500  121,500  121,500  27 to 40 turns left
    10.3838  9.8030  0.3359  0.2443  0.0006  1.8723  1.5651  121,500  121,500  121,500  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.5504   5.0366   0.2674   0.2443   0.0021   1.0935   1.3413
       5.5125   4.9972   0.2672   0.2456   0.0025   1.0935   1.3640
    
    Launching a checkpoint evaluation
    
      Average reward: +0.06 (win rate of 53%), redundancy: 1.6%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.18 (win rate of -9%), redundancy: 1.0%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +0.83 (win rate of 92%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -2.45 (win rate of -73%), redundancy: 1.0%

Starting iteration 54

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.8
    MCTS memory footprint: 79.17MB
    Experience buffer size: 491,500 (491,500 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.5180  5.0043  0.2657  0.2456  0.0023  1.3633  1.0938  491,500  491,500  491,500  all samples
     5.5116  4.9940  0.2697  0.2456  0.0023  1.3649  1.0923   52,000   52,000   52,000  latest batch
     1.2815  0.9052  0.1252  0.2456  0.0054  0.5309  0.4099  122,875  122,875  122,875  1 to 14 turns left
     3.7799  3.2440  0.2881  0.2456  0.0021  1.3451  1.0520  122,875  122,875  122,875  14 to 27 turns left
     6.6962  6.1285  0.3209  0.2456  0.0012  1.6715  1.3478  122,875  122,875  122,875  27 to 40 turns left
    10.3157  9.7409  0.3285  0.2456  0.0006  1.9059  1.5652  122,875  122,875  122,875  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.5271   5.0113   0.2677   0.2456   0.0025   1.0938   1.3644
       5.5034   4.9898   0.2655   0.2456   0.0024   1.0938   1.3415
    
    Launching a checkpoint evaluation
    
      Average reward: +0.64 (win rate of 82%), redundancy: 1.7%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.75 (win rate of 12%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.37 (win rate of 118%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -2.15 (win rate of -57%), redundancy: 1.0%

Starting iteration 55

  Starting self-play
  
    Time spent on inference: 55%
    Generating 5 samples per second on average
    Average exploration depth: 5.8
    MCTS memory footprint: 79.52MB
    Experience buffer size: 497,000 (497,000 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.5685  5.0542  0.2662  0.2456  0.0024  1.3418  1.0932  497,000  497,000  497,000  all samples
     6.1017  5.5812  0.2725  0.2456  0.0024  1.3404  1.0904   52,000   52,000   52,000  latest batch
     1.2857  0.9107  0.1240  0.2456  0.0053  0.5231  0.4101  124,250  124,250  124,250  1 to 14 turns left
     3.8361  3.3003  0.2879  0.2456  0.0022  1.3386  1.0517  124,250  124,250  124,250  14 to 27 turns left
     6.7891  6.2200  0.3220  0.2456  0.0014  1.6630  1.3472  124,250  124,250  124,250  27 to 40 turns left
    10.3667  9.7893  0.3311  0.2456  0.0007  1.8425  1.5638  124,250  124,250  124,250  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.5777   5.0634   0.2663   0.2456   0.0024   1.0932   1.3411
       5.5228   5.0082   0.2669   0.2450   0.0028   1.0932   1.3567
    
    Launching a checkpoint evaluation
    
      Average reward: +0.16 (win rate of 58%), redundancy: 1.8%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.08 (win rate of -4%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.42 (win rate of 121%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -1.88 (win rate of -44%), redundancy: 1.0%

Starting iteration 56

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.8
    MCTS memory footprint: 78.59MB
    Experience buffer size: 502,500 (502,500 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.5535  5.0391  0.2668  0.2450  0.0027  1.3592  1.0924  502,500  502,500  502,500  all samples
     5.9727  5.4537  0.2713  0.2450  0.0027  1.3589  1.0903   52,000   52,000   52,000  latest batch
     1.2795  0.9067  0.1223  0.2450  0.0054  0.5271  0.4099  125,625  125,625  125,625  1 to 14 turns left
     3.8052  3.2658  0.2921  0.2450  0.0024  1.3456  1.0505  125,625  125,625  125,625  14 to 27 turns left
     6.7760  6.2055  0.3239  0.2450  0.0017  1.6759  1.3463  125,625  125,625  125,625  27 to 40 turns left
    10.3536  9.7785  0.3288  0.2450  0.0014  1.8884  1.5630  125,625  125,625  125,625  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.5570   5.0418   0.2675   0.2450   0.0028   1.0924   1.3565
       5.4984   4.9824   0.2666   0.2472   0.0022   1.0924   1.3350
    
    Launching a checkpoint evaluation
    
      Average reward: +0.14 (win rate of 57%), redundancy: 1.6%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.73 (win rate of 14%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.35 (win rate of 118%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -1.96 (win rate of -48%), redundancy: 1.0%

Starting iteration 57

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.8
    MCTS memory footprint: 78.59MB
    Experience buffer size: 508,000 (508,000 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.5159  4.9996  0.2667  0.2472  0.0023  1.3305  1.0924  508,000  508,000  508,000  all samples
     5.8358  5.3171  0.2692  0.2472  0.0023  1.3318  1.0928   52,000   52,000   52,000  latest batch
     1.2683  0.8916  0.1240  0.2472  0.0055  0.5235  0.4101  127,000  127,000  127,000  1 to 14 turns left
     3.7768  3.2387  0.2888  0.2472  0.0021  1.3330  1.0504  127,000  127,000  127,000  14 to 27 turns left
     6.7086  6.1369  0.3234  0.2472  0.0012  1.6412  1.3458  127,000  127,000  127,000  27 to 40 turns left
    10.3098  9.7313  0.3307  0.2472  0.0006  1.8243  1.5635  127,000  127,000  127,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.5175   5.0013   0.2668   0.2472   0.0022   1.0924   1.3352
       5.4870   4.9778   0.2644   0.2425   0.0023   1.0924   1.3205
    
    Launching a checkpoint evaluation
    
      Average reward: -0.04 (win rate of 48%), redundancy: 1.8%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.04 (win rate of -2%), redundancy: 1.2%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.12 (win rate of 106%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -2.23 (win rate of -62%), redundancy: 1.1%

Starting iteration 58

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.8
    MCTS memory footprint: 78.96MB
    Experience buffer size: 513,500 (513,500 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.5238  5.0144  0.2649  0.2425  0.0021  1.3185  1.0923  513,500  513,500  513,500  all samples
     5.8129  5.2988  0.2694  0.2425  0.0021  1.3178  1.0932   52,000   52,000   52,000  latest batch
     1.2652  0.8942  0.1235  0.2425  0.0049  0.5147  0.4103  128,375  128,375  128,375  1 to 13 turns left
     3.7649  3.2348  0.2857  0.2425  0.0019  1.3034  1.0507  128,375  128,375  128,375  14 to 26 turns left
     6.7122  6.1463  0.3224  0.2425  0.0011  1.6236  1.3455  128,375  128,375  128,375  27 to 39 turns left
    10.3492  9.7783  0.3278  0.2425  0.0006  1.8324  1.5629  128,375  128,375  128,375  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.5265   5.0167   0.2650   0.2425   0.0023   1.0923   1.3204
       5.4851   4.9731   0.2680   0.2416   0.0024   1.0923   1.3462
    
    Launching a checkpoint evaluation
    
      Average reward: +0.09 (win rate of 55%), redundancy: 1.7%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.98 (win rate of 1%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.56 (win rate of 128%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -1.98 (win rate of -49%), redundancy: 1.0%

Starting iteration 59

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.8
    MCTS memory footprint: 78.72MB
    Experience buffer size: 519,000 (519,000 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.5175  5.0064  0.2670  0.2416  0.0025  1.3480  1.0924  519,000  519,000  519,000  all samples
     5.8068  5.2923  0.2705  0.2416  0.0024  1.3485  1.0935   52,000   52,000   52,000  latest batch
     1.2614  0.8922  0.1221  0.2416  0.0056  0.5260  0.4106  129,750  129,750  129,750  1 to 14 turns left
     3.7557  3.2226  0.2894  0.2416  0.0022  1.3310  1.0506  129,750  129,750  129,750  14 to 27 turns left
     6.7191  6.1495  0.3267  0.2416  0.0013  1.6617  1.3455  129,750  129,750  129,750  27 to 40 turns left
    10.3323  9.7601  0.3299  0.2416  0.0007  1.8733  1.5629  129,750  129,750  129,750  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.5216   5.0091   0.2684   0.2416   0.0024   1.0924   1.3460
       5.4954   4.9843   0.2671   0.2418   0.0022   1.0924   1.3489
    
    Launching a checkpoint evaluation
    
      Average reward: +0.32 (win rate of 66%), redundancy: 1.9%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.99 (win rate of 1%), redundancy: 1.0%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.46 (win rate of 123%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -2.02 (win rate of -51%), redundancy: 1.0%

Starting iteration 60

  Starting self-play
  
    Time spent on inference: 57%
    Generating 5 samples per second on average
    Average exploration depth: 5.8
    MCTS memory footprint: 79.19MB
    Experience buffer size: 524,500 (524,500 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.5475  5.0368  0.2665  0.2418  0.0023  1.3486  1.0926  524,500  524,500  524,500  all samples
     6.0791  5.5645  0.2704  0.2418  0.0024  1.3489  1.0945   52,000   52,000   52,000  latest batch
     1.2530  0.8834  0.1226  0.2418  0.0052  0.5264  0.4109  131,125  131,125  131,125  1 to 14 turns left
     3.7660  3.2330  0.2891  0.2418  0.0021  1.3457  1.0509  131,125  131,125  131,125  14 to 27 turns left
     6.7538  6.1839  0.3268  0.2418  0.0013  1.6639  1.3450  131,125  131,125  131,125  27 to 40 turns left
    10.4167  9.8468  0.3274  0.2418  0.0007  1.8583  1.5636  131,125  131,125  131,125  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.5521   5.0404   0.2677   0.2418   0.0022   1.0926   1.3491
       5.5232   5.0130   0.2667   0.2412   0.0023   1.0926   1.3447
    
    Launching a checkpoint evaluation
    
      Average reward: +0.22 (win rate of 61%), redundancy: 1.8%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -0.97 (win rate of 2%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.11 (win rate of 106%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -2.21 (win rate of -60%), redundancy: 1.0%

Starting iteration 61

  Starting self-play
  
    Time spent on inference: 57%
    Generating 5 samples per second on average
    Average exploration depth: 5.8
    MCTS memory footprint: 79.01MB
    Experience buffer size: 530,000 (530,000 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.5727  5.0625  0.2667  0.2412  0.0022  1.3444  1.0924  530,000  530,000  530,000  all samples
     5.8775  5.3639  0.2702  0.2412  0.0022  1.3428  1.0916   52,000   52,000   52,000  latest batch
     1.2542  0.8842  0.1238  0.2412  0.0049  0.5321  0.4113  132,500  132,500  132,500  1 to 14 turns left
     3.7808  3.2507  0.2869  0.2412  0.0019  1.3395  1.0503  132,500  132,500  132,500  14 to 27 turns left
     6.7921  6.2236  0.3259  0.2412  0.0012  1.6458  1.3451  132,500  132,500  132,500  27 to 40 turns left
    10.4598  9.8878  0.3301  0.2412  0.0007  1.8602  1.5628  132,500  132,500  132,500  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.5762   5.0658   0.2669   0.2412   0.0023   1.0924   1.3445
       5.5204   5.0145   0.2629   0.2408   0.0021   1.0924   1.3344
    
    Launching a checkpoint evaluation
    
      Average reward: +0.20 (win rate of 60%), redundancy: 1.7%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.11 (win rate of -6%), redundancy: 1.0%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.53 (win rate of 127%), redundancy: 1.2%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -2.09 (win rate of -54%), redundancy: 1.0%

Starting iteration 62

  Starting self-play
  
    Time spent on inference: 56%
    Generating 5 samples per second on average
    Average exploration depth: 5.8
    MCTS memory footprint: 78.96MB
    Experience buffer size: 535,500 (535,500 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.5529  5.0478  0.2623  0.2408  0.0020  1.3381  1.0929  535,500  535,500  535,500  all samples
     5.9453  5.4369  0.2656  0.2408  0.0020  1.3379  1.0971   52,000   52,000   52,000  latest batch
     1.2381  0.8715  0.1213  0.2408  0.0046  0.5288  0.4117  133,875  133,875  133,875  1 to 14 turns left
     3.7803  3.2535  0.2843  0.2408  0.0018  1.3379  1.0509  133,875  133,875  133,875  14 to 27 turns left
     6.7574  6.1954  0.3202  0.2408  0.0011  1.6474  1.3452  133,875  133,875  133,875  27 to 40 turns left
    10.4359  9.8711  0.3235  0.2408  0.0006  1.8380  1.5639  133,875  133,875  133,875  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.5589   5.0526   0.2634   0.2408   0.0021   1.0929   1.3344
       5.5349   5.0265   0.2660   0.2402   0.0022   1.0929   1.3268
    
    Launching a checkpoint evaluation
    
      Average reward: +0.08 (win rate of 54%), redundancy: 1.8%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.27 (win rate of -14%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +1.36 (win rate of 118%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -2.12 (win rate of -56%), redundancy: 1.0%

Starting iteration 63

  Starting self-play
  
    Time spent on inference: 57%
    Generating 5 samples per second on average
    Average exploration depth: 5.8
    MCTS memory footprint: 78.79MB
    Experience buffer size: 541,000 (541,000 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     5.5508  5.0426  0.2656  0.2402  0.0024  1.3269  1.0930  541,000  541,000  541,000  all samples
     5.7691  5.2573  0.2692  0.2402  0.0024  1.3307  1.0949   52,000   52,000   52,000  latest batch
     1.2454  0.8791  0.1204  0.2402  0.0057  0.5273  0.4119  135,250  135,250  135,250  1 to 14 turns left
     3.7861  3.2543  0.2894  0.2402  0.0022  1.3245  1.0511  135,250  135,250  135,250  14 to 27 turns left
     6.7561  6.1898  0.3247  0.2402  0.0013  1.6239  1.3455  135,250  135,250  135,250  27 to 40 turns left
    10.4150  9.8465  0.3277  0.2402  0.0006  1.8318  1.5636  135,250  135,250  135,250  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.5545   5.0456   0.2664   0.2402   0.0022   1.0930   1.3270
       5.5370   5.0301   0.2647   0.2401   0.0021   1.0930   1.3437
    
    Launching a checkpoint evaluation
    
      Average reward: +0.03 (win rate of 52%), redundancy: 1.8%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against MCTS (1000 rollouts)
  
    Average reward: -1.69 (win rate of -34%), redundancy: 1.1%
  
  Running benchmark: AlphaZero against MinMax (depth 5)
  
    Average reward: +0.89 (win rate of 94%), redundancy: 1.3%
  
  Running benchmark: Network Only against MCTS (1000 rollouts)
  
    Average reward: -2.00 (win rate of -50%), redundancy: 1.0%
