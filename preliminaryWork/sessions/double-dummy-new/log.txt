
Initializing a new AlphaZero environment

  Initial report
  
    Number of network parameters: 6,520,885
    Number of regularized network parameters: 6,520,704
    Memory footprint per MCTS node: 2488 bytes
  
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.52 (win rate of -76%), redundancy: 3.3%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -4.79 (win rate of -189%), redundancy: 2.7%

Starting iteration 1

  Starting self-play
  
    Time spent on inference: 60%
    Generating 3 samples per second on average
    Average exploration depth: 10.3
    MCTS memory footprint: 96.33MB
    Experience buffer size: 52,000 (51,996 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp    Wtot      Nb      Ns
     8.9671  6.9623  0.5022  0.5656  0.9370  0.8549  0.5796  52,000  51,996  52,000  all samples
     8.9656  6.9610  0.5020  0.5656  0.9370  0.8548  0.5796  52,000  51,996  52,000  latest batch
     4.6410  2.9448  0.1531  0.5656  0.9774  0.4220  0.3318  13,000  12,996  13,000  1 to 13 turns left
    10.0872  8.0495  0.5229  0.5656  0.9492  0.9109  0.5897  13,000  13,000  13,000  14 to 26 turns left
    10.7678  8.6581  0.6175  0.5656  0.9266  0.9883  0.6527  13,000  13,000  13,000  27 to 39 turns left
    10.3840  8.2090  0.7147  0.5656  0.8947  1.0982  0.7442  13,000  13,000  13,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       9.4533   7.2531   0.7082   0.5656   0.9264   0.5796   0.8746
      19.0750   6.9560   0.4507  10.7363   0.9321   0.5796   1.0337
    
    Launching a checkpoint evaluation
    
      Average reward: +3.00 (win rate of 200%, network replaced), redundancy: 0.9%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
      18.3944   6.9560   0.4449  10.0624   0.9311   0.5796   1.0377
    
    Launching a checkpoint evaluation
    
      Average reward: +2.00 (win rate of 150%), redundancy: 3.8%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -3.43 (win rate of -121%), redundancy: 3.4%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -4.83 (win rate of -191%), redundancy: 2.7%

Starting iteration 2

  Starting self-play
  
    Time spent on inference: 62%
    Generating 3 samples per second on average
    Average exploration depth: 9.2
    MCTS memory footprint: 99.43MB
    Experience buffer size: 104,000 (103,992 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp     Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
    17.9705  6.5729  0.4034  10.0624  0.9318  1.0410  0.6051  104,000  103,992  104,000  all samples
    17.5467  6.1893  0.3620  10.0624  0.9329  1.0427  0.6306   52,000   52,000   52,000  latest batch
    14.1636  2.9839  0.1465  10.0624  0.9708  0.4901  0.3473   26,000   25,992   26,000  1 to 13 turns left
    19.2319  7.7720  0.4563  10.0624  0.9411  1.0797  0.6162   26,000   26,000   26,000  14 to 26 turns left
    19.4216  7.9475  0.4902  10.0624  0.9214  1.2120  0.6892   26,000   26,000   26,000  27 to 39 turns left
    19.0758  7.5987  0.5206  10.0624  0.8940  1.3823  0.7676   26,000   26,000   26,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
      17.9716   6.5741   0.4028  10.0624   0.9323   0.6051   1.0379
      16.7276   6.5686   0.3887   8.8369   0.9335   0.6051   1.0020
    
    Launching a checkpoint evaluation
    
      Average reward: +1.00 (win rate of 100%, network replaced), redundancy: 2.8%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
      15.7542   6.6151   0.3935   7.8140   0.9316   0.6051   1.0014
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 1.9%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -3.08 (win rate of -104%), redundancy: 3.0%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -4.87 (win rate of -193%), redundancy: 2.7%

Starting iteration 3

  Starting self-play
  
    Time spent on inference: 62%
    Generating 3 samples per second on average
    Average exploration depth: 9.3
    MCTS memory footprint: 99.64MB
    Experience buffer size: 156,000 (155,988 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
    15.6699  6.5485  0.3751  7.8140  0.9323  1.0001  0.6112  156,000  155,988  156,000  all samples
    15.4948  6.4049  0.3425  7.8140  0.9334  0.9981  0.6234   52,000   52,000   52,000  latest batch
    11.9660  3.0363  0.1473  7.8140  0.9684  0.4827  0.3548   39,000   38,988   39,000  1 to 13 turns left
    16.9685  7.7712  0.4437  7.8140  0.9396  1.0623  0.6241   39,000   39,000   39,000  14 to 26 turns left
    17.0666  7.8737  0.4546  7.8140  0.9242  1.1681  0.6942   39,000   39,000   39,000  27 to 39 turns left
    16.6831  7.5172  0.4549  7.8140  0.8970  1.2874  0.7717   39,000   39,000   39,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
      15.6674   6.5451   0.3761   7.8140   0.9322   0.6112   1.0007
      13.6235   6.4493   0.4430   6.4369   0.2944   0.6112   0.8833
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 1.9%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.9366   3.1296   0.3976   5.3288   0.0805   0.6112   0.8709
    
    Launching a checkpoint evaluation
    
      Average reward: +3.00 (win rate of 200%, network replaced), redundancy: 0.9%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.76 (win rate of -88%), redundancy: 3.2%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -4.36 (win rate of -168%), redundancy: 2.8%

Starting iteration 4

  Starting self-play
  
    Time spent on inference: 62%
    Generating 2 samples per second on average
    Average exploration depth: 10.3
    MCTS memory footprint: 97.46MB
    Experience buffer size: 208,000 (207,988 distinct boards)
  
  Memory Analysis
  
      Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
    9.0714  3.2669  0.3931  5.3288  0.0826  0.8727  0.6072  208,000  207,988  208,000  all samples
    9.4790  3.6918  0.3734  5.3288  0.0850  0.8745  0.5952   52,000   52,000   52,000  latest batch
    7.5439  1.9827  0.1664  5.3288  0.0661  0.4424  0.3536   52,000   51,988   52,000  1 to 13 turns left
    9.6319  3.7305  0.4749  5.3288  0.0976  0.9358  0.6182   52,000   52,000   52,000  14 to 26 turns left
    9.4889  3.5922  0.4731  5.3288  0.0948  1.0160  0.6911   52,000   52,000   52,000  27 to 39 turns left
    9.6194  3.7612  0.4574  5.3288  0.0719  1.0965  0.7659   52,000   52,000   52,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       9.0791   3.2708   0.3985   5.3288   0.0810   0.6072   0.8709
       7.0401   2.4712   0.3637   4.1723   0.0330   0.6072   0.9041
    
    Launching a checkpoint evaluation
    
      Average reward: -2.00 (win rate of -50%), redundancy: 1.9%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       5.9134   2.2561   0.3523   3.2790   0.0259   0.6072   0.8853
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 3.8%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.73 (win rate of -87%), redundancy: 2.9%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -3.69 (win rate of -135%), redundancy: 2.7%

Starting iteration 5

  Starting self-play
  
    Time spent on inference: 63%
    Generating 2 samples per second on average
    Average exploration depth: 10.2
    MCTS memory footprint: 99.02MB
    Experience buffer size: 208,000 (207,992 distinct boards)
  
  Memory Analysis
  
      Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
    6.0537  2.4046  0.3448  3.2790  0.0252  0.8859  0.6130  208,000  207,992  208,000  all samples
    6.4570  2.7626  0.3905  3.2790  0.0248  0.8865  0.6030   52,000   52,000   52,000  latest batch
    4.8316  1.3852  0.1426  3.2790  0.0248  0.4610  0.3571   52,000   51,992   52,000  1 to 13 turns left
    6.1809  2.4608  0.4158  3.2790  0.0253  0.9724  0.6257   52,000   52,000   52,000  14 to 26 turns left
    6.3801  2.6561  0.4178  3.2790  0.0272  1.0320  0.6988   52,000   52,000   52,000  27 to 39 turns left
    6.8232  3.1173  0.4034  3.2790  0.0234  1.0784  0.7707   52,000   52,000   52,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       6.0608   2.4120   0.3441   3.2790   0.0257   0.6130   0.8870
       5.0636   2.1281   0.3199   2.5937   0.0219   0.6130   0.8837
    
    Launching a checkpoint evaluation
    
      Average reward: +1.00 (win rate of 100%, network replaced), redundancy: 4.7%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       4.3601   1.9606   0.3165   2.0687   0.0143   0.6130   0.8758
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 2.8%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.17 (win rate of -59%), redundancy: 2.9%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -3.49 (win rate of -125%), redundancy: 2.8%

Starting iteration 6

  Starting self-play
  
    Time spent on inference: 64%
    Generating 2 samples per second on average
    Average exploration depth: 10.4
    MCTS memory footprint: 97.58MB
    Experience buffer size: 208,000 (207,996 distinct boards)
  
  Memory Analysis
  
      Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
    4.5264  2.1107  0.3307  2.0687  0.0162  0.8721  0.6025  208,000  207,996  208,000  all samples
    4.9134  2.4910  0.3376  2.0687  0.0162  0.8671  0.5883   52,000   52,000   52,000  latest batch
    3.3629  1.1382  0.1342  2.0687  0.0218  0.4551  0.3540   52,000   51,996   52,000  1 to 13 turns left
    4.5466  2.0688  0.3925  2.0687  0.0166  0.9580  0.6155   52,000   52,000   52,000  14 to 26 turns left
    4.9015  2.4138  0.4034  2.0687  0.0156  1.0203  0.6832   52,000   52,000   52,000  27 to 39 turns left
    5.2958  2.8233  0.3928  2.0687  0.0110  1.0550  0.7573   52,000   52,000   52,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       4.5314   2.1189   0.3296   2.0687   0.0142   0.6025   0.8741
       3.9948   1.9872   0.3247   1.6704   0.0125   0.6025   0.8796
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 4.7%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       3.3217   1.6329   0.3125   1.3636   0.0128   0.6025   0.8855
    
    Launching a checkpoint evaluation
    
      Average reward: -3.00 (win rate of -100%), redundancy: 3.8%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.64 (win rate of -82%), redundancy: 2.9%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -3.37 (win rate of -119%), redundancy: 2.7%

Starting iteration 7

  Starting self-play
  
    Time spent on inference: 64%
    Generating 2 samples per second on average
    Average exploration depth: 10.3
    MCTS memory footprint: 97.64MB
    Experience buffer size: 234,000 (233,996 distinct boards)
  
  Memory Analysis
  
      Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
    3.4733  1.7786  0.3184  1.3636  0.0127  0.8842  0.5985  234,000  233,996  234,000  all samples
    3.9866  2.2885  0.3216  1.3636  0.0129  0.8834  0.5965   52,000   52,000   52,000  latest batch
    2.4192  0.9213  0.1236  1.3636  0.0107  0.4559  0.3507   58,500   58,496   58,500  1 to 13 turns left
    3.5173  1.7626  0.3762  1.3636  0.0148  0.9637  0.6136   58,500   58,500   58,500  14 to 26 turns left
    3.8017  2.0302  0.3935  1.3636  0.0143  1.0352  0.6771   58,500   58,500   58,500  27 to 39 turns left
    4.1554  2.4003  0.3807  1.3636  0.0108  1.0824  0.7526   58,500   58,500   58,500  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       3.4827   1.7879   0.3185   1.3636   0.0128   0.5985   0.8855
       3.1525   1.7034   0.3128   1.1242   0.0121   0.5985   0.8750
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 0.9%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       2.8213   1.5658   0.3115   0.9325   0.0115   0.5985   0.8926
    
    Launching a checkpoint evaluation
    
      Average reward: +1.00 (win rate of 100%, network replaced), redundancy: 3.8%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.27 (win rate of -63%), redundancy: 3.0%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -3.35 (win rate of -117%), redundancy: 2.6%

Starting iteration 8

  Starting self-play
  
    Time spent on inference: 64%
    Generating 2 samples per second on average
    Average exploration depth: 10.4
    MCTS memory footprint: 98.31MB
    Experience buffer size: 260,000 (259,996 distinct boards)
  
  Memory Analysis
  
      Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
    2.9705  1.7165  0.3094  0.9324  0.0121  0.8925  0.5968  260,000  259,996  260,000  all samples
    3.5536  2.3145  0.2941  0.9324  0.0126  0.8905  0.6010   52,000   52,000   52,000  latest batch
    1.9313  0.8681  0.1162  0.9324  0.0145  0.4512  0.3495   65,000   64,996   65,000  1 to 13 turns left
    2.9452  1.6376  0.3607  0.9324  0.0144  0.9642  0.6124   65,000   65,000   65,000  14 to 26 turns left
    3.2940  1.9656  0.3839  0.9324  0.0121  1.0480  0.6768   65,000   65,000   65,000  27 to 39 turns left
    3.7135  2.3965  0.3770  0.9324  0.0076  1.1068  0.7486   65,000   65,000   65,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       2.9796   1.7224   0.3132   0.9324   0.0116   0.5968   0.8921
       2.5852   1.4786   0.3111   0.7865   0.0090   0.5968   0.8712
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 11.3%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       3.0648   1.4674   0.3067   1.2798   0.0109   0.5968   0.8792
    
    Launching a checkpoint evaluation
    
      Average reward: -2.00 (win rate of -50%), redundancy: 0.9%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.24 (win rate of -62%), redundancy: 3.0%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -3.31 (win rate of -115%), redundancy: 2.8%

Starting iteration 9

  Starting self-play
  
    Time spent on inference: 65%
    Generating 2 samples per second on average
    Average exploration depth: 10.3
    MCTS memory footprint: 98.35MB
    Experience buffer size: 286,000 (285,996 distinct boards)
  
  Memory Analysis
  
      Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
    3.2065  1.6078  0.3074  1.2798  0.0114  0.8798  0.5978  286,000  285,996  286,000  all samples
    3.8669  2.2579  0.3174  1.2798  0.0118  0.8760  0.6015   52,000   52,000   52,000  latest batch
    2.1808  0.7736  0.1135  1.2798  0.0138  0.4506  0.3494   71,500   71,496   71,500  1 to 13 turns left
    3.1793  1.5335  0.3532  1.2798  0.0128  0.9567  0.6178   71,500   71,500   71,500  14 to 26 turns left
    3.5301  1.8572  0.3817  1.2798  0.0113  1.0320  0.6765   71,500   71,500   71,500  27 to 39 turns left
    3.9370  2.2678  0.3815  1.2798  0.0079  1.0797  0.7474   71,500   71,500   71,500  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       3.2235   1.6249   0.3078   1.2798   0.0110   0.5978   0.8782
       2.8633   1.4976   0.3051   1.0491   0.0115   0.5978   0.8633
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 0.9%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       2.5296   1.3331   0.3021   0.8834   0.0110   0.5978   0.8674
    
    Launching a checkpoint evaluation
    
      Average reward: +2.00 (win rate of 150%, network replaced), redundancy: 4.7%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.28 (win rate of -64%), redundancy: 2.9%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -3.40 (win rate of -120%), redundancy: 2.7%

Starting iteration 10

  Starting self-play
  
    Time spent on inference: 65%
    Generating 2 samples per second on average
    Average exploration depth: 10.6
    MCTS memory footprint: 97.68MB
    Experience buffer size: 312,000 (312,000 distinct boards)
  
  Memory Analysis
  
      Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
    2.7105  1.5185  0.2968  0.8834  0.0119  0.8691  0.5978  312,000  312,000  312,000  all samples
    3.6389  2.4597  0.2836  0.8834  0.0122  0.8682  0.5964   52,000   52,000   52,000  latest batch
    1.7184  0.7083  0.1090  0.8834  0.0177  0.4472  0.3516   78,000   78,000   78,000  1 to 13 turns left
    2.6666  1.4367  0.3344  0.8834  0.0121  0.9411  0.6179   78,000   78,000   78,000  14 to 26 turns left
    3.0179  1.7546  0.3694  0.8834  0.0105  1.0180  0.6771   78,000   78,000   78,000  27 to 39 turns left
    3.4398  2.1748  0.3745  0.8834  0.0072  1.0701  0.7445   78,000   78,000   78,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       2.7256   1.5314   0.2997   0.8834   0.0111   0.5978   0.8669
       5.5240   3.2156   0.3616   1.9133   0.0335   0.5978   0.8998
    
    Launching a checkpoint evaluation
    
      Average reward: +1.00 (win rate of 100%, network replaced), redundancy: 1.9%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       3.9158   2.1570   0.3296   1.4102   0.0189   0.5978   0.8872
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 0.9%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.48 (win rate of -74%), redundancy: 3.0%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -3.36 (win rate of -118%), redundancy: 2.7%

Starting iteration 11

  Starting self-play
  
    Time spent on inference: 63%
    Generating 2 samples per second on average
    Average exploration depth: 10.2
    MCTS memory footprint: 98.09MB
    Experience buffer size: 338,000 (338,000 distinct boards)
  
  Memory Analysis
  
      Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
    3.9377  2.1794  0.3301  1.4102  0.0180  0.8861  0.5980  338,000  338,000  338,000  all samples
    4.1147  2.3491  0.3379  1.4102  0.0174  0.8924  0.6009   52,000   52,000   52,000  latest batch
    2.6681  1.1254  0.1190  1.4102  0.0135  0.4537  0.3522   84,500   84,500   84,500  1 to 13 turns left
    3.9003  2.0896  0.3786  1.4102  0.0218  0.9591  0.6166   84,500   84,500   84,500  14 to 26 turns left
    4.3343  2.4898  0.4130  1.4102  0.0213  1.0391  0.6790   84,500   84,500   84,500  27 to 39 turns left
    4.8483  3.0131  0.4094  1.4102  0.0156  1.0924  0.7442   84,500   84,500   84,500  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       3.9571   2.1983   0.3298   1.4102   0.0188   0.5980   0.8879
       3.6472   1.8623   0.3149   1.4478   0.0222   0.5980   0.8791
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 0.9%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       3.9746   2.1294   0.3125   1.5229   0.0098   0.5980   0.8772
    
    Launching a checkpoint evaluation
    
      Average reward: -4.00 (win rate of -150%), redundancy: 1.9%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.32 (win rate of -66%), redundancy: 3.0%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -2.87 (win rate of -93%), redundancy: 2.7%

Starting iteration 12

  Starting self-play
  
    Time spent on inference: 63%
    Generating 2 samples per second on average
    Average exploration depth: 10.1
    MCTS memory footprint: 97.62MB
    Experience buffer size: 364,000 (363,992 distinct boards)
  
  Memory Analysis
  
      Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
    3.9828  2.1375  0.3120  1.5229  0.0104  0.8770  0.5981  364,000  363,992  364,000  all samples
    3.9936  2.1387  0.3216  1.5229  0.0104  0.8798  0.6023   52,000   52,000   52,000  latest batch
    2.6486  0.9998  0.1141  1.5229  0.0117  0.4489  0.3525   91,000   90,992   91,000  1 to 13 turns left
    3.8800  1.9909  0.3537  1.5229  0.0124  0.9459  0.6170   91,000   91,000   91,000  14 to 26 turns left
    4.4364  2.5149  0.3881  1.5229  0.0105  1.0267  0.6787   91,000   91,000   91,000  27 to 39 turns left
    4.9670  3.0449  0.3923  1.5229  0.0069  1.0870  0.7444   91,000   91,000   91,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       3.9873   2.1422   0.3123   1.5229   0.0098   0.5981   0.8768
       3.1279   1.7243   0.2999   1.0928   0.0109   0.5981   0.8639
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 4.7%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       3.2093   1.7334   0.2979   1.1686   0.0094   0.5981   0.8688
    
    Launching a checkpoint evaluation
    
      Average reward: +1.00 (win rate of 100%, network replaced), redundancy: 1.9%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.12 (win rate of -56%), redundancy: 2.9%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -3.01 (win rate of -101%), redundancy: 2.7%

Starting iteration 13

  Starting self-play
  
    Time spent on inference: 65%
    Generating 2 samples per second on average
    Average exploration depth: 10.5
    MCTS memory footprint: 97.91MB
    Experience buffer size: 390,000 (389,992 distinct boards)
  
  Memory Analysis
  
      Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
    3.2764  1.7998  0.2968  1.1686  0.0112  0.8704  0.5990  390,000  389,992  390,000  all samples
    3.7206  2.2644  0.2760  1.1686  0.0116  0.8710  0.6009   52,000   52,000   52,000  latest batch
    1.9181  0.6231  0.1094  1.1686  0.0169  0.4467  0.3539   97,500   97,492   97,500  1 to 13 turns left
    3.1345  1.6209  0.3331  1.1686  0.0118  0.9383  0.6193   97,500   97,500   97,500  14 to 26 turns left
    3.7452  2.1986  0.3684  1.1686  0.0096  1.0167  0.6795   97,500   97,500   97,500  27 to 39 turns left
    4.3058  2.7548  0.3761  1.1686  0.0063  1.0800  0.7434   97,500   97,500   97,500  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       3.2798   1.8045   0.2973   1.1686   0.0093   0.5990   0.8690
       2.8032   1.6418   0.2884   0.8644   0.0086   0.5990   0.8735
    
    Launching a checkpoint evaluation
    
      Average reward: +1.00 (win rate of 100%, network replaced), redundancy: 0.9%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.4276   3.3964   0.4047   4.5204   0.1060   0.5990   0.8955
    
    Launching a checkpoint evaluation
    
      Average reward: -1.00 (win rate of 0%), redundancy: 1.9%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.39 (win rate of -69%), redundancy: 3.1%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -3.97 (win rate of -149%), redundancy: 2.8%

Starting iteration 14

  Starting self-play
  
    Time spent on inference: 65%
    Generating 2 samples per second on average
    Average exploration depth: 10.5
    MCTS memory footprint: 98.76MB
    Experience buffer size: 416,000 (415,992 distinct boards)
  
  Memory Analysis
  
      Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
    8.4891  3.4575  0.4073  4.5204  0.1038  0.8976  0.6003  416,000  415,992  416,000  all samples
    8.6465  3.6037  0.4188  4.5204  0.1036  0.8946  0.6025   52,000   52,000   52,000  latest batch
    6.3667  1.6524  0.1380  4.5204  0.0559  0.4469  0.3552  104,000  103,992  104,000  1 to 13 turns left
    8.4816  3.4141  0.4423  4.5204  0.1048  0.9512  0.6210  104,000  104,000  104,000  14 to 26 turns left
    9.2576  4.0983  0.5058  4.5204  0.1331  1.0462  0.6807  104,000  104,000  104,000  27 to 39 turns left
    9.8502  4.6654  0.5428  4.5204  0.1216  1.1459  0.7441  104,000  104,000  104,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.4633   3.4306   0.4065   4.5204   0.1058   0.6003   0.8954
       5.8989   2.6239   0.3353   2.9198   0.0199   0.6003   0.8932
    
    Launching a checkpoint evaluation
    
      Average reward: +1.00 (win rate of 100%, network replaced), redundancy: 3.8%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       4.2929   2.0023   0.3086   1.9708   0.0112   0.6003   0.8819
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 2.8%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.17 (win rate of -59%), redundancy: 3.0%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -3.05 (win rate of -103%), redundancy: 2.8%

Starting iteration 15

  Starting self-play
  
    Time spent on inference: 64%
    Generating 2 samples per second on average
    Average exploration depth: 10.2
    MCTS memory footprint: 97.46MB
    Experience buffer size: 442,000 (441,992 distinct boards)
  
  Memory Analysis
  
      Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
    4.3023  2.0115  0.3088  1.9708  0.0112  0.8822  0.6011  442,000  441,992  442,000  all samples
    4.4439  2.1508  0.3110  1.9708  0.0113  0.8866  0.6046   52,000   52,000   52,000  latest batch
    2.9744  0.8874  0.1066  1.9708  0.0097  0.4477  0.3559  110,500  110,492  110,500  1 to 13 turns left
    4.1542  1.8201  0.3497  1.9708  0.0137  0.9440  0.6210  110,500  110,500  110,500  14 to 26 turns left
    4.7537  2.3859  0.3842  1.9708  0.0128  1.0305  0.6823  110,500  110,500  110,500  27 to 39 turns left
    5.3268  2.9529  0.3944  1.9708  0.0087  1.1067  0.7454  110,500  110,500  110,500  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       4.3172   2.0261   0.3090   1.9708   0.0112   0.6011   0.8825
      376.470   9.7481   0.4195 365.3734   0.9299   0.6011   1.0284
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 0.9%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
      221.350   9.7499   0.4162 210.2616   0.9226   0.6011   1.0264
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 1.9%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -3.09 (win rate of -105%), redundancy: 3.0%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -4.35 (win rate of -167%), redundancy: 2.6%

Starting iteration 16

  Starting self-play
  
    Time spent on inference: 64%
    Generating 2 samples per second on average
    Average exploration depth: 10.3
    MCTS memory footprint: 98.10MB
    Experience buffer size: 468,000 (467,992 distinct boards)
  
  Memory Analysis
  
        Loss       Lv      Lp      Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
    221.3534   9.7519  0.4178  210.2611  0.9226  1.0266  0.6014  468,000  467,992  468,000  all samples
    221.2660   9.6588  0.4239  210.2610  0.9222  1.0277  0.6022   52,000   52,000   52,000  latest batch
    214.5865   3.2246  0.1361  210.2611  0.9648  0.4925  0.3564  117,000  116,992  117,000  1 to 13 turns left
    221.1370   9.4882  0.4567  210.2611  0.9310  1.0801  0.6207  117,000  117,000  117,000  14 to 26 turns left
    224.2728  12.5762  0.5227  210.2611  0.9128  1.2083  0.6827  117,000  117,000  117,000  27 to 39 turns left
    225.4183  13.7196  0.5558  210.2611  0.8818  1.3255  0.7457  117,000  117,000  117,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
      221.353   9.7520   0.4175 210.2611   0.9225   0.6014   1.0265
      127.424   9.7485   0.4111 117.1452   0.1194   0.6014   0.9058
    
    Launching a checkpoint evaluation
    
      Average reward: -2.00 (win rate of -50%), redundancy: 0.9%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
      75.5161   9.7512   0.3925  65.2763   0.0961   0.6014   0.8964
    
    Launching a checkpoint evaluation
    
      Average reward: +1.00 (win rate of 100%, network replaced), redundancy: 0.9%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.91 (win rate of -95%), redundancy: 3.1%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -3.80 (win rate of -140%), redundancy: 2.7%

Starting iteration 17

  Starting self-play
  
    Time spent on inference: 60%
    Generating 3 samples per second on average
    Average exploration depth: 10.6
    MCTS memory footprint: 96.26MB
    Experience buffer size: 494,000 (493,988 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp     Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
    75.3012   9.5440  0.3850  65.2763  0.0958  0.8987  0.5968  494,000  493,988  494,000  all samples
    73.4337   7.7316  0.3331  65.2763  0.0926  0.9145  0.5596   52,000   52,000   52,000  latest batch
    68.6898   3.2069  0.1489  65.2763  0.0577  0.4414  0.3562  123,500  123,488  123,500  1 to 13 turns left
    75.2419   9.4144  0.4447  65.2763  0.1065  0.9624  0.6172  123,500  123,500  123,500  14 to 26 turns left
    78.1925  12.3173  0.4729  65.2763  0.1260  1.0570  0.6758  123,500  123,500  123,500  27 to 39 turns left
    79.0831  13.2400  0.4737  65.2763  0.0931  1.1340  0.7380  123,500  123,500  123,500  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
      75.3042   9.5441   0.3882  65.2763   0.0956   0.5968   0.8980
      45.1769   9.5569   0.3654  35.2209   0.0337   0.5968   0.9028
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 5.7%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
      28.9196   9.5469   0.3475  19.0119   0.0133   0.5968   0.9042
    
    Launching a checkpoint evaluation
    
      Average reward: -1.00 (win rate of 0%), redundancy: 2.8%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.81 (win rate of -91%), redundancy: 3.2%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -3.32 (win rate of -116%), redundancy: 2.8%

Starting iteration 18

  Starting self-play
  
    Time spent on inference: 60%
    Generating 2 samples per second on average
    Average exploration depth: 10.6
    MCTS memory footprint: 98.07MB
    Experience buffer size: 520,000 (519,984 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp     Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
    28.6470   9.2756  0.3464  19.0119  0.0131  0.9054  0.5931  520,000  519,984  520,000  all samples
    26.6176   7.2464  0.3466  19.0119  0.0127  0.9125  0.5603   52,000   52,000   52,000  latest batch
    22.3312   3.1858  0.1213  19.0119  0.0123  0.4605  0.3566  130,000  129,984  130,000  1 to 13 turns left
    28.6589   9.2297  0.4013  19.0119  0.0160  0.9821  0.6141  130,000  130,000  130,000  14 to 26 turns left
    31.3816  11.9243  0.4308  19.0119  0.0146  1.0599  0.6704  130,000  130,000  130,000  27 to 39 turns left
    32.2191  12.7654  0.4323  19.0119  0.0096  1.1189  0.7313  130,000  130,000  130,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
      28.6482   9.2758   0.3473  19.0119   0.0133   0.5931   0.9053
      19.5879   9.2952   0.3383   9.9424   0.0120   0.5931   0.8807
    
    Launching a checkpoint evaluation
    
      Average reward: -3.00 (win rate of -100%), redundancy: 6.6%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
      14.8387   9.2845   0.3332   5.2072   0.0138   0.5931   0.8788
    
    Launching a checkpoint evaluation
    
      Average reward: +2.00 (win rate of 150%, network replaced), redundancy: 2.8%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.99 (win rate of -99%), redundancy: 3.2%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -3.28 (win rate of -114%), redundancy: 2.8%

Starting iteration 19

  Starting self-play
  
    Time spent on inference: 59%
    Generating 2 samples per second on average
    Average exploration depth: 11.0
    MCTS memory footprint: 96.82MB
    Experience buffer size: 546,000 (545,984 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
    14.6355   9.0865  0.3279  5.2072  0.0139  0.8807  0.5885  546,000  545,984  546,000  all samples
    12.8589   7.3564  0.2813  5.2072  0.0139  0.8898  0.5491   52,000   52,000   52,000  latest batch
     8.5401   3.2021  0.1166  5.2072  0.0143  0.4560  0.3569  136,500  136,484  136,500  1 to 13 turns left
    14.7790   9.1702  0.3846  5.2072  0.0171  0.9561  0.6081  136,500  136,500  136,500  14 to 26 turns left
    17.2833  11.6529  0.4082  5.2072  0.0150  1.0263  0.6655  136,500  136,500  136,500  27 to 39 turns left
    17.9365  12.3180  0.4022  5.2072  0.0092  1.0843  0.7233  136,500  136,500  136,500  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
      14.6371   9.0860   0.3301   5.2072   0.0138   0.5885   0.8799
      12.0607   9.0783   0.3243   2.6489   0.0092   0.5885   0.8630
    
    Launching a checkpoint evaluation
    
      Average reward: +3.00 (win rate of 200%, network replaced), redundancy: 0.9%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
      10.7794   9.1004   0.3143   1.3560   0.0086   0.5885   0.8605
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 1.9%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.65 (win rate of -83%), redundancy: 3.0%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -3.21 (win rate of -111%), redundancy: 2.7%

Starting iteration 20

  Starting self-play
  
    Time spent on inference: 59%
    Generating 2 samples per second on average
    Average exploration depth: 10.8
    MCTS memory footprint: 96.75MB
    Experience buffer size: 572,000 (571,984 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
    10.6157   8.9391  0.3119  1.3560  0.0086  0.8604  0.5846  572,000  571,984  572,000  all samples
     9.2769   7.6162  0.2961  1.3560  0.0085  0.8679  0.5522   52,000   52,000   52,000  latest batch
     4.6935   3.2160  0.1123  1.3560  0.0091  0.4566  0.3573  143,000  142,984  143,000  1 to 13 turns left
    10.8479   9.1162  0.3650  1.3560  0.0107  0.9424  0.6049  143,000  143,000  143,000  14 to 26 turns left
    13.2281  11.4789  0.3842  1.3560  0.0091  0.9981  0.6603  143,000  143,000  143,000  27 to 39 turns left
    13.6906  11.9430  0.3860  1.3560  0.0056  1.0442  0.7161  143,000  143,000  143,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
      10.6160   8.9390   0.3123   1.3560   0.0086   0.5846   0.8615
       9.9088   8.9133   0.3064   0.6811   0.0079   0.5846   0.8508
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 0.9%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       9.5717   8.9124   0.2999   0.3519   0.0075   0.5846   0.8553
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 3.8%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.69 (win rate of -85%), redundancy: 3.0%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -3.16 (win rate of -108%), redundancy: 2.7%

Starting iteration 21

  Starting self-play
  
    Time spent on inference: 61%
    Generating 2 samples per second on average
    Average exploration depth: 10.9
    MCTS memory footprint: 97.58MB
    Experience buffer size: 598,000 (597,984 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     9.4128   8.7554  0.2981  0.3519  0.0073  0.8560  0.5812  598,000  597,984  598,000  all samples
     8.1363   7.4921  0.2852  0.3519  0.0071  0.8579  0.5500   52,000   52,000   52,000  latest batch
     3.6010   3.1329  0.1077  0.3519  0.0085  0.4558  0.3574  149,500  149,484  149,500  1 to 13 turns left
     9.7666   9.0575  0.3483  0.3519  0.0089  0.9351  0.6018  149,500  149,500  149,500  14 to 26 turns left
    11.9719  11.2460  0.3667  0.3519  0.0074  0.9890  0.6547  149,500  149,500  149,500  27 to 39 turns left
    12.3084  11.5821  0.3697  0.3519  0.0046  1.0439  0.7107  149,500  149,500  149,500  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       9.4125   8.7551   0.2980   0.3519   0.0074   0.5812   0.8558
       9.2361   8.7576   0.2898   0.1844   0.0043   0.5812   0.8265
    
    Launching a checkpoint evaluation
    
      Average reward: +1.00 (win rate of 100%, network replaced), redundancy: 3.8%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       9.1468   8.7537   0.2839   0.1048   0.0045   0.5812   0.8357
    
    Launching a checkpoint evaluation
    
      Average reward: -1.00 (win rate of 0%), redundancy: 0.9%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.79 (win rate of -89%), redundancy: 3.0%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -2.81 (win rate of -91%), redundancy: 2.7%

Starting iteration 22

  Starting self-play
  
    Time spent on inference: 60%
    Generating 2 samples per second on average
    Average exploration depth: 11.3
    MCTS memory footprint: 96.16MB
    Experience buffer size: 624,000 (623,988 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     8.9896   8.5988  0.2816  0.1048  0.0044  0.8353  0.5777  624,000  623,988  624,000  all samples
     8.0311   7.6504  0.2717  0.1048  0.0043  0.8454  0.5481   52,000   52,000   52,000  latest batch
     3.3294   3.1170  0.1024  0.1048  0.0053  0.4473  0.3566  156,000  155,988  156,000  1 to 13 turns left
     9.4035   8.9638  0.3305  0.1048  0.0043  0.9172  0.5992  156,000  156,000  156,000  14 to 26 turns left
    11.4706  11.0171  0.3446  0.1048  0.0040  0.9638  0.6505  156,000  156,000  156,000  27 to 39 turns left
    11.7548  11.2970  0.3490  0.1048  0.0040  1.0128  0.7046  156,000  156,000  156,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.9903   8.5987   0.2824   0.1048   0.0045   0.5777   0.8371
       8.9481   8.5979   0.2784   0.0668   0.0050   0.5777   0.8148
    
    Launching a checkpoint evaluation
    
      Average reward: +1.00 (win rate of 100%, network replaced), redundancy: 2.8%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.9188   8.5990   0.2668   0.0494   0.0036   0.5777   0.8398
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 0.9%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.55 (win rate of -77%), redundancy: 3.2%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -2.84 (win rate of -92%), redundancy: 2.8%

Starting iteration 23

  Starting self-play
  
    Time spent on inference: 60%
    Generating 2 samples per second on average
    Average exploration depth: 11.2
    MCTS memory footprint: 96.14MB
    Experience buffer size: 650,000 (649,988 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     8.8145   8.4962  0.2654  0.0494  0.0035  0.8392  0.5739  650,000  649,988  650,000  all samples
     7.8452   7.5306  0.2617  0.0494  0.0035  0.8413  0.5427   52,000   52,000   52,000  latest batch
     3.2841   3.1329  0.0980  0.0494  0.0038  0.4413  0.3562  162,500  162,488  162,500  1 to 13 turns left
     9.2985   8.9335  0.3119  0.0494  0.0037  0.8959  0.5965  162,500  162,500  162,500  14 to 26 turns left
    11.2349  10.8590  0.3232  0.0494  0.0033  0.9650  0.6449  162,500  162,500  162,500  27 to 39 turns left
    11.4382  11.0570  0.3287  0.0494  0.0031  1.0548  0.6979  162,500  162,500  162,500  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.8151   8.4962   0.2659   0.0494   0.0036   0.5739   0.8398
       8.8037   8.4990   0.2597   0.0417   0.0032   0.5739   0.7936
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 4.7%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.7969   8.4997   0.2547   0.0389   0.0036   0.5739   0.8107
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 1.9%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.21 (win rate of -61%), redundancy: 3.1%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -2.75 (win rate of -87%), redundancy: 2.7%

Starting iteration 24

  Starting self-play
  
    Time spent on inference: 61%
    Generating 2 samples per second on average
    Average exploration depth: 11.3
    MCTS memory footprint: 96.61MB
    Experience buffer size: 676,000 (675,992 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     8.7279   8.4325  0.2528  0.0389  0.0037  0.8092  0.5705  676,000  675,992  676,000  all samples
     8.2635   7.9792  0.2418  0.0389  0.0036  0.8112  0.5417   52,000   52,000   52,000  latest batch
     3.2827   3.1449  0.0957  0.0389  0.0032  0.4449  0.3561  169,000  168,992  169,000  1 to 13 turns left
     9.2820   8.9349  0.3042  0.0389  0.0040  0.8970  0.5933  169,000  169,000  169,000  14 to 26 turns left
    11.1465  10.7991  0.3046  0.0389  0.0039  0.9314  0.6403  169,000  169,000  169,000  27 to 39 turns left
    11.1997  10.8504  0.3068  0.0389  0.0035  0.9634  0.6923  169,000  169,000  169,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.7275   8.4324   0.2527   0.0389   0.0036   0.5705   0.8110
       8.7191   8.4333   0.2443   0.0383   0.0032   0.5705   0.8016
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 3.8%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.7256   8.4467   0.2366   0.0385   0.0037   0.5705   0.7777
    
    Launching a checkpoint evaluation
    
      Average reward: -2.00 (win rate of -50%), redundancy: 2.8%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.59 (win rate of -79%), redundancy: 3.2%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -3.01 (win rate of -101%), redundancy: 2.7%

Starting iteration 25

  Starting self-play
  
    Time spent on inference: 61%
    Generating 2 samples per second on average
    Average exploration depth: 11.3
    MCTS memory footprint: 97.02MB
    Experience buffer size: 702,000 (701,992 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     8.6649   8.3886  0.2341  0.0385  0.0037  0.7777  0.5671  702,000  701,992  702,000  all samples
     8.0594   7.7948  0.2224  0.0385  0.0037  0.7776  0.5392   52,000   52,000   52,000  latest batch
     3.3010   3.1683  0.0908  0.0385  0.0034  0.4363  0.3567  175,500  175,492  175,500  1 to 13 turns left
     9.2824   8.9564  0.2836  0.0385  0.0039  0.8459  0.5894  175,500  175,500  175,500  14 to 26 turns left
    11.0844  10.7618  0.2805  0.0385  0.0037  0.8799  0.6356  175,500  175,500  175,500  27 to 39 turns left
    10.9902  10.6663  0.2817  0.0385  0.0037  0.9489  0.6866  175,500  175,500  175,500  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.6652   8.3885   0.2345   0.0385   0.0037   0.5671   0.7780
      10.5354   8.3696   0.2342   1.9284   0.0032   0.5671   0.7829
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 0.9%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       9.4428   8.3850   0.2297   0.8249   0.0032   0.5671   0.7680
    
    Launching a checkpoint evaluation
    
      Average reward: -1.00 (win rate of 0%), redundancy: 0.9%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.95 (win rate of -97%), redundancy: 3.1%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -2.88 (win rate of -94%), redundancy: 2.8%

Starting iteration 26

  Starting self-play
  
    Time spent on inference: 61%
    Generating 2 samples per second on average
    Average exploration depth: 11.3
    MCTS memory footprint: 96.54MB
    Experience buffer size: 728,000 (727,992 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     9.3918   8.3376  0.2261  0.8249  0.0031  0.7695  0.5640  728,000  727,992  728,000  all samples
     9.1866   8.1465  0.2121  0.8249  0.0031  0.7721  0.5422   52,000   52,000   52,000  latest batch
     4.0383   3.1223  0.0877  0.8249  0.0034  0.4323  0.3569  182,000  181,992  182,000  1 to 13 turns left
    10.0943   8.9897  0.2764  0.8249  0.0034  0.8449  0.5865  182,000  182,000  182,000  14 to 26 turns left
    11.8060  10.7087  0.2695  0.8249  0.0029  0.8755  0.6312  182,000  182,000  182,000  27 to 39 turns left
    11.6280  10.5292  0.2711  0.8249  0.0028  0.9255  0.6812  182,000  182,000  182,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       9.3933   8.3382   0.2271   0.8249   0.0032   0.5640   0.7683
       8.9065   8.3254   0.2229   0.3554   0.0029   0.5640   0.7923
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 1.9%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.7230   8.3320   0.2214   0.1669   0.0027   0.5640   0.7720
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 0.9%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.67 (win rate of -83%), redundancy: 3.3%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -2.76 (win rate of -88%), redundancy: 2.7%

Starting iteration 27

  Starting self-play
  
    Time spent on inference: 61%
    Generating 2 samples per second on average
    Average exploration depth: 11.3
    MCTS memory footprint: 95.82MB
    Experience buffer size: 754,000 (753,988 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     8.6152   8.2284  0.2172  0.1669  0.0027  0.7709  0.5608  754,000  753,988  754,000  all samples
     8.3770   8.0026  0.2048  0.1669  0.0027  0.7699  0.5370   52,000   52,000   52,000  latest batch
     3.4101   3.1537  0.0864  0.1669  0.0031  0.4369  0.3565  188,500  188,488  188,500  1 to 13 turns left
     9.3549   8.9190  0.2661  0.1669  0.0029  0.8523  0.5830  188,500  188,500  188,500  14 to 26 turns left
    10.9926  10.5641  0.2592  0.1669  0.0024  0.8747  0.6271  188,500  188,500  188,500  27 to 39 turns left
    10.7035  10.2771  0.2572  0.1669  0.0024  0.9196  0.6768  188,500  188,500  188,500  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.6167   8.2285   0.2187   0.1669   0.0027   0.5608   0.7723
       8.5312   8.2220   0.2174   0.0894   0.0025   0.5608   0.7678
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 4.7%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.4982   8.2221   0.2142   0.0591   0.0028   0.5608   0.7720
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 0.9%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.64 (win rate of -82%), redundancy: 3.2%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -2.71 (win rate of -85%), redundancy: 2.7%

Starting iteration 28

  Starting self-play
  
    Time spent on inference: 61%
    Generating 2 samples per second on average
    Average exploration depth: 11.2
    MCTS memory footprint: 95.67MB
    Experience buffer size: 780,000 (779,988 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     8.3941   8.1208  0.2115  0.0591  0.0027  0.7673  0.5585  780,000  779,988  780,000  all samples
     7.9219   7.6574  0.2026  0.0591  0.0028  0.7727  0.5453   52,000   52,000   52,000  latest batch
     3.2809   3.1340  0.0850  0.0591  0.0027  0.4327  0.3559  195,000  194,988  195,000  1 to 13 turns left
     9.1906   8.8671  0.2615  0.0591  0.0029  0.8387  0.5808  195,000  195,000  195,000  14 to 26 turns left
    10.7452  10.4332  0.2503  0.0591  0.0026  0.8677  0.6237  195,000  195,000  195,000  27 to 39 turns left
    10.3609  10.0499  0.2492  0.0591  0.0028  0.9301  0.6735  195,000  195,000  195,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.3939   8.1206   0.2113   0.0591   0.0028   0.5585   0.7726
       8.3831   8.1245   0.2066   0.0495   0.0024   0.5585   0.7468
    
    Launching a checkpoint evaluation
    
      Average reward: +1.00 (win rate of 100%, network replaced), redundancy: 0.9%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.4136   8.1553   0.2103   0.0437   0.0042   0.5585   0.7594
    
    Launching a checkpoint evaluation
    
      Average reward: -3.00 (win rate of -100%), redundancy: 1.9%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.45 (win rate of -73%), redundancy: 3.2%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -2.76 (win rate of -88%), redundancy: 2.7%

Starting iteration 29

  Starting self-play
  
    Time spent on inference: 61%
    Generating 2 samples per second on average
    Average exploration depth: 12.2
    MCTS memory footprint: 93.55MB
    Experience buffer size: 806,000 (805,976 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     8.3229   8.0674  0.2077  0.0437  0.0041  0.7607  0.5546  806,000  805,976  806,000  all samples
     8.0901   7.8359  0.2064  0.0437  0.0040  0.7675  0.5205   52,000   52,000   52,000  latest batch
     3.3222   3.1891  0.0856  0.0437  0.0038  0.4366  0.3545  201,500  201,476  201,500  1 to 13 turns left
     9.1670   8.8590  0.2598  0.0437  0.0044  0.8404  0.5762  201,500  201,500  201,500  14 to 26 turns left
    10.6372  10.3441  0.2453  0.0437  0.0041  0.8624  0.6197  201,500  201,500  201,500  27 to 39 turns left
    10.1647   9.8768  0.2401  0.0437  0.0040  0.9035  0.6680  201,500  201,500  201,500  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.3232   8.0672   0.2081   0.0437   0.0042   0.5546   0.7603
       8.2827   8.0302   0.2079   0.0418   0.0028   0.5546   0.7600
    
    Launching a checkpoint evaluation
    
      Average reward: -1.00 (win rate of 0%), redundancy: 3.8%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.2785   8.0296   0.2050   0.0411   0.0028   0.5546   0.7503
    
    Launching a checkpoint evaluation
    
      Average reward: +1.00 (win rate of 100%, network replaced), redundancy: 0.9%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.41 (win rate of -71%), redundancy: 3.2%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -2.57 (win rate of -79%), redundancy: 2.8%

Starting iteration 30

  Starting self-play
  
    Time spent on inference: 61%
    Generating 2 samples per second on average
    Average exploration depth: 12.2
    MCTS memory footprint: 94.21MB
    Experience buffer size: 832,000 (831,972 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     8.1870   7.9435  0.1995  0.0411  0.0030  0.7507  0.5508  832,000  831,972  832,000  all samples
     8.1980   7.9754  0.1785  0.0411  0.0030  0.7528  0.5174   52,000   52,000   52,000  latest batch
     3.2349   3.1083  0.0824  0.0411  0.0031  0.4335  0.3533  208,000  207,972  208,000  1 to 13 turns left
     9.1037   8.8054  0.2538  0.0411  0.0034  0.8291  0.5724  208,000  208,000  208,000  14 to 26 turns left
    10.4760  10.1970  0.2351  0.0411  0.0028  0.8517  0.6147  208,000  208,000  208,000  27 to 39 turns left
     9.9346   9.6644  0.2265  0.0411  0.0026  0.8884  0.6626  208,000  208,000  208,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.1891   7.9436   0.2016   0.0411   0.0028   0.5508   0.7509
       8.1903   7.9462   0.2002   0.0411   0.0029   0.5508   0.7436
    
    Launching a checkpoint evaluation
    
      Average reward: +2.00 (win rate of 150%, network replaced), redundancy: 3.8%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.1882   7.9465   0.1980   0.0413   0.0025   0.5508   0.7508
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 3.8%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.40 (win rate of -70%), redundancy: 3.1%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -2.95 (win rate of -97%), redundancy: 2.7%

Starting iteration 31

  Starting self-play
  
    Time spent on inference: 62%
    Generating 2 samples per second on average
    Average exploration depth: 12.2
    MCTS memory footprint: 95.81MB
    Experience buffer size: 858,000 (857,980 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     8.1332   7.8928  0.1966  0.0413  0.0025  0.7500  0.5471  858,000  857,980  858,000  all samples
     7.9051   7.6575  0.2038  0.0413  0.0025  0.7556  0.5176   52,000   52,000   52,000  latest batch
     3.2370   3.1109  0.0822  0.0413  0.0025  0.4262  0.3528  214,500  214,480  214,500  1 to 13 turns left
     9.0657   8.7704  0.2512  0.0413  0.0027  0.8217  0.5690  214,500  214,500  214,500  14 to 26 turns left
    10.4167  10.1422  0.2308  0.0413  0.0024  0.8464  0.6096  214,500  214,500  214,500  27 to 39 turns left
     9.8154   9.5495  0.2222  0.0413  0.0023  0.9056  0.6571  214,500  214,500  214,500  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.1332   7.8929   0.1965   0.0413   0.0025   0.5471   0.7513
       8.1322   7.8923   0.1967   0.0411   0.0020   0.5471   0.7369
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 0.9%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.1318   7.8912   0.1967   0.0413   0.0026   0.5471   0.7192
    
    Launching a checkpoint evaluation
    
      Average reward: +1.00 (win rate of 100%, network replaced), redundancy: 0.9%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.71 (win rate of -85%), redundancy: 3.0%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -2.80 (win rate of -90%), redundancy: 2.7%

Starting iteration 32

  Starting self-play
  
    Time spent on inference: 61%
    Generating 2 samples per second on average
    Average exploration depth: 12.6
    MCTS memory footprint: 94.90MB
    Experience buffer size: 884,000 (883,980 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     8.0603   7.8235  0.1929  0.0413  0.0026  0.7182  0.5430  884,000  883,980  884,000  all samples
     8.0154   7.7970  0.1744  0.0413  0.0026  0.7175  0.5055   52,000   52,000   52,000  latest batch
     3.2088   3.0799  0.0848  0.0413  0.0028  0.4249  0.3511  221,000  220,980  221,000  1 to 13 turns left
     9.0274   8.7334  0.2498  0.0413  0.0029  0.8072  0.5647  221,000  221,000  221,000  14 to 26 turns left
    10.3342  10.0663  0.2243  0.0413  0.0024  0.8106  0.6048  221,000  221,000  221,000  27 to 39 turns left
     9.6711   9.4150  0.2127  0.0413  0.0022  0.8303  0.6513  221,000  221,000  221,000  40 to 52 turns left

Loading environment

  Loading network from: sessions/double-dummy-new/bestnn.data
  Loading network from: sessions/double-dummy-new/curnn.data
  Loading memory from: sessions/double-dummy-new/mem.data
  Loaded iteration counter from: sessions/double-dummy-new/iter.txt

Starting iteration 32

  Starting self-play
  
    Time spent on inference: 57%
    Generating 2 samples per second on average
    Average exploration depth: 12.5
    MCTS memory footprint: 94.57MB
    Experience buffer size: 884,000 (883,972 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     8.0669   7.8302  0.1929  0.0413  0.0026  0.7187  0.5433  884,000  883,972  884,000  all samples
     8.1292   7.9107  0.1746  0.0413  0.0026  0.7245  0.5115   52,000   52,000   52,000  latest batch
     3.1999   3.0711  0.0848  0.0413  0.0028  0.4252  0.3513  221,000  220,972  221,000  1 to 13 turns left
     9.0236   8.7295  0.2499  0.0413  0.0029  0.8076  0.5650  221,000  221,000  221,000  14 to 26 turns left
    10.3296  10.0617  0.2242  0.0413  0.0024  0.8110  0.6053  221,000  221,000  221,000  27 to 39 turns left
     9.7145   9.4584  0.2126  0.0413  0.0022  0.8308  0.6518  221,000  221,000  221,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.0674   7.8301   0.1934   0.0413   0.0026   0.5433   0.7198
       8.0652   7.8312   0.1901   0.0415   0.0024   0.5433   0.7334
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 0.9%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.0901   7.8550   0.1913   0.0417   0.0021   0.5433   0.7179
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 3.8%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.75 (win rate of -87%), redundancy: 3.2%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -2.89 (win rate of -95%), redundancy: 2.8%

Starting iteration 33

  Starting self-play
  
    Time spent on inference: 57%
    Generating 2 samples per second on average
    Average exploration depth: 12.4
    MCTS memory footprint: 92.30MB
    Experience buffer size: 910,000 (909,968 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     8.0410   7.8079  0.1893  0.0417  0.0021  0.7185  0.5397  910,000  909,968  910,000  all samples
     8.1949   7.9520  0.1991  0.0417  0.0021  0.7212  0.5114   52,000   52,000   52,000  latest batch
     3.2528   3.1268  0.0823  0.0417  0.0021  0.4297  0.3497  227,500  227,468  227,500  1 to 13 turns left
     8.9972   8.7057  0.2475  0.0417  0.0023  0.7958  0.5611  227,500  227,500  227,500  14 to 26 turns left
    10.3083  10.0441  0.2205  0.0417  0.0020  0.8000  0.6014  227,500  227,500  227,500  27 to 39 turns left
     9.6041   9.3538  0.2066  0.0417  0.0020  0.8485  0.6468  227,500  227,500  227,500  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.0408   7.8079   0.1891   0.0417   0.0021   0.5397   0.7183
       8.0272   7.7913   0.1914   0.0426   0.0019   0.5397   0.6991
    
    Launching a checkpoint evaluation
    
      Average reward: +1.00 (win rate of 100%, network replaced), redundancy: 3.8%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.0567   7.8248   0.1873   0.0421   0.0025   0.5397   0.7176
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 1.9%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.73 (win rate of -87%), redundancy: 3.2%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -2.97 (win rate of -99%), redundancy: 2.6%

Starting iteration 34

  Starting self-play
  
    Time spent on inference: 57%
    Generating 2 samples per second on average
    Average exploration depth: 12.7
    MCTS memory footprint: 94.04MB
    Experience buffer size: 936,000 (935,972 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     8.0091   7.7806  0.1839  0.0421  0.0025  0.7174  0.5362  936,000  935,972  936,000  all samples
     8.2018   7.9633  0.1939  0.0421  0.0026  0.7214  0.5051   52,000   52,000   52,000  latest batch
     3.2656   3.1404  0.0807  0.0421  0.0024  0.4155  0.3488  234,000  233,972  234,000  1 to 13 turns left
     8.9765   8.6875  0.2440  0.0421  0.0029  0.7869  0.5575  234,000  234,000  234,000  14 to 26 turns left
    10.2637  10.0046  0.2144  0.0421  0.0025  0.8075  0.5971  234,000  234,000  234,000  27 to 39 turns left
     9.5304   9.2894  0.1965  0.0421  0.0023  0.8596  0.6412  234,000  234,000  234,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.0103   7.7807   0.1850   0.0421   0.0025   0.5362   0.7181
       7.9699   7.7402   0.1844   0.0432   0.0021   0.5362   0.7013
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 4.7%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       7.9954   7.7693   0.1818   0.0423   0.0020   0.5362   0.6977
    
    Launching a checkpoint evaluation
    
      Average reward: -1.00 (win rate of 0%), redundancy: 8.5%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.71 (win rate of -85%), redundancy: 3.0%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -2.49 (win rate of -75%), redundancy: 2.9%

Starting iteration 35

  Starting self-play
  
    Time spent on inference: 57%
    Generating 2 samples per second on average
    Average exploration depth: 12.7
    MCTS memory footprint: 94.83MB
    Experience buffer size: 962,000 (961,972 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     7.9947  7.7697  0.1808  0.0423  0.0020  0.6971  0.5338  962,000  961,972  962,000  all samples
     8.1428  7.9123  0.1861  0.0423  0.0020  0.6986  0.5035   52,000   52,000   52,000  latest batch
     3.1805  3.0557  0.0803  0.0423  0.0021  0.4126  0.3480  240,500  240,472  240,500  1 to 13 turns left
     8.9944  8.7091  0.2408  0.0423  0.0022  0.7684  0.5553  240,500  240,500  240,500  14 to 26 turns left
    10.2412  9.9874  0.2096  0.0423  0.0019  0.7847  0.5942  240,500  240,500  240,500  27 to 39 turns left
     9.5628  9.3263  0.1923  0.0423  0.0018  0.8228  0.6379  240,500  240,500  240,500  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       7.9953   7.7697   0.1813   0.0423   0.0020   0.5338   0.6978
       7.9667   7.7395   0.1824   0.0431   0.0017   0.5338   0.6960
    
    Launching a checkpoint evaluation
    
      Average reward: +3.00 (win rate of 200%, network replaced), redundancy: 7.5%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.0585   7.7460   0.1797   0.1307   0.0021   0.5338   0.7000
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 1.9%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.77 (win rate of -89%), redundancy: 3.1%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -3.05 (win rate of -103%), redundancy: 2.8%

Starting iteration 36

  Starting self-play
  
    Time spent on inference: 58%
    Generating 2 samples per second on average
    Average exploration depth: 12.6
    MCTS memory footprint: 94.93MB
    Experience buffer size: 988,000 (987,968 distinct boards)
  
  Memory Analysis
  
       Loss      Lv      Lp    Lreg    Linv   Hpnet      Hp     Wtot       Nb       Ns
     8.0727  7.7616  0.1783  0.1307  0.0022  0.7019  0.5319  988,000  987,968  988,000  all samples
     8.2117  7.8949  0.1839  0.1307  0.0022  0.7102  0.5111   52,000   52,000   52,000  latest batch
     3.2581  3.0462  0.0789  0.1307  0.0023  0.4221  0.3473  247,000  246,968  247,000  1 to 13 turns left
     9.0451  8.6755  0.2365  0.1307  0.0025  0.7792  0.5532  247,000  247,000  247,000  14 to 26 turns left
    10.3316  9.9920  0.2069  0.1307  0.0021  0.7874  0.5922  247,000  247,000  247,000  27 to 39 turns left
     9.6552  9.3318  0.1908  0.1307  0.0019  0.8192  0.6349  247,000  247,000  247,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.0734   7.7615   0.1791   0.1307   0.0022   0.5319   0.7004
       8.0211   7.7625   0.1809   0.0755   0.0022   0.5319   0.7058
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 2.8%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.0328   7.7943   0.1804   0.0555   0.0026   0.5319   0.7043
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 1.9%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.37 (win rate of -69%), redundancy: 3.0%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -2.64 (win rate of -82%), redundancy: 2.7%

Starting iteration 37

  Starting self-play
  
    Time spent on inference: 57%
    Generating 2 samples per second on average
    Average exploration depth: 12.7
    MCTS memory footprint: 94.20MB
    Experience buffer size: 1,014,000 (1,013,972 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp       Wtot         Nb         Ns
     8.0604   7.8238  0.1784  0.0555  0.0026  0.7029  0.5299  1,014,000  1,013,972  1,014,000  all samples
     8.3003   8.0563  0.1857  0.0555  0.0028  0.7051  0.5057     52,000     52,000     52,000  latest batch
     3.2000   3.0631  0.0786  0.0555  0.0027  0.4175  0.3466    253,500    253,472    253,500  1 to 13 turns left
     9.0354   8.7411  0.2352  0.0555  0.0036  0.7737  0.5508    253,500    253,500    253,500  14 to 26 turns left
    10.3485  10.0826  0.2079  0.0555  0.0024  0.7966  0.5899    253,500    253,500    253,500  27 to 39 turns left
     9.6586   9.4092  0.1920  0.0555  0.0019  0.8237  0.6321    253,500    253,500    253,500  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.0618   7.8237   0.1799   0.0555   0.0026   0.5299   0.7044
       8.0090   7.7829   0.1761   0.0478   0.0023   0.5299   0.7032
    
    Launching a checkpoint evaluation
    
      Average reward: +2.00 (win rate of 150%, network replaced), redundancy: 0.9%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.0682   7.8395   0.1813   0.0454   0.0020   0.5299   0.6760
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 2.8%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.89 (win rate of -95%), redundancy: 2.9%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -2.72 (win rate of -86%), redundancy: 2.7%

Starting iteration 38

  Starting self-play
  
    Time spent on inference: 57%
    Generating 2 samples per second on average
    Average exploration depth: 12.7
    MCTS memory footprint: 93.71MB
    Experience buffer size: 1,040,000 (1,039,968 distinct boards)
  
  Memory Analysis
  
       Loss       Lv      Lp    Lreg    Linv   Hpnet      Hp       Wtot         Nb         Ns
     8.0998   7.8736  0.1787  0.0454  0.0020  0.6726  0.5278  1,040,000  1,039,968  1,040,000  all samples
     8.5369   8.3057  0.1838  0.0454  0.0020  0.6735  0.5055     52,000     52,000     52,000  latest batch
     3.2831   3.1552  0.0804  0.0454  0.0021  0.4068  0.3456    260,000    259,968    260,000  1 to 13 turns left
     9.0248   8.7401  0.2369  0.0454  0.0024  0.7467  0.5485    260,000    260,000    260,000  14 to 26 turns left
    10.4448  10.1900  0.2075  0.0454  0.0020  0.7566  0.5878    260,000    260,000    260,000  27 to 39 turns left
     9.6454   9.4081  0.1902  0.0454  0.0017  0.7805  0.6295    260,000    260,000    260,000  40 to 52 turns left
  
  Starting learning
  
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.1014   7.8736   0.1803   0.0454   0.0020   0.5278   0.6760
       8.0515   7.8262   0.1782   0.0445   0.0027   0.5278   0.7079
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00 (win rate of 50%), redundancy: 2.8%
    
    Optimizing the loss
    
         Loss       Lv       Lp     Lreg     Linv       Hp    Hpnet
       8.0499   7.8259   0.1780   0.0441   0.0019   0.5278   0.6703
    
    Launching a checkpoint evaluation
    
      Average reward: -2.00 (win rate of -50%), redundancy: 0.9%
    
    Optimizing the loss
    
  Running benchmark: AlphaZero against Perfect Player (0% random)
  
    Average reward: -2.67 (win rate of -83%), redundancy: 3.1%
  
  Running benchmark: Network Only against Perfect Player (0% random)
  
    Average reward: -2.67 (win rate of -83%), redundancy: 2.7%

Starting iteration 39

  Starting self-play
  
